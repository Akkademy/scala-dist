\renewcommand{\todo}[1]{}
\newcommand{\notyet}[1]{\footnote{#1 not yet implemented.}}
\newcommand{\Ts}{\mbox{\sl Ts}}
\newcommand{\tps}{\mbox{\sl tps}}
\newcommand{\ps}{\mbox{\sl ps}}
\newcommand{\ds}{\mbox{\sl ds}}
\newcommand{\xs}{\mbox{\sl xs}}
\newcommand{\psig}{\mbox{\sl psig}}
\newcommand{\fsig}{\mbox{\sl fsig}}
\newcommand{\csig}{\mbox{\sl csig}}
\newcommand{\args}{\mbox{\sl args}}
\newcommand{\targs}{\mbox{\sl targs}}
\newcommand{\enums}{\mbox{\sl enums}}
\newcommand{\proto}{\mbox{\sl pt}}
\newcommand{\argtypes}{\mbox{\sl Ts}}
\newcommand{\stats}{\mbox{\sl stats}}
\newcommand{\overload}{\la\mbox{\sf and}\ra}
\newcommand{\op}{\mbox{\sl op}}

\newcommand{\eqdef}{\stackrel{\mbox{\small eq}}{=}}
\newcommand{\ifqualified}[1]{}
\newcommand{\iflet}[1]{}
\newcommand{\ifundefvar}[1]{}
\newcommand{\iffinaltype}[1]{}
\newcommand{\ifpackaging}[1]{}
\newcommand{\ifnewfor}[1]{}

\newcommand{\U}[1]{\mbox{$\backslash$u{#1}}}
\newcommand{\Urange}[2]{\mbox{$\backslash$u{#1}-$\backslash$u{#2}}}
%\newcommand{\U}[1]{\mbox{U+{#1}}}

\section*{Preface}

Scala is a Java-like programming language which unifies
object-oriented and functional programming.  It is a pure
object-oriented language in the sense that every value is an
object. Types and behavior of objects are described by
classes. Classes can be composed using mixin composition.  Scala is
designed to work seamlessly with two less pure but mainstream
object-oriented languages -- Java and C\#.

Scala is a functional language in the sense that every function is a
value. Nesting of function definitions and higher-order functions are
naturally supported. Scala also supports a general notion of pattern
matching which can model the algebraic types used in many functional
languages.

Scala has been designed to interoperate seamlessly with Java (an
alternative implementation of Scala also works for .NET). Scala
classes can call Java methods, create Java objects, inherit from Java
classes and implement Java interfaces. None of this requires interface
definitions or glue code.

Scala has been developed from 2001 in the programming methods
laboratory at EPFL. Version 1.0 was released in November 2003. This
document describes the second version of the language, which was
released in March 2006. It acts a reference for the language
definition and some core library modules. It is not intended to teach
Scala or its concepts; for this there are other documents 
\cite{scala-overview-tech-report,%
      odersky:scala-experiment,%
      odersky:sca,%
      odersky-et-al:ecoop03,%
      odersky-zenger:fool12}.

Scala has been a collective effort of many people. The design and the
implementation of version 1.0 was completed by Philippe Altherr,
Vincent Cremet, Gilles Dubochet, Burak Emir, St\'ephane Micheloud,
Nikolay Mihaylov, Michel Schinz, Erik Stenman, Matthias Zenger, and
the author. Iulian Dragos, Gilles Dubochet, Sean McDirmid and Lex
Spoon joined in the effort to develop the second version of the
language and tools.  Gilad Bracha, Craig Chambers, Erik Ernst,
Matthias Felleisen, Shriram Krishnamurti, Gary Leavens, Sebastian
Maneth, Erik Mejer, Klaus Ostermann, Mads Torgersen, and Philip Wadler
have shaped the design of the language through lively and inspiring
discussions and comments on previous versions of this document.  The
contributors to the Scala mailing list have also given very useful
feedback that helped us improve the language and its tools.

\chapter{Lexical Syntax}

Scala programs are written using the Unicode character set.
This chapter defines the two modes of Scala's lexical syntax, the
Scala mode and the \textsc{Xml} mode. If not otherwise mentioned, the following 
descriptions of Scala tokens refer to Scala mode, and literal characters `c' refer 
to the ASCII fragment \Urange{0000}{007F}. 

In Scala mode, \textit{Unicode escapes} are replaced by the corresponding
Unicode character with the given hexadecimal code.
\begin{lstlisting}
UnicodeEscape ::= \{\\}u{u} hexDigit hexDigit hexDigit hexDigit
hexDigit      ::= '0' | $\ldots$ | `9' | `A' | $\ldots$ | `F' | `a' | $\ldots$ | `f' |
\end{lstlisting}
To construct tokens, characters are distinguished according to the following classes 
(Unicode general category given in parentheses):
\begin{enumerate}
\item Whitespace characters. \U{0020} | \U{0009} | \U{000D} | \U{000A}
\item Letters, which include lower case letters(Ll), upper case letters(Lu), titlecase letters(Lt), other letters(Lo), letter numerals(Nl) and the 
two characters \U{0024} ~\lstinline@`$\Dollar$'@ and \U{005F} ~\lstinline@`_'@, which
both count as upper case letters
\item Digits ~\lstinline@`0' | $\ldots$ | `9'@.
\item Parentheses ~\lstinline@`(' | `)' | `[' | `]' | `{' | `}'@.
\item Delimiter characters ~\lstinline@``' | `'' | `"' | `.' | `;' | `,'@.
\item Operator characters. These consist of all printable ASCII characters \Urange{0020}{007F}. 
which are in none of the sets above, mathematical symbols(Sm) and other symbols(So).
\end{enumerate}
\newpage
\section{Identifiers}\label{sec:idents}

\syntax\begin{lstlisting}
op        ::=  special {special}
varid     ::=  lower idrest
id        ::=  upper idrest
            |  varid
            |  op
            |  `\`'string chars`\`'
idrest    ::= {letter $|$ digit} [`_' op | `_' idrest]
\end{lstlisting}

There are three ways to form an identifier. First, an identifier can
start with a letter which can be followed by an arbitrary sequence of
letters and digits. This may be followed by underscore `\lstinline@_@'
characters and other string composed of either letters and digits or
of special characters.  Second, an identifier can start with a
special character followed by an arbitrary sequence of special
characters.  Finally, an identifier may also be formed by an arbitrary
string between back-quotes (host systems may impose some restrictions
on which strings are legal for identifiers).  As usual, a longest
match rule applies. For instance, the string

\begin{lstlisting}
big_bob++=`def`
\end{lstlisting}

decomposes into the three identifiers \lstinline@big_bob@, \lstinline@++=@, and
\code{def}.  The rules for pattern matching further distinguish between
{\em variable identifiers}, which start with a lower case letter, and
{\em constant identifiers}, which do not.


The `\lstinline[mathescape=false]@$@'\comment{$} character is reserved
for compiler-synthesized identifiers.  User programs should not define
identifiers which contain `\lstinline[mathescape=false]@$@'\comment{$}
characters.

The following names are reserved words instead of being members of the
syntactic class \code{id} of lexical identifiers.

\begin{lstlisting}
abstract    case        catch       class       def    
do          else        extends     false       final    
finally     for         if          implicit    import      
match       new         null        object      override    
package     private     protected   requires    return      
sealed      super       this        throw       trait
try         true        type        val         var         
while       with        yield
_    :    =    =>    <-    <:    <%     >:    #    @
\end{lstlisting}

The Unicode operator \U{21D2} `$\Rightarrow$', which has the ASCII equivalent
`\lstinline@=>@', is also reserved.

\example
Here are examples of identifiers:
\begin{lstlisting}
    x    Object        maxIndex        p2p      empty_?
    +    +_field       `yield`         $\alpha\rho\epsilon\tau\eta$      
\end{lstlisting}

\section{Newline Characters}\label{sec:newlines}

\syntax\begin{lstlisting}
StatementSeparator ::=  NewLine | `;'
\end{lstlisting}

Scala is a line-oriented language where statements may be terminated by
semi-colons or newlines. A newline in a Scala source text is treated
as the special \lstinline@NewLine@ token if the three following
criteria are satisfied:
\begin{enumerate}
\item
The token immediately preceding the newline can terminate a statement.
\item
The token immediately following the newline can begin a statement.
\item
The token appears in a region where multiple statements are allowed.
\end{enumerate}

The tokens that can terminate a statement are: literals, identifiers
and the following delimiters and reserved words:
\begin{lstlisting}
this    null    true    false    return    _    )    ]    }
\end{lstlisting}

The tokens that can begin a statement are all Scala tokens {\em except}
the following delimiters and reserved words:
\begin{lstlisting}
catch    else    extends    finally    match    requires    with    
yield    ,    .    ;    :    _    =    =>    <-    <:    <%    >:    
#    @    )    ]    }
\end{lstlisting}
A \lstinline@case@ token can begin a statement only if followed by a
\lstinline@class@ or \lstinline@object@ token.

Multiple statements are allowed in:
\begin{enumerate}
\item
all of a Scala source file, except for nested regions where newlines
are suppressed, and
\item
the interval between matching \lstinline@{@ and \lstinline@}@ brace tokens,
except for nested regions where newlines are suppressed.
\end{enumerate}

Multiple statements are disabled in:
\begin{enumerate}
\item
the interval between matching \lstinline@(@ and \lstinline@)@ parenthesis tokens, except for nested regions where newlines are enabled, and
\item
the interval between matching \lstinline@[@ and \lstinline@]@ bracket tokens,
except for nested regions where newlines are enabled.
\item
The interval between a \lstinline@case@ token and its matching
\lstinline@=>@ token, except for nested regions where newlines are
enabled.
\item Any regions analyzed in XML mode (\sref{sec::xmlMode}).
\end{enumerate}
Note that the brace characters of \lstinline@{...}@ escapes in XML and string literals are not tokens, and therefore do not enclose a region where newlines
are enabled.

\section{Literals}\label{sec:literals}

There are literals for integer numbers floating point numbers,
characters, booleans, symbols, strings.  The syntax of these literals is in
each case as in Java.

\todo{say that we take values from Java, give examples of some lits in
  particular float and double.}

\syntax\begin{lstlisting}
  Literal       ::=  integerLiteral
                  |  floatingPointLiteral
                  |  booleanLiteral
                  |  characterLiteral
                  |  stringLiteral
                  |  symbolLiteral
\end{lstlisting}

\subsection{Integer Literals}

\syntax\begin{lstlisting}
integerLiteral ::=  (decimalNumeral | hexNumeral | octalNumeral) ['L' | 'l']
decimalNumeral ::=  `0' | nonZeroDigit {digit}
hexNumeral     ::=  `0' `x' hexDigit {hexDigit}
octalNumeral   ::=  `0' octalDigit {octalDigit}
digit          ::=  `0' | nonZeroDigit
nonZeroDigit   ::=  `1' | $\ldots$ | `9'
octalDigit     ::=  `0' | $\ldots$ | `7'
\end{lstlisting}
Integer literals are usually of type \lstinline@int@, or of type
\lstinline@long@ when followed by a \lstinline@L@ or
\lstinline@l@ suffix. Values of type \lstinline@int@ are all integer
numbers between $-2^{31}$ and $2^{31}-1$, inclusive.  Values of
type \lstinline@long@ are all integer numbers between $-2^{63}$ and
$2^{63}-1$, inclusive. A compile-time error occurs if an integer literal
denotes a number outside these ranges.

However, if the expected type $\proto$ (\sref{sec:exprs}) of a literal
in an expression is either \code{byte}, \code{short}, or \code{char}
and the integer number fits in the numeric range defined by the type,
then the number is converted to type $\proto$ and the literal's type
is $\proto$. The numeric ranges given by these types are:
\begin{quote}
\begin{tabular}{p{2cm}{l}}
\lstinline@byte@ & $-2^7$ to $2^7-1$ \\
\lstinline@short@ & $-2^{15}$ to $2^{15}-1$ \\
\lstinline@char@ & $0$ to $2^{16}-1$
\end{tabular}
\end{quote}

\example
Here are some integer literals:
\begin{lstlisting}
0          -21          0xFFFFFFFF       0777L
\end{lstlisting}

\subsection{Floating Point Literals}

\syntax\begin{lstlisting}
floatingPointLiteral ::=  digit {digit} `.' {digit} [exponentPart] [floatType]
                      |   `.' digit {digit} [exponentPart] [floatType]
                      |   digit {digit} exponentPart [floatType]
                      |   digit {digit} [exponentPart] floatType
exponentPart         ::=  ('E' | 'e') ['+' | '-'] digit {digit}
floatType            ::=  'F' | 'f' | 'D' | 'd'
\end{lstlisting}
Floating point literals are of type \lstinline@float@ when followed by
a floating point type suffix \lstinline@F@ or \lstinline@f@, and are
of type \lstinline@double@ otherwise.  The type \lstinline@float@
consists of all IEEE 754 32-bit single-precision binary floating point
values, whereas the type \lstinline@double@ consists of all IEEE 754
64-bit double-precision binary floating point values.

\example
Here are some floating point literals:
\begin{lstlisting}
0.0        1e30f      3.14159f      1.0e-100      .1
\end{lstlisting}

\subsection{Boolean Literals}

\syntax\begin{lstlisting}
booleanLiteral      ::= true | false
\end{lstlisting}

The boolean literals \lstinline@true@ and \lstinline@false@ are
members of type \lstinline@boolean@.

\subsection{Character Literals}

\syntax\begin{lstlisting}
characterLiteral     ::= `\'' char `\''
                      |  `\'' charEscapeSeq `\''
\end{lstlisting}

A character literal is a single character enclosed in quotes.
The character is either a printable unicode character or is described
by an escape sequence (\sref{sec:escapes}).

\example
Here are some character literals:
\begin{lstlisting}
'a'    '\u0041'    '\n'    '\t'
\end{lstlisting}
Note that '\lstinline@\u000A@' is {\em not} a valid character literal because
Unicode conversion is done before literal parsing and the Unicode
character \lstinline@\u000A@ (line feed), and is not a printable
character. One can use instead the escape sequence `\lstinline@\n@' or
the octal escape `\lstinline@\12@' (\sref{sec:escapes}).

\subsection{String Literals}

\syntax\begin{lstlisting}
stringLiteral      ::= `\"' {stringElement} `\"'
stringElement      ::= charNoDoubleQuote |  charEscapeSeq
\end{lstlisting}

A string literal is a sequence of characters in double quotes.  The
characters are either printable unicode character or are described by
escape sequences (\sref{sec:escapes}). If the string literal
contains a double quote character, it must be escaped,
i.e. \lstinline@\"@. The value of a string literal is an instance of
class \lstinline@String@. T

\example
Here are some string literals:
\begin{lstlisting}
"Hello,\nWorld!"       
"This string contains a \" character."
\end{lstlisting}

\subsection{Escape Sequences}\label{sec:escapes}

The following escape sequences are recognized in character and string
literals.
\begin{quote}
\begin{tabular}{p{2cm}ll}
\lstinline@\b@ & \lstinline@\u0008@: backspace BS \\
\lstinline@\t@ & \lstinline@\u0009@: horizontal tab HT \\
\lstinline@\n@ & \lstinline@\u000a@: linefeed LF \\
\lstinline@\f@ & \lstinline@\u000c@: form feed FF\\
\lstinline@\r@ & \lstinline@\u000d@: carriage return CR\\
\lstinline@\"@ & \lstinline@\u0022@: double quote "\\
\lstinline@\'@ & \lstinline@\u0027@: single quote '\\
\lstinline@\\@ & \lstinline@\u0009@: backslash \lstinline@\@\\
\end{tabular}
\end{quote}
A character with Unicode between 0 and 255 may also be represented by
an octal escape, i.e. a backslash `\lstinline@\@' followed by a
sequence of up to three octal characters.

It is a compile time error if a backslash character in a character or
string literal does not start a valid escape sequence.

\subsection{Symbol literals}

A symbol literal ~\lstinline@'$x$@~ is a shorthand for the expression
~\lstinline@scala.Symbol("$x$")@. \lstinline@Symbol@ is a case class
(\sref{sec:case-classes}), which is defined as follows.
\begin{lstlisting}
package scala
final case class Symbol(name: String) {
  override def toString(): String = "'" + name
}
\end{lstlisting}

\subsection{Primitive Types Defined in {\em Predef}}

The object \lstinline@Predef@ is imported implicitly into every Scala
program . It contains type definitions which establish the primitive
types mentioned above as aliases of class types. Numeric and boolean
types are equated with standard Scala classes. The \lstinline@String@
type is equated with the string class of the underlying host
system. In a Java environment, Predef contains the following bindings,
among others:
\begin{lstlisting}
  type byte    = scala.Byte
  type short   = scala.Short
  type char    = scala.Char
  type int     = scala.Int
  type long    = scala.Long
  type float   = scala.Float
  type double  = scala.Double
  type boolean = scala.Boolean
  type String  = java.lang.String
\end{lstlisting}

\section{Whitespace and Comments}

Tokens may be separated by whitespace characters
and/or comments. Comments come in two forms:

A single-line comment is a sequence of characters which starts with
\lstinline@//@ and extends to the end of the line.

A multi-line comment is a sequence of characters between \lstinline@/*@ and
\lstinline@*/@. Multi-line comments may be nested.

\section{XML mode\label{sec::xmlMode}}

In order to allow literal inclusion of XML fragments, lexical analysis
switches from Scala mode to XML mode when encountering an opening
angle bracket '<' in the following circumstance: The '<' must be
preceded either by whitespace, an opening parenthesis or an opening
brace and immediately followed by a character starting an XML name.

\syntax\begin{lstlisting}
 ( whitespace | '(' | '{' ) '<' XNameStart

  XNameStart ::= `_' | BaseChar | Ideographic $\mbox{\rm\em (as in W3C XML, but without }$ `:'
\end{lstlisting}

The scanner switches from XML mode to Scala mode if either
\begin{itemize}
\item the XML expression or the XML pattern started by the initial '<' has been 
successfully parsed, or if

\item the parser encounters an embedded Scala expression or pattern and 
forces the Scanner 
back to normal mode, until the Scala expression or pattern is
successfully parsed. In this case, since code and XML fragments can be
nested, the parser has to maintain a stack that reflects the nesting
of XML and Scala expressions adequately.
\end{itemize}

Note that no Scala tokens are constructed in XML mode, and that comments are interpreted
as text.

\example 
The following value definition uses an XML literal with two embedded
Scala expressions
\begin{lstlisting}
val b = <book>
          <title>The Scala Language Specification</title>
          <version>{scalaBook.version}</version>
          <authors>{scalaBook.authors.mkList("", ", ", "")}</authors>
        </book>
\end{lstlisting}

\chapter{\label{sec:names}Identifiers, Names and Scopes}

Names in Scala identify types, values, methods, and classes which are
collectively called {\em entities}. Names are introduced by local
definitions and declarations (\sref{sec:defs}), inheritance (sref{sec:members}),
import clauses (\sref{sec:import}), or package clauses
(\sref{sec:packagings}) which are collectively called {\em
bindings}.

Bindings of different kinds have a precedence defined on them:
Definitions (local or inherited) have highest precedence, followed by
explicit imports, followed by wildcard imports, followed by package
members, which have lowest precedence.

There are two different name spaces, one for types (\sref{sec:types})
and one for terms (\sref{sec:exprs}).  The same name may designate a
type and a term, depending on the context where the name is used.

A binding has a {\em scope} in which the entity defined by a single
name can be accessed using a simple name. Scopes are nested.  A binding
in some inner scope {\em shadows} bindings of lower precedence in the
same scope as well as bindings of the same or lower precedence in outer
scopes. 

Note that shadowing is only a partial order. In a situation like
\begin{lstlisting}
val x = 1;
{ import p.x; 
  x }
\end{lstlisting}
neither binding of \code{x} shadows the other. Consequently, the
reference to \code{x} in the third line above would be ambiguous.

A reference to an unqualified (type- or term-) identifier $x$ is bound
by the unique binding, which
\begin{itemize}
\item defines an entity with name $x$ in the same namespace as the
identifier, and
\item shadows all other bindings that define entities with name $x$ in that namespace.
\end{itemize}
It is an error if no such binding exists.  If $x$ is bound by an
import clause, then the simple name $x$ is taken to be equivalent to
the qualified name to which $x$ is mapped by the import clause. If $x$
is bound by a definition or declaration, then $x$ refers to the entity
introduced by that binding. In that case, the type of $x$ is the type
of the referenced entity.

\example Assume the following two definitions of a objects named \lstinline@X@ in packages \lstinline@P@ and \lstinline@Q@.
%ref: shadowing.scala
\begin{lstlisting}
package P {
  object X { val x = 1; val y = 2 }
}
\end{lstlisting}
\begin{lstlisting}
package Q {
  object X { val x = true; val y = "" }
}
\end{lstlisting}
The following program illustrates different kinds of bindings and
precedences between them.
\begin{lstlisting}
package P {                  // `X' bound by package clause
import Console._             // `println' bound by wildcard import
object A {                   
  println("L4: "+X)          // `X' refers to `P.X' here
  object B {
    import Q._               // `X' bound by wildcard import
    println("L7: "+X)        // `X' refers to `Q.X' here
    import X._               // `x' and `y' bound by wildcard import
    println("L8: "+x)        // `x' refers to `Q.X.x' here
    object C {
      val x = 3              // `x' bound by local definition
      println("L12: "+x)     // `x' refers to constant `3' here
      { import Q.X._         // `x' and `y' bound by wildcard import
//      println("L14: "+x)   // reference to `x' is ambiguous here
        import X.y           // `y' bound by explicit import
        println("L16: "+y)   // `y' refers to `Q.X.y' here
        { val x = "abc"      // `x' bound by local definition
          import P.X._       // `x' and `y' bound by wildcard import
//        println("L19: "+y) // reference to `y' is ambiguous here
          println("L20: "+x) // `x' refers to string ``abc'' here
}}}}}}
\end{lstlisting}

A reference to a qualified (type- or term-) identifier $e.x$ refers to
the member of the type $T$ of $e$ which has the name $x$ in the same
namespace as the identifier. It is an error if $T$ is not a value type
(\sref{sec:value-types}). The type of $e.x$ is the member type of the
referenced entity in $T$.

\chapter{\label{sec:types}Types}

\syntax\begin{lstlisting}
  Type          ::=  Type1 `=>' Type
                  |  `(' [Types] `)' `=>' Type
                  |  Type1
  Type1         ::=  SimpleType {with SimpleType} [Refinement]
  SimpleType    ::=  StableId
                  |  SimpleType `#' id
                  |  Path `.' type
                  |  SimpleType TypeArgs
                  |  `(' Type ')'
  Types         ::=  Type {`,' Type}
\end{lstlisting}

We distinguish between first-order types and type constructors, which
take type parameters and yield types. A subset of first-order types
called {\em value types} represents sets of (first-class) values.
Value types are either {\em concrete} or {\em abstract}. Every
concrete value type can be represented as a {\em class type}, i.e.\ a
type designator (\sref{sec:type-desig}) that refers to a
class\footnote{We assume that objects and packages also implicitly
define a class (of the same name as the object or package, but
inaccessible to user programs).} (\sref{sec:class-defs}), or as a {\em
compound type} (\sref{sec:compound-types}) representing an
intersection of types, possibly with a refinement
(\sref{sec:refinements}) that further constrains the types of its
members.
\comment{A shorthand exists for denoting function types (\sref{sec:function-types}).  }
Abstract value types are introduced by type parameters and abstract
type bindings (\sref{sec:typedcl}).  Parentheses in types are used for
grouping.

Non-value types capture properties of
identifiers that are not values
(\sref{sec:synthetic-types}).  There is no syntax to express these
types directly in Scala.

\section{Paths}\label{sec:paths}\label{sec:stable-ids}

\syntax\begin{lstlisting}
  Path            ::=  StableId
                    |  [id `.'] this
  StableId        ::=  id
                    |  Path `.' id 
                    |  [id '.'] super [ClassQualifier] `.' id
  ClassQualifier  ::= `[' id `]'
\end{lstlisting}

Paths are not types themselves, but they can be a part of named types
and in that function form a central role in Scala's type system.

A path is one of the following.
\begin{itemize}
\item
The empty path $\epsilon$ (which cannot be written explicitly in user programs).
\item
\lstinline@$C$.this@, where $C$ references a class. 
The path \code{this} is taken as a shorthand for \lstinline@$C$.this@ where 
$C$ is the name of the class directly enclosing the reference. 
\item
\lstinline@$p$.$x$@ where $p$ is a path and $x$ is a stable member of $p$.
{\em Stable members} are members introduced by value or object
definitions, as well as packages.
\item
\lstinline@$C$.super.$x$@ or \lstinline@$C$.super[$M\,$].$x$@
where $C$ references a class and $x$ references a 
stable member of the super class or designated parent class $M$ of $C$. 
The prefix \code{super} is taken as a shorthand for \lstinline@$C$.super@ where 
$C$ is the name of the class directly enclosing the reference. 
\end{itemize}
A {\em stable identifier} is a path which ends in an identifier.

\section{Value Types}\label{sec:value-types}

Every value in Scala has a type which is of one of the following
forms.

\subsection{Singleton Types}
\label{sec:singleton-type}

\syntax\begin{lstlisting}
  SimpleType  ::=  Path `.' type
\end{lstlisting}

A singleton type is of the form \lstinline@$p$.type@, where $p$ is a
path pointing to a value expected to conform (\sref{sec:exprs})
to \lstinline@scala.AnyRef@.  The type denotes the set of values
consisting of \code{null} and the value denoted by $p$. 

\subsection{Type Projection}
\label{sec:type-project}

\syntax\begin{lstlisting} 
SimpleType  ::=  SimpleType `#' id
\end{lstlisting}

A type projection \lstinline@$T$#$x$@ references the type member named
$x$ of type $T$. If $x$ references an abstract type member, then $T$
must be a singleton type. 

\subsection{Type Designators}
\label{sec:type-desig}

\syntax\begin{lstlisting}
  SimpleType  ::=  StableId
\end{lstlisting}

A type designator refers to a named value type. It can be simple or
qualified. All such type designators are shorthands for type projections.

Specifically, the unqualified type name $t$ where $t$ is bound in some
class, object, or package $C$ is taken as a shorthand for
\lstinline@$C$.this.type#$t$@.  If $t$ is not bound in a class, object, or
package, then $t$ is taken as a shorthand for
\lstinline@$\epsilon$.type#$t$@.

A qualified type designator has the form \lstinline@$p$.$t$@ where $p$ is
a path (\sref{sec:paths}) and $t$ is a type name. Such a type designator is
equivalent to the type projection \lstinline@$p$.type#$x$@.

\example 
Some type designators and their expansions are listed below. We assume
a local type parameter $t$, a value \code{maintable}
with a type member \code{Node} and the standard class \lstinline@scala.Int@, 
\begin{lstlisting}
  t                     $\epsilon$.type#t
  Int                   scala.type#Int
  scala.Int             scala.type#Int
  data.maintable.Node   data.maintable.type#Node
\end{lstlisting}

\subsection{Parameterized Types}
\label{sec:param-types}

\syntax\begin{lstlisting}
  SimpleType      ::=  SimpleType TypeArgs
  TypeArgs        ::=  `[' Types `]'
\end{lstlisting}

A parameterized type $T[U_1 \commadots U_n]$ consists of a type
designator $T$ and type parameters $U_1 \commadots U_n$ where $n \geq
1$.  $T$ must refer to a type constructor which takes $n$ type
parameters $a_1 \commadots a_n$.

Say the type parameters have lower bounds $L_1 \commadots L_n$ and
upper bounds $U_1 \commadots U_n$.  The parameterized type is
well-formed if each actual type parameter {\em conforms to its
bounds}, i.e.\ $\sigma L_i <: T_i <: \sigma U_i$ where $\sigma$ is the
substitution $[a_1 := T_1 \commadots a_n := T_n]$.

\example\label{ex:param-types}
Given the partial type definitions:

\begin{lstlisting}
  class TreeMap[a <: Comparable[a], b] { $\ldots$ }
  class List[a] { $\ldots$ }
  class I extends Comparable[I] { $\ldots$ }
\end{lstlisting}

the following parameterized types are well formed:

\begin{lstlisting}
  TreeMap[I, String]
  List[I]
  List[List[Boolean]]
\end{lstlisting}

\example Given the type definitions of \sref{ex:param-types},
the following types are ill-formed:

\begin{lstlisting}
  TreeMap[I]                // illegal: wrong number of parameters
  TreeMap[List[I], Boolean] // illegal: type parameter not within bound
\end{lstlisting}

\subsection{Compound Types}
\label{sec:compound-types}
\label{sec:refinements}

\syntax\begin{lstlisting}
  Type            ::=  SimpleType {with SimpleType} [Refinement]
  Refinement      ::=  `{' [RefineStat {StatementSeparator RefineStat}] `}'
  RefineStat      ::=  Dcl
                    |  type TypeDef
                    |
\end{lstlisting}

A compound type ~\lstinline@$T_1$ with $\ldots$ with $T_n$ {$R\,$}@~
represents objects with members as given in the component types $T_1
\commadots T_n$ and the refinement \lstinline@{$R\,$}@. A refinement
\lstinline@{$R\,$}@ contains declarations and type definitions. Each
declaration or definition in a refinement must override a declaration
or definition in one of the component types $T_1 \commadots T_n$. The
usual rules for overriding (\sref{sec:overriding}) apply. If no
refinement is given, the empty refinement is implicitly added,
i.e. ~\lstinline@$T_1$ with $\ldots$ with $T_n$@~ is a shorthand for
~\lstinline@$T_1$ with $\ldots$ with $T_n$ {}@.
 
\subsection{Function Types}
\label{sec:function-types}

\syntax\begin{lstlisting}
  SimpleType     ::=  Type1 `=>' Type
                   |  `(' [Types] `)' `=>' Type
\end{lstlisting}
The type ~\lstinline@($T_1 \commadots T_n$) => $U$@~ represents the set of function
values that take arguments of types $T_1 \commadots T_n$ and yield
results of type $U$.  In the case of exactly one argument type
~\lstinline@$T$ => $U$@~ is a shorthand for ~\lstinline@($T\,$) => $U$@.  Function types
associate to the right, e.g.~\lstinline@($S\,$) => ($T\,$) => $U$@~ is the same as
~\lstinline@($S\,$) => (($T\,$) => $U\,$)@.

Function types are shorthands for class types that define \code{apply}
functions.  Specifically, the $n$-ary function type 
~\lstinline@($T_1 \commadots T_n$) => U@~ is a shorthand for the class type
\lstinline@Function$n$[$T_1 \commadots T_n$,$U\,$]@. Such class
types are defined in the Scala library for $n$ between 0 and 9 as follows.
\begin{lstlisting}
package scala 
trait Function$n$[-$T_1 \commadots$ -$T_n$, +$R$] {
  def apply($x_1$: $T_1 \commadots x_n$: $T_n$): $R$ 
  override def toString() = "<function>" 
}
\end{lstlisting}
Hence, function types are covariant (\sref{sec:variances}) in their
result type and contravariant in their argument types.

\section{Non-Value Types}
\label{sec:synthetic-types}

The types explained in the following do not denote sets of values, nor
do they appear explicitly in programs. They are introduced in this
report as the internal types of defined identifiers.

\subsection{Method Types}
\label{sec:method-types}

A method type is denoted internally as $(\Ts)U$, where $(\Ts)$ is a
sequence of types $(T_1 \commadots T_n)$ for some $n \geq 0$
and $U$ is a (value or method) type.  This type represents named
methods that take arguments of types $T_1 \commadots T_n$ 
and that return a result of type $U$.

We let method types associate to the right: $(\Ts_1)(\Ts_2)U$ is
treated as $(\Ts_1)((\Ts_2)U)$.

A special case are types of methods without any parameters. They are
written here \lstinline@=> T@. Parameterless methods name expressions
that are re-evaluated each time the parameterless method name is
referenced.

Method types do not exist as types of values. If a method name is used
as a value, its type is implicitly converted to a corresponding
function type (\sref{sec:impl-conv}).

\example The declarations
\begin{lstlisting}
def a: Int
def b (x: Int): Boolean
def c (x: Int) (y: String, z: String): String
\end{lstlisting}
produce the typings
\begin{lstlisting}
a: => Int
b: (Int) Boolean
c: (Int) (String, String) String
\end{lstlisting}

\subsection{Polymorphic Method Types}
\label{sec:poly-types}

A polymorphic method type is denoted internally as ~\lstinline@[$\tps\,$]$T$@~ where
\lstinline@[$\tps\,$]@ is a type parameter section 
~\lstinline@[$a_1$ >: $L_1$ <: $U_1 \commadots a_n$ >: $L_n$ <: $U_n$]@~ 
for some $n \geq 0$ and $T$ is a
(value or method) type.  This type represents named methods that
take type arguments ~\lstinline@$S_1 \commadots S_n$@~ which
conform (\sref{sec:param-types}) to the lower bounds
~\lstinline@$L_1 \commadots L_n$@~ and the upper bounds
~\lstinline@$U_1 \commadots U_n$@~ and that yield results of type $T$.

\example The declarations
\begin{lstlisting}
def empty[a]: List[a]
def union[a <: Comparable[a]] (x: Set[a], xs: Set[a]): Set[a]
\end{lstlisting}
produce the typings
\begin{lstlisting}
empty : [a >: Bottom <: Any] List[a]
union : [a >: Bottom <: Comparable[a]] (x: Set[a], xs: Set[a]) Set[a]  .
\end{lstlisting}

\comment{
\subsection{Overloaded Types}
\label{sec:overloaded-types}

More than one values or methods are defined in the same scope with the
same name, we model

An overloaded type consisting of type alternatives $T_1 \commadots
T_n (n \geq 2)$ is denoted internally $T_1 \overload \ldots \overload T_n$.

\example The definitions
\begin{lstlisting}
def println: unit 
def println(s: string): unit = $\ldots$ 
def println(x: float): unit = $\ldots$ 
def println(x: float, width: int): unit = $\ldots$ 
def println[a](x: a)(tostring: a => String): unit = $\ldots$
\end{lstlisting}
define a single function \code{println} which has an overloaded
type.
\begin{lstlisting}
println:  => unit $\overload$
          (String) unit $\overload$
          (float) unit $\overload$
          (float, int) unit $\overload$
          [a] (a) (a => String) unit
\end{lstlisting}

\example The definitions
\begin{lstlisting}
def f(x: T): T = $\ldots$ 
val f = 0
\end{lstlisting}
define a function \code{f} which has type ~\lstinline@(x: T)T $\overload$ Int@.
}

\section{Base Types and Member Definitions}
\label{sec:base-classes-member-defs}

Types of class members depend on the way the members are referenced.
Central here are three notions, namely:
\begin{enumerate}
\item the notion of the set of base types of a type $T$,
\item the notion of a type $T$ in some class $C$ seen from some 
      prefix type $S$,
\item the notion of the set of member bindings of some type $T$.
\end{enumerate}
These notions are defined mutually recursively as follows.

1. The set of {\em base types} of a type is a set of class types, 
given as follows.
\begin{itemize}
\item
The base types of a class type $C$ with parents $T_1 \commadots T_n$ are
$C$ itself, as well as the base types of the compound type
~\lstinline@$T_1$ with $\ldots$ with $T_n$ {$R\,$}@.
\item
The base types of an aliased type are the base types of its alias.
\item
The base types of an abstract type are the base types of its upper bound.
\item
The base types of a parameterized type 
~\lstinline@$C$[$T_1 \commadots T_n$]@~ are the base types
of type $C$, where every occurrence of a type parameter $a_i$ 
of $C$ has been replaced by the corresponding parameter type $T_i$.
\item
The base types of a singleton type \lstinline@$p$.type@ are the base types of
the type of $p$.
\item
The base types of a compound type 
~\lstinline@$T_1$ with $\ldots$ with $T_n$ {$R\,$}@~ 
are the {\em reduced union} of the base
classes of all $T_i$'s. This means: 
Let the multi-set $\SS$ be the multi-set-union of the
base types of all $T_i$'s.
If $\SS$ contains several type instances of the same class, say
~\lstinline@$S^i$#$C$[$T^i_1 \commadots T^i_n$]@~ $(i \in I)$, then
all those instances 
are replaced by one of them which conforms to all
others. It is an error if no such instance exists. It follows that the reduced union, if it exists,
produces a set of class types, where different types are instances of different classes.
\item
The base types of a type selection \lstinline@$S$#$T$@ are
determined as follows. If $T$ is an alias or abstract type, the
previous clauses apply. Otherwise, $T$ must be a (possibly
parameterized) class type, which is defined in some class $B$.  Then
the base types of \lstinline@$S$#$T$@ are the base types of $T$
in $B$ seen from the prefix type $S$.
\end{itemize}

2. The notion of a type $T$
{\em in class $C$ seen from some prefix type
$S\,$} makes sense only if the prefix type $S$
has a type instance of class $C$ as a base type, say
~\lstinline@$S'$#$C$[$T_1 \commadots T_n$]@. Then we define as follows.
\begin{itemize}
 \item 
  If \lstinline@$S$ = $\epsilon$.type@, then $T$ in $C$ seen from $S$ is $T$ itself.
 \item Otherwise, if $T$ is the $i$'th type parameter of some class $D$, then
   \begin{itemize}
   \item
   If $S$ has a base type ~\lstinline@$D$[$U_1 \commadots U_n$]@, for some type parameters
   ~\lstinline@[$U_1 \commadots U_n$]@, then $T$ in $C$ seen from $S$ is $U_i$.
   \item
   Otherwise, if $C$ is defined in a class $C'$, then
   $T$ in $C$ seen from $S$ is the same as $T$ in $C'$ seen from $S'$.
   \item
   Otherwise, if $C$ is not defined in another class, then  
   $T$ in $C$ seen from $S$ is $T$ itself.
  \end{itemize}
\item
   Otherwise, 
   if $T$ is the singleton type \lstinline@$D$.this.type@ for some class $D$
   then
   \begin{itemize}
   \item
   If $D$ is a subclass of $C$ and 
   $S$ has a type instance of class $D$ among its base types,
   then $T$ in $C$ seen from $S$ is $S$.
   \item
   Otherwise, if $C$ is defined in a class $C'$, then
   $T$ in $C$ seen from $S$ is the same as $T$ in $C'$ seen from $S'$.
   \item
   Otherwise, if $C$ is not defined in another class, then  
   $T$ in $C$ seen from $S$ is $T$ itself.
   \end{itemize}
\item
  If $T$ is some other type, then the described mapping is performed
  to all its type components.
\end{itemize}

If $T$ is a possibly parameterized class type, where $T$'s class
is defined in some other class $D$, and $S$ is some prefix type,
then we use ``$T$ seen from $S$'' as a shorthand for
``$T$ in $D$ seen from $S$''.

3. The {\em member bindings} of a type $T$ are all bindings $d$ such that
there exists a type instance of some class $C$ among the base types of $T$
and there exists a definition or declaration $d'$ in $C$
such that $d$ results from $d'$ by replacing every
type $T'$ in $d'$ by $T'$ in $C$ seen from $T$.

The {\em definition} of a type projection \lstinline@$S$#$t$@ is the member
binding $d_t$ of the type $t$ in $S$. In that case, we also say
that \lstinline@$S$#$t$@ {\em is defined by} $d_t$.

\section{Relations between types}

We define two relations between types.
\begin{quote}\begin{tabular}{l@{\gap}l@{\gap}l}
\em Type equivalence & $T \equiv U$ & $T$ and $U$ are interchangeable
in all contexts.
\\
\em Conformance & $T \conforms U$ & Type $T$ conforms to type $U$.
\end{tabular}\end{quote}

\subsection{Type Equivalence}
\label{sec:type-equiv}

Equivalence $(\equiv)$ between types is the smallest congruence\footnote{ A
congruence is an equivalence relation which is closed under formation
of contexts} such that the following holds:
\begin{itemize}
\item 
If $t$ is defined by a type alias ~\lstinline@type $t$ = $T$@, then $t$ is
equivalent to $T$.
\item
If a path $p$ has a singleton type ~\lstinline@$q$.type@, then
~\lstinline@$p$.type $\equiv q$.type@.
\item
If $O$ is defined by an object definition, and $p$ is a path
consisting only of package or object selectors and ending in $O$, then
~\lstinline@$O$.this.type $\equiv p$.type@.
\item
Two compound types are equivalent if their component types are
pairwise equivalent and their refinements are equivalent. Two
refinements are equivalent if they bind the same names and the
modifiers, types and bounds of every declared entity are equivalent in
both refinements.
\item
Two method types are equivalent if they have equivalent result types,
both have the same number of parameters, and corresponding parameters
have equivalent types.  Note that the names of parameters do not
matter for method type equivalence.
\item
Two polymorphic types are equivalent if they have the same number of
type parameters, and, after renaming one set of type parameters by
another, the result types as well as lower and upper bounds of
corresponding type parameters are equivalent.
\end{itemize}

\subsection{Conformance}
\label{sec:conformance}

The conformance relation $(\conforms)$ is the smallest 
transitive relation that satisfies the following conditions.
\begin{itemize}
\item Conformance includes equivalence. If $T \equiv U$ then $T \conforms U$.
\item For every value type $T$, 
      $\mbox{\code{scala.Bottom}} \conforms T \conforms \mbox{\code{scala.Any}}$. 
\item For every class type $T \conforms \mbox{\code{scala.AnyRef}}$ 
      one has $\mbox{\code{scala.Null}} \conforms T$.
\item A type variable or abstract type $t$ conforms to its upper bound and
      its lower bound conforms to $t$. 
\item A class type or parameterized type conforms to any of its base-types.
\item A type projection \lstinline@$T$#$t$@ conforms to \lstinline@$U$#$t$@ if 
      $T$ conforms to $U$.
\item A parameterized type ~\lstinline@$T$[$T_1 \commadots T_n$]@~ conforms to 
      ~\lstinline@$T$[$U_1 \commadots U_n$]@~ if
      the following three conditions hold for $i = 1 \commadots n$. 
      \begin{itemize}
      \item
      If the $i$'th type parameter of $T$ is declared covariant, then $T_i \conforms U_i$.
      \item
      If the $i$'th type parameter of $T$ is declared contravariant, then $U_i \conforms T_i$.
      \item
      If the $i$'th type parameter of $T$ is declared neither covariant 
      nor contravariant, then $U_i \equiv T_i$.
      \end{itemize}
\item A compound type ~\lstinline@$T_1$ with $\ldots$ with $T_n$ {$R\,$}@~ conforms to
      each of its component types $T_i$.
\item If $T \conforms U_i$ for $i = 1 \commadots n$ and for every
      binding $d$ of a type or value $x$ in $R$ there exists a member
      binding of $x$ in $T$ which subsumes $d$, then $T$ conforms to the
      compound type ~\lstinline@$U_1$ with $\ldots$ with $U_n$ {$R\,$}@.
\item If
        $T_i \equiv T'_i$ for $i = 1 \commadots n$ and $U$ conforms to $U'$ 
        then the method type $(T_1 \commadots T_n) U$ conforms to
        $(T'_1 \commadots T'_n) U'$.
\item The polymorphic type
$[a_1 >: L_1 <: U_1 \commadots a_n >: L_n <: U_n] T$ conforms to the polymorphic type
$[a_1 >: L'_1 <: U'_1 \commadots a_n >: L'_n <: U'_n] T'$ if, assuming
$L'_1 \conforms a_1 \conforms U'_1 \commadots L'_n \conforms a_n \conforms U'_n$ 
one has $T \conforms T'$ and $L_i \conforms L'_i$ and $U'_i \conforms U_i$
for $i = 1 \commadots n$.
\end{itemize}

A declaration or definition in some compound type of class type $C$
{\em subsumes} another
declaration of the same name in some compound type or class type $C'$, if one of the following holds.
\begin{itemize}
\item
A value or declaration or definition that defines a name $x$ with type $T$ subsumes 
a value or method declaration that defines $x$ with type $T'$, provided $T \conforms T'$.
\item 
A method declaration or definition that defines a name $x$ with type $T$ subsumes 
a method declaration that defines $x$ with type $T'$, provided $T \conforms T'$.
\item
A type alias
$\TYPE;t=T$ subsumes a type alias $\TYPE;t=T'$ if
$T \equiv T'$.
\item 
A type declaration ~\lstinline@type $t$ >: $L$ <: $U$@~ subsumes
a type declaration ~\lstinline@type $t$ >: $L'$ <: $U'$@~ if $L' \conforms L$ and 
$U \conforms U'$.
\item
A type or class definition that binds a type name $t$ subsumes an abstract
type declaration ~\lstinline@type t >: L <: U@~ if
$L \conforms t \conforms U$.
\end{itemize}

The $(\conforms)$ relation forms pre-order between types,
i.e. it is transitive and reflexive. {\em
least upper bounds} and {\em greatest lower bounds} of a set of types
are understood to be relative to that order.

\paragraph{Note} The least upper bound or greatest lower bound 
of a set of types does not always exist. For instance, consider
the class definitions
\begin{lstlisting}
class A[+t] {}
class B extends A[B] 
class C extends A[C] 
\end{lstlisting}
Then the types ~\lstinline@A[Any], A[A[Any]], A[A[A[Any]]], ...@~ form
a descending sequence of upper bounds for \code{B} and \code{C}. The
least upper bound would be the infinite limit of that sequence, which
does not exist as a Scala type. Since cases like this are in general
impossible to detect, a Scala compiler is free to reject a term
which has a type specified as a least upper or greatest lower bound,
and that bound would be more complex than some compiler-set
limit\footnote{The current Scala compiler limits the nesting level
of parameterization in such bounds to 10.}.

The least upper bound or greatest lower bound might also not be
unique. For instance \code{A with B} and \code{B with A} are both
least upper bounds of \code{A} and \code{B}. If there are several
least upper bounds or greatest lower bounds, the Scala compiler is
free to pick any one of them.

\section{Type Erasure}
\label{sec:erasure}

A type is called {\em generic} if it contains type arguments or type variables.
{\em Type erasure} is a mapping from (possibly generic) types to
non-generic types. We write $|T|$ for the erasure of type $T$.
The erasure mapping is defined as follows.
\begin{itemize}
\item The erasure of a type variable is the erasure of its upper bound.
\item The erasure of a parameterized type $T[T_1 \commadots T_n]$ is $|T|$.
\item The erasure of a singleton type \lstinline@$p$.type@ is the 
      erasure of the type of $p$.
\item The erasure of a type projection \lstinline@$T$#$x$@ is \lstinline@|$T$|#$x$@.
\item The erasure of a compound type ~\lstinline@$T_1$ with $\ldots$ with $T_n$ {$R\,$}@ 
      is $|T_1|$.
\item The erasure of every other type is the type itself.
\end{itemize}

\chapter{Basic Declarations and Definitions}
\label{sec:defs}

\syntax\begin{lstlisting}
  Dcl             ::=  val ValDcl
                    |  var VarDcl
                    |  def FunDcl
                    |  type TypeDcl
  Def             ::=  val PatDef 
                    |  var VarDef 
                    |  def FunDef 
                    |  type TypeDef 
                    |  TmplDef
\end{lstlisting}

A {\em declaration} introduces names and assigns them types. It can
form part of a class definition (\sref{sec:templates}) or of a
refinement in a compound type (\sref{sec:refinements}).

A {\em definition} introduces names that denote terms or types. It can
form part of an object or class definition or it can be local to a
block.  Both declarations and definitions produce {\em bindings} that
associate type names with type definitions or bounds, and that
associate term names with types.

The scope of a name introduced by a declaration or definition is the
whole statement sequence containing the binding.  However, there is a
restriction on forward references in blocks: In a statement sequence
$s_1 \ldots s_n$ making up a block, if a simple name in $s_i$ refers
to an entity defined by $s_j$ where $j \geq i$, then none of the
definitions between and including $s_i$ and $s_j$ may be a value or
variable definition.

\comment{
Every basic definition may introduce several defined names, separated
by commas. These are expanded according to the following scheme:
\bda{lcl}
\VAL;x, y: T = e && \VAL; x: T = e \\
                 && \VAL; y: T = x \\[0.5em]

\LET;x, y: T = e && \LET; x: T = e \\
                 && \VAL; y: T = x \\[0.5em]

\DEF;x, y (ps): T = e &\tab\mbox{expands to}\tab& \DEF; x(ps): T = e \\
                      && \DEF; y(ps): T = x(ps)\\[0.5em]

\VAR;x, y: T := e && \VAR;x: T := e\\
                  && \VAR;y: T := x\\[0.5em]

\TYPE;t,u = T && \TYPE; t = T\\
              && \TYPE; u = t\\[0.5em]
\eda

All definitions have a ``repeated form'' where the initial
definition keyword is followed by several constituent definitions
which are separated by commas.  A repeated definition is
always interpreted as a sequence formed from the
constituent definitions. E.g.\ the function definition
~\lstinline@def f(x) = x, g(y) = y@~ expands to
~\lstinline@def f(x) = x; def g(y) = y@~ and
the type definition
~\lstinline@type T, U <: B@~ expands to
~\lstinline@type T; type U <: B@.
}
\comment{
If an element in such a sequence introduces only the defined name,
possibly with some type or value parameters, but leaves out any
additional parts in the definition, then those parts are implicitly
copied from the next subsequent sequence element which consists of
more than just a defined name and parameters. Examples:
\begin{itemize}
\item[]
The variable declaration ~\lstinline@var x, y: int@~ 
expands to ~\lstinline@var x: int; var y: int@.
\item[]
The value definition ~\lstinline@val x, y: int = 1@~ 
expands to ~\lstinline@val x: int = 1; val y: int = 1@.
\item[]
The class definition ~\lstinline@case class X(), Y(n: int) extends Z@~ expands to
~\lstinline@case class X extends Z; case class Y(n: int) extends Z@.
\item
The object definition ~\lstinline@case object Red, Green, Blue extends Color@~
expands to  
\begin{lstlisting}
case object Red extends Color  
case object Green extends Color 
case object Blue extends Color .
\end{lstlisting}
\end{itemize}
}
\section{Value Declarations and Definitions}
\label{sec:valdef}

\syntax\begin{lstlisting}
  Dcl          ::=  val ValDcl
  ValDcl       ::=  ids `:' Type
  Def          ::=  val PatDef 
  PatDef       ::=  Pattern2 {`,' Pattern2} [`:' Type] `=' Expr
  ids          ::=  id {`,' id}
\end{lstlisting}

A value declaration ~\lstinline@val $x$: $T$@~ introduces $x$ as a name of a value of
type $T$.  

A value definition ~\lstinline@val $x$: $T$ = $e$@~ defines $x$ as a name of the
value that results from the evaluation of $e$. The type $T$ may be
omitted, in which case the type of expression $e$ is assumed.
If a type $T$ is given, then $e$ is expected to conform to it (\sref{sec:exprs}).

Evaluation of the value definition implies evaluation of its
right-hand side $e$.  The effect of the value definition is to bind
$x$ to the value of $e$ converted to type $T$.

Value definitions can alternatively have a pattern
(\sref{sec:patterns}) as left-hand side.  If $p$ is some pattern other
than a simple name or a name followed by a colon and a type, then the
value definition ~\lstinline@val $p$ = $e$@~ is expanded as follows:

1. If the pattern $p$ has bound variables $x_1 \commadots x_n$, where $n > 1$:
\begin{lstlisting}
val $\Dollar x$ = $e$ match {case $p$ => scala.Tuple$n$($x_1 \commadots x_n$)}
val $x_1$ = $\Dollar x$._1
$\ldots$
val $x_n$ = $\Dollar x$._n  .
\end{lstlisting}
Here, $\Dollar x$ is a fresh name.  The class
\lstinline@Tuple$n$@ is defined for $n = 2 \commadots 9$ in package
\code{scala}.

2. If $p$ has a unique bound variable $x$:
\begin{lstlisting}
val $x$ = $e$ match { case $p$ => $x$ }
\end{lstlisting}

3. If $p$ has no bound variables:
\begin{lstlisting}
$e$ match { case $p$ => ()}
\end{lstlisting}

\example
The following are examples of value definitions
\begin{lstlisting}
val pi = 3.1415 
val pi: double = 3.1415   // equivalent to first definition
val Some(x) = f()         // a pattern definition
val x :: xs = mylist      // an infix pattern definition
\end{lstlisting}

The last two definitions have the following expansions.
\begin{lstlisting}
val x = f() match { case Some(x) => x }

val x$\Dollar$ = mylist match { case x :: xs => scala.Tuple2(x, xs) }
val x = x$\Dollar$._1 
val xs = x$\Dollar$._2 
\end{lstlisting}

A value declaration ~\lstinline@val $x_1 \commadots x_n$: $T$@~
is a
shorthand for the sequence of value declarations
~\lstinline@val $x_1$: $T$; ...; val $x_n$: $T$@.
A value definition ~\lstinline@val $p_1 \commadots p_n$ = $e$@~
is a
shorthand for the sequence of value definitions
~\lstinline@val $p_1$ = $e$; ...; val $p_n$ = $e$@.
A value definition ~\lstinline@val $p_1 \commadots p_n: T$ = $e$@~
is a
shorthand for the sequence of value definitions
~\lstinline@val $p_1: T$ = $e$; ...; val $p_n: T$ = $e$@.

\section{Variable Declarations and Definitions}
\label{sec:vardef}

\syntax\begin{lstlisting}
  Dcl            ::=  var VarDcl
  Def            ::=  var VarDef
  VarDcl         ::=  ids `:' Type
  VarDef         ::=  ids [`:' Type] `=' Expr
                   |  ids `:' Type `=' `_'
\end{lstlisting}

A variable declaration ~\lstinline@var $x$: $T$@~ is equivalent to declarations
of a {\em getter function} $x$ and a {\em setter function}
\lstinline@$x$_=@, defined as follows:

\begin{lstlisting}
  def $x$: $T$ 
  def $x$_= ($y$: $T$): unit
\end{lstlisting}

An implementation of a class containing variable declarations
may define these variables using variable definitions, or it may
define setter and getter functions directly.

A variable definition ~\lstinline@var $x$: $T$ = $e$@~ introduces a mutable
variable with type $T$ and initial value as given by the
expression $e$. The type $T$ can be omitted, 
in which case the type of $e$ is assumed. If $T$ is given, then $e$ 
is expected to conform to it (\sref{sec:exprs}).

A variable definition ~\lstinline@var $x$: $T$ = _@~ introduces a mutable
variable with type \ $T$ and a default initial value. 
The default value depends on the type $T$ as follows:
\begin{quote}\begin{tabular}{ll}
\code{0} & if $T$ is \code{int} or one of its subrange types, \\
\code{0L} & if $T$ is \code{long},\\
\lstinline@0.0f@ & if $T$ is \code{float},\\
\lstinline@0.0d@ & if $T$ is \code{double},\\
\code{false} & if $T$ is \code{boolean},\\
\lstinline@()@ & if $T$ is \code{unit}, \\
\code{null} & for all other types $T$.
\end{tabular}\end{quote}

When they occur as members of a template, both forms of variable
definition also introduce a getter function $x$ which returns the
value currently assigned to the variable, as well as a setter function
\lstinline@$x$_=@ which changes the value currently assigned to the variable.
The functions have the same signatures as for a variable declaration.
The template then has the these getter and setter functions as
members, whereas the original variable cannot be accessed directly as
a template member.

\example The following example shows how {\em properties} can be
simulated in Scala. It defines a class \code{TimeOfDayVar} of time
values with updatable integer fields representing hours, minutes, and
seconds. Its implementation contains tests that allow only legal
values to be assigned to these fields. The user code, on the other
hand, accesses these fields just like normal variables.

\begin{lstlisting}
class TimeOfDayVar {
  private var h: int = 0 
  private var m: int = 0 
  private var s: int = 0 

  def hours              =  h 
  def hours_= (h: int)   =  if (0 <= h && h < 24) this.h = h 
                            else throw new DateError() 

  def minutes            =  m 
  def minutes_= (m: int) =  if (0 <= m && m < 60) this.m = m
                            else throw new DateError() 

  def seconds            =  s 
  def seconds_= (s: int) =  if (0 <= s && s < 60) this.s = s
                            else throw new DateError() 
}
val d = new TimeOfDayVar 
d.hours = 8; d.minutes = 30; d.seconds = 0 
d.hours = 25                  // throws a DateError exception
\end{lstlisting}

A variable declaration ~\lstinline@var $x_1 \commadots x_n$: $T$@~
is a
shorthand for the sequence of variable declarations
~\lstinline@var $x_1$: $T$; ...; var $x_n$: $T$@.
A variable definition ~\lstinline@var $x_1 \commadots x_n$ = $e$@~
is a
shorthand for the sequence of variable definitions
~\lstinline@var $x_1$ = $e$; ...; var $x_n$ = $e$@.
A variable definition ~\lstinline@var $x_1 \commadots x_n: T$ = $e$@~
is a
shorthand for the sequence of variable definitions
~\lstinline@var $x_1: T$ = $e$; ...; var $x_n: T$ = $e$@.

\section{Type Declarations and Type Aliases}
\label{sec:typedcl}
\label{sec:typealias}

\syntax\begin{lstlisting}
  Dcl             ::=  type TypeDcl
  TypeDcl         ::=  id [>: Type] [<: Type]
  Def             ::=  type TypeDef
  TypeDef         ::=  id [TypeParamClause] `=' Type
\end{lstlisting}

A {\em type declaration} ~\lstinline@type $t$ >: $L$ <: $U$@~ declares
$t$ to be an abstract type with lower bound type $L$ and upper bound
type $U$.  If such a declaration appears as a member declaration of a
type, implementations of the type may implement $t$ with any type $T$
for which $L \conforms T \conforms U$. It is a compile-time error if
$L$ does not conform to $U$.  Either or both bounds may be omitted.
If the lower bound $L$ is absent, the bottom type
\lstinline@scala.Bottom@ is assumed.  If the upper bound $U$ is absent,
the top type \lstinline@scala.Any@ is assumed.

A {\em type alias} ~\lstinline@type $t$ = $T$@~ defines $t$ to be an alias
name for the type $T$.  The left hand side of a type alias may
have a type parameter clause, e.g. ~\lstinline@type $t$[$\tps\,$] = $T$@.  The scope
of a type parameter extends over the right hand side $T$ and the
type parameter clause $\tps$ itself.  

The scope rules for definitions (\sref{sec:defs}) and type parameters
(\sref{sec:funsigs}) make it possible that a type name appears in its
own bound or in its right-hand side.  However, it is a static error if
a type alias refers recursively to the defined type constructor itself.  
That is, the type $T$ in a type alias ~\lstinline@type $t$[$\tps\,$] = $T$@~ may not refer
directly or indirectly to the name $t$.  It is also an error if
an abstract type is directly or indirectly its own upper or lower bound.

\example The following are legal type declarations and definitions:
\begin{lstlisting}
type IntList = List[Integer]
type T <: Comparable[T]
type Two[a] = Tuple2[a, a]
\end{lstlisting}

The following are illegal:
\begin{lstlisting}
type Abs = Comparable[Abs]        // recursive type alias

type S <: T                       // S, T are bounded by themselves.
type T <: S

type T >: Comparable[T.That]      // Cannot select from T.
                                  // T is a type, not a value
\end{lstlisting}

If a type alias ~\lstinline@type $t$[$\tps\,$] = $S$@~ refers to a class type
$S$, the name $t$ can also be used as a constructor for
objects of type $S$.

\example The \code{Predef} object contains a definition which establishes \code{Pair} 
as an alias of the parameterized class \code{Tuple2}:
\begin{lstlisting}
type Pair[+a, +b] = Tuple2[a, b] 
\end{lstlisting}
As a consequence, for any two types $S$ and $T$, the type
~\lstinline@Pair[$S$, $T\,$]@~ is equivalent to the type ~\lstinline@Tuple2[$S$, $T\,$]@.
\code{Pair} can also be used as a constructor instead of \code{Tuple2}.
Furthermore, because \code{Tuple2} is a case class (\sref{sec:case-classes}),
\code{Pair2} is also an alias for the case class factory \lstinline@Tuple2@, and this holds
for in expressions as well as patterns. Hence, the following are all legal uses of \lstinline@Pair@.
\begin{lstlisting}
val x: Pair[int, String] = new Pair(1, "abc")
val y: Pair[String, int] = x match {
  case Pair(i, s) => Pair(z + i, i * i)
}
\end{lstlisting}

\section{Type Parameters}\label{sec:type-params}

\syntax\begin{lstlisting}
  TypeParamClause  ::= [NewLine] 
                       `[' VariantTypeParam {`,' VariantTypeParam} `]'
  VariantTypeParam ::= [`+' | `-'] TypeParam
  TypeParam        ::= id [>: Type] [<: Type]
\end{lstlisting}


Type parameters appear in type definitions, class definitions, and
function definitions.  In this section we consider only type parameter
definitions with lower bounds ~\lstinline@>: $L$@~ and upper bounds
~\lstinline@<: $U$@~ whereas a discussion of view bounds
~\lstinline@<% $U$@~ is deferred to Section~\ref{sec:view-bounds}.

The most general form of a type parameter is ~\lstinline@$\pm t$>:$L$<:$U$@.  
Here, $L$, and $U$ are lower and upper bounds that
constrain possible type arguments for the parameter.  It is a
compile-time error if $L$ does not conform to $U$. $\pm$ is a {\em
variance}, i.e.\ an optional prefix of either \lstinline@+@, or
\lstinline@-@.

\comment{
The upper bound $U$ in a type parameter clauses may not be a final
class. The lower bound may not denote a value type.\todo{Why}
}
The names of all type parameters in a type parameter clause must be
pairwise different.  The scope of a type parameter includes in each
case the whole type parameter clause. Therefore it is possible that a
type parameter appears as part of its own bounds or the bounds of
other type parameters in the same clause.  However, a type parameter
may not be bounded directly or indirectly by itself.

\example Here are some well-formed type parameter clauses:
\begin{lstlisting}
[s, t]
[ex <: Throwable]
[a <: Comparable[b], b <: a]
[a, b >: a, c >: a <: b]
\end{lstlisting}
The following type parameter clauses are illegal:
\begin{lstlisting}
[a >: a]                  // illegal, `a' has itself as bound
[a <: b, b <: c, c <: a]  // illegal, `a' has itself as bound
[a, b, c >: a <: b]       // illegal lower bound `a' of `c' does
                          // not conform to upper bound `b'.
\end{lstlisting}

\section{Variance Annotations}\label{sec:variances}

Variance annotations indicate how instances of parameterized types
vary with respect to subtyping (\sref{sec:conformance}).  A
`\lstinline@+@' variance indicates a covariant dependency, a
`\lstinline@-@' variance indicates a contravariant dependency, and a
missing variance indication indicates an invariant dependency.

A variance annotation constrains the way the annotated type variable
may appear in the type or class which binds the type parameter.  In a
type definition ~\lstinline@type $t$[$\tps\,$] = $S$@, type parameters labeled
`\lstinline@+@' must only appear in covariant position in $S$ whereas
type parameters labeled `\lstinline@-@' must only appear in contravariant
position. Analogously, for a class definition
~\lstinline@class $c$[$\tps\,$]($\ps\,$) requires $s$ extends $t$@, type parameters labeled
`\lstinline@+@' must only appear in covariant position in the self type
$s$ and the template $t$, whereas type
parameters labeled `\lstinline@-@' must only appear in contravariant
position. 

The variance position of a type parameter in a type or template is
defined as follows.  Let the opposite of covariance be contravariance,
and the opposite of invariance be itself.  The top-level of the type
or template is always in covariant position. The variance position
changes at the following constructs.
\begin{itemize}
\item
The variance position of a method parameter is the opposite of the 
variance position of the enclosing parameter clause.
\item
The variance position of a type parameter is the opposite of the
variance position of the enclosing type parameter clause.
\item
The variance position of the lower bound of a type declaration or type parameter 
is the opposite of the variance position of the type declaration or parameter.  
\item
The right hand side $S$ of a type alias ~\lstinline@type $t$[$\tps\,$] = $S$@~ 
is always in invariant position.
\item
The type of a mutable variable is always in invariant position.
\item 
The prefix $S$ of a type selection \lstinline@$S$#$T$@ is always in invariant position.
\item
For a type argument $T$ of a type ~\lstinline@$S$[$\ldots T \ldots$ ]@: If the
corresponding type parameter is invariant, then $T$ is in
invariant position.  If the corresponding type parameter is
contravariant, the variance position of $T$ is the opposite of
the variance position of the enclosing type ~\lstinline@$S$[$\ldots T \ldots$ ]@.
\end{itemize}

\example The following variance annotation is legal. 
\begin{lstlisting}
abstract class P[+a, +b] {
  def fst: a; def snd: b
}
\end{lstlisting}
With this variance annotation, elements
of type $P$ subtype covariantly with respect to their arguments. 
For instance, 
\begin{lstlisting}
P[IOException, String] <: P[Throwable, AnyRef] .
\end{lstlisting}

If we make the elements of $P$ mutable, 
the variance annotation becomes illegal. 
\begin{lstlisting}
abstract class Q[+a, +b] { 
  var fst: a            // **** error: illegal variance:
  var snd: b            // `a', `b' occur in invariant position.
}
\end{lstlisting}

\example The following variance annotation is illegal, since $a$ appears
in contravariant position in the parameter of \code{append}:

\begin{lstlisting}
abstract class Vector[+a] {
  def append(x: Vector[a]): Vector[a]  
                        // **** error: illegal variance: 
                        // `a' occurs in contravariant position.
}
\end{lstlisting} 
The problem can be avoided by generalizing the type of \code{append}
by means of a lower bound:

\begin{lstlisting}
abstract class Vector[+a] {
  def append[b >: a](x: Vector[b]): Vector[b] 
}
\end{lstlisting}

\example Here is a case where a contravariant type parameter is useful.

\begin{lstlisting}
abstract class OutputChannel[-a] {
  def write(x: a): unit
}
\end{lstlisting}
With that annotation, we have that
\lstinline@OutputChannel[AnyRef]@ conforms to \lstinline@OutputChannel[String]@.  
That is, a
channel on which one can write any object can substitute for a channel
on which one can write only strings.

\section{Function Declarations and Definitions}
\label{sec:defdef}
\label{sec:funsigs}
\label{sec:parameters}

\syntax\begin{lstlisting} 
Dcl                ::=  def FunDcl
FunDcl             ::=  FunSig `:' Type 
Def                ::=  def FunDef
FunDef             ::=  FunSig [`:' Type] `=' Expr 
FunSig             ::=  id [FunTypeParamClause] ParamClauses
FunTypeParamClause ::=  [NewLine] [' TypeParam {`,' TypeParam} `]' 
ParamClauses       ::=  {ParamClause} [[NewLine] `(' implicit Params `)']
ParamClause        ::=  [NewLine] `(' [Params] ')'} 
Params             ::=  Param {`,' Param}
Param              ::=  id `:' ParamType
ParamType          ::=  [`=>'] Type [`*']
\end{lstlisting}

A function declaration has the form ~\lstinline@def $f \psig$: $T$@, where
$f$ is the function's name, $\psig$ is its parameter
signature and $T$ is its result type. A function definition
~\lstinline@$f \psig$: $T$ = $e$@~ also includes a {\em function body} $e$,
i.e.\ an expression which defines the function's result.  A parameter
signature consists of an optional type parameter clause \lstinline@[$\tps\,$]@,
followed by zero or more value parameter clauses
~\lstinline@($\ps_1$)$\ldots$($\ps_n$)@.  Such a declaration or definition
introduces a value with a (possibly polymorphic) method type whose
parameter types and result type are as given.

The type of the function body must conform to the function's declared
result type, if one is given. If the function definition is not
recursive nor overloaded, the result type may be omitted, in which case
it is determined from the type of the function body.

A type parameter clause $\tps$ consists of one or more type
declarations (\sref{sec:typedcl}), which introduce type parameters,
possibly with bounds.  The scope of a type parameter includes
the whole signature, including any of the type parameter bounds as
well as the function body, if it is present.  

A value parameter clause $\ps$ consists of zero or more formal
parameter bindings such as \lstinline@$x$: $T$@, which bind value
parameters and associate them with their types.  The scope of a formal
value parameter name $x$ is the function body, if one is
given. Both type parameter names and value parameter names must be
pairwise distinct.

The type of a value parameter may be prefixed by \code{=>}, e.g.\
~\lstinline@$x$: => $T$@. The type of such a parameter is then the
parameterless method type ~\lstinline@=> $T$@. This indicates that the
corresponding argument is not evaluated at the point of function
application, but instead is evaluated at each use within the
function. That is, the argument is evaluated using {\em call-by-name}.

\example The declaration
\begin{lstlisting}
def whileLoop (cond: => Boolean) (stat: => Unit): Unit
\end{lstlisting}
indicates that both parameters of \code{whileLoop} are evaluated using
call-by-name.

The last value parameter of a parameter section may be suffixed by
``\code{*}'', e.g.\ ~\lstinline@(..., $x$:$T$*)@.  The type of such a
{\em repeated} parameter inside the method is then the sequence type
\lstinline@scala.Seq[$T$]@.  Methods with repeated parameters
\lstinline@$T$*@ take a variable number of arguments of type $T$.
That is, if a method $m$ with type ~\lstinline@($T_1 \commadots T_n,
S$*)$U$@~ is applied to arguments $(e_1 \commadots e_k)$ where $k \geq
n$, then $m$ is taken in that application to have type $(T_1
\commadots T_n, S \commadots S)U$, with $k - n$ occurrences of type
$S$.  The only exception to this rule is if the last argument is
marked to be a {\em sequence argument} via a \lstinline@_*@ type
annotation. If $m$ above is applied to arguments
~\lstinline@($e_1 \commadots e_n, e'$: _*)@, then the type of $m$ in
that application is taken to be 
~\lstinline@($T_1\commadots T_n,$ scala.Seq[$S$])@.

\example The following method definition computes the sum of a variable number
of integer arguments.
\begin{lstlisting}
def sum(args: int*) {
  var result = 0 
  for (val arg <- args.elements) result = result + arg 
  result
}
\end{lstlisting}
The following applications of this method yield \code{0}, \code{1},
\code{6}, in that order.
\begin{lstlisting}
sum()
sum(1)
sum(1, 2, 3)
\end{lstlisting}
Furthermore, assume the definition:
\begin{lstlisting}
val xs = List(1, 2, 3)
\end{lstlisting}
The following applications method \lstinline@sum@ is ill-formed:
\begin{lstlisting}
sum(xs)       // ***** error: expected: int, found: List[int]
\end{lstlisting}
By contrast, the following application is well formed and yields again
the result \code{6}:
\begin{lstlisting}
sum(xs: _*) 
\end{lstlisting}

\comment{
For any index $i$ let $\fsig_i$ be a function signature consisting of a function
name, an optional type parameter section, and zero or more parameter
sections.  Then a function declaration 
~\lstinline@def $\fsig_1 \commadots \fsig_n$: $T$@~ 
is a shorthand for the sequence of function
declarations ~\lstinline@def $\fsig_1$: $T$; ...; def $\fsig_n$: $T$@.  
A function definition ~\lstinline@def $\fsig_1 \commadots \fsig_n$ = $e$@~ is a
shorthand for the sequence of function definitions 
~\lstinline@def $\fsig_1$ = $e$; ...; def $\fsig_n$ = $e$@.  
A function definition
~\lstinline@def $\fsig_1 \commadots \fsig_n: T$ = $e$@~ is a shorthand for the
sequence of function definitions 
~\lstinline@def $\fsig_1: T$ = $e$; ...; def $\fsig_n: T$ = $e$@.
}

\comment{
\section{Overloaded Definitions}
\label{sec:overloaded-defs}
\todo{change}

An overloaded definition is a set of $n > 1$ value or function
definitions in the same statement sequence that define the same name,
binding it to types ~\lstinline@$T_1 \commadots T_n$@, respectively.
The individual definitions are called {\em alternatives}.  Overloaded
definitions may only appear in the statement sequence of a template.
Alternatives always need to specify the type of the defined entity
completely.  It is an error if the types of two alternatives $T_i$ and
$T_j$ have the same erasure (\sref{sec:erasure}).

\todo{Say something about bridge methods.}
%This must be a well-formed
%overloaded type
}

\section{Import Clauses}
\label{sec:import}

\syntax\begin{lstlisting}
  Import          ::= import ImportExpr {`,' ImportExpr}
  ImportExpr      ::= StableId `.' (id | `_' | ImportSelectors)
  ImportSelectors ::= `{' {ImportSelector `,'} 
                      (ImportSelector | `_') `}'
  ImportSelector  ::= id [`=>' id | `=>' `_']
\end{lstlisting}

An import clause has the form ~\lstinline@import $p$.$I$@~ where $p$ is a stable
identifier (\sref{sec:paths}) and $I$ is an import expression.
The import expression determines a set of names of members of $p$
which are made available without qualification. 
The most general form of an import expression is a list of {\em import
selectors}
\begin{lstlisting}
{ $x_1$ => $y_1 \commadots x_n$ => $y_n$, _ } .
\end{lstlisting}
for $n \geq 0$, where the final wildcard `\lstinline@_@' may be absent.  It
makes available each member \lstinline@$p$.$x_i$@ under the unqualified name
$y_i$. I.e.\ every import selector ~\lstinline@$x_i$ => $y_i$@~ renames
\lstinline@$p$.$x_i$@ to
$y_i$.  If a final wildcard is present, all members $z$ of
$p$ other than ~\lstinline@$x_1 \commadots x_n$@~ are also made available
under their own unqualified names.

Import selectors work in the same way for type and term members. For
instance, an import clause ~\lstinline@import $p$.{$x$ => $y\,$}@~ renames the term
name \lstinline@$p$.$x$@ to the term name $y$ and the type name \lstinline@$p$.$x$@
to the type name $y$. At least one of these two names must
reference a member of $p$.

If the target in an import selector is a wildcard, the import selector
hides access to the source member. For instance, the import selector
~\lstinline@$x$ => _@~ ``renames'' $x$ to the wildcard symbol (which is
unaccessible as a name in user programs), and thereby effectively
prevents unqualified access to $x$. This is useful if there is a
final wildcard in the same import selector list, which imports all
members not mentioned in previous import selectors.

The scope of a binding introduced by an import-clause starts
immediately after the import clause and extends to the end of the
enclosing block, template, package clause, or compilation unit,
whichever comes first.

Several shorthands exist. An import selector may be just a simple name
$x$. In this case, $x$ is imported without renaming, so the
import selector is equivalent to ~\lstinline@$x$ => $x$@. Furthermore, it is
possible to replace the whole import selector list by a single
identifier or wildcard. The import clause ~\lstinline@import $p$.$x$@~ is
equivalent to ~\lstinline@import $p$.{$x\,$}@~, i.e.\ it makes available without
qualification the member $x$ of $p$. The import clause
~\lstinline@import $p$._@~ is equivalent to
~\lstinline@import $p$.{_}@, 
i.e.\ it makes available without qualification all members of $p$
(this is analogous to ~\lstinline@import $p$.*@~ in Java).

An import clause with multiple import expressions
~\lstinline@import $p_1$.$I_1 \commadots p_n$.$I_n$@~ is interpreted as a
sequence of import clauses 
~\lstinline@import $p_1$.$I_1$; $\ldots$; import $p_n$.$I_n$@.

\example Consider the object definition:
\begin{lstlisting}
object M { 
  def z = 0, one = 1  
  def add(x: Int, y: Int): Int = x + y 
}
\end{lstlisting}
Then the block
\begin{lstlisting}
{ import M.{one, z => zero, _}; add(zero, one) }
\end{lstlisting}
is equivalent to the block 
\begin{lstlisting}
{ M.add(M.z, M.one) } .
\end{lstlisting}

\chapter{Classes and Objects}
\label{sec:globaldefs}

\syntax\begin{lstlisting}
  TmplDef          ::= [case] class ClassDef
                    |  [case] object ObjectDef
                    |  trait TraitDef
\end{lstlisting}

Classes (\sref{sec:class-defs}) and objects
(\sref{sec:object-defs}) are both defined in terms of {\em templates}.

\section{Templates}
\label{sec:templates}

\syntax\begin{lstlisting}
  Template        ::= TemplateParents [TemplateBody]
  TemplateParents ::= SimpleType {`(' [Exprs] `)'} {with SimpleType}
  TemplateBody    ::=  `{' [TemplateStat {StatementSeparator TemplateStat}] `}'
\end{lstlisting}

A template defines the type signature, behavior and initial state of a
class of objects or of a single object. Templates form part of
instance creation expressions, class definitions, and object
definitions.  A template 
~\lstinline@$sc$ with $mt_1$ with $\ldots$ with $mt_n$ {$\stats\,$}@~ 
consists of a constructor invocation $sc$
which defines the template's {\em superclass}, trait references
~\lstinline@$mt_1 \commadots mt_n$@~ $(n \geq 0)$, which define the
template's {\em traits}, and a statement sequence $\stats$ which
contains initialization code and additional member definitions for the
template.

Each trait reference $mt_i$ must denote a trait (\sref{sec:traits}).
By contrast, the superclass constructor $sc$ normally refers to a
class which is not a trait. It is possible to write a list of
parents that starts with a trait reference, e.g.
~\lstinline@$mt_1$ with $\ldots$ with $mt_n$@. In that case the list
of parents is implicitly extended to include the supertype of $mt_1$
as first parent type. The new supertype must have at least one
constructor that does not take parameters.  In the following, we will
always assume that this implicit extension has been performed, so that
the first parent class of a template is a regular superclass
constructor, not a trait reference.

The list of parents of every class is also always implicitly extended
by a reference to the \code{scala.ScalaObject} trait as last
mixin. E.g.\
\begin{lstlisting}
$sc$ with $mt_1$ with $\ldots$ with $mt_n$ {$\stats\,$}
\end{lstlisting}
becomes
\begin{lstlisting}
$mt_1$ with $\ldots$ with $mt_n$ {$\stats\,$} with ScalaObject {$\stats\,$} .
\end{lstlisting}

The {\em least proper supertype} of a template is the class type or
compound type (\sref{sec:compound-types}) consisting of all its parent
class types. 

The statement sequence $\stats$ contains member definitions that
define new members or overwrite members in the parent classes.  If the
template forms part of a class definition, the statement part $\stats$
may also contain declarations of abstract members. Furthermore,
$\stats$ may contain expressions that are executed in the order they
are given as part of the initialization of a template.


\example Consider the following class definitions:

\begin{lstlisting}
class Base extends Object {}
trait Mixin extends Base {}
object O extends Mixin {}
\end{lstlisting}
In this case, the definition of \code{O} is expanded to:
\begin{lstlisting}
object O extends Base with Mixin {}
\end{lstlisting}

%The type of each non-private definition or declaration of a
%template must be equivalent to a type which does not refer to any
%private members of that template.

\todo{Make all references to Java generic}

\paragraph{\em Inheriting from Java Types} A template may have a Java class as
its superclass and Java interfaces as its mixins. 

\paragraph{\em Template Evaluation}
Consider a template ~\lstinline@$sc$ with $mt_1$ with $mt_n$ {$\stats\,$}@.

If this is the template of a trait (\sref{sec:traits}) then its {\em
mixin-evaluation} consists of an evaluation of the statement sequence
$\stats$.

If this is not a template of a trait, then its {\em evaluation}
consists of the following steps.
\begin{itemize}
\item
First, the superclass constructor $sc$ is evaluated (\sref{sec:constr-invoke}).
\item
Then, all base classes in the template's linearization
(\sref{sec:linearization}) up to the
template's superclass denoted by $sc$ are
mixin-evaluated. Mixin-evaluation happens in reverse order of
occurrence in the linearization, i.e. the class immediately preceding
$sc$ is evaluated first.
\item 
Finally the statement sequence $\stats\,$ is evaluated.
\end{itemize}

\subsection{Constructor Invocations}
\label{sec:constr-invoke}
\syntax\begin{lstlisting}
  Constr  ::=  StableId [TypeArgs] {`(' [Exprs] `)'}
\end{lstlisting}

Constructor invocations define the type, members, and initial state of
objects created by an instance creation expression, or of parts of an
object's definition which are inherited by a class or object
definition. A constructor invocation is a function application
~\lstinline@$x$.$c$[$\targs$]($\args_1$)$\ldots$($\args_n$)@, where $x$ is a stable identifier
(\sref{sec:stable-ids}), $c$ is a type name which either designates a
class or defines an alias type for one, $\targs$ is a type argument
list, and $\args_1 \commadots \args_n$ are argument lists, which match
the parameters of one the constructors of that class. 

The prefix `\lstinline@$x$.@' can be omitted.  A type argument list
can be given only if the class $c$ takes type parameters.  Even then
it can be omitted, in which case a type argument list is synthesized
using local type inference (\sref{sec:local-type-inf}). If no explicit
arguments are given, an empty list \lstinline@()@ is implicitly supplied.

An evaluation of a constructor invocation 
~\lstinline@$x$.$c$[$\targs$]($\args_1$)$\ldots$($\args_n$)@~
consists of the following steps:
\begin{itemize}
\item First, the prefix $x$ is evaluated.
\item Then, the arguments $\args_1 \commadots \args_n$ are evaluated from left to right.
\item Finally, the being constructed is initialized by evaluating the
  template of the class referred to by $c$.
\end{itemize}

\subsection{Class Linearization}\label{sec:linearization}

The classes reachable through transitive closure of the direct
inheritance relation from a class $C$ are called the {\em
base classes} of $C$.  Because of mixins, the inheritance relationship
on base classes forms in general a directed acyclic graph. A
linearization of this graph is defined as follows.

\newcommand{\uright}{\;\vec +\;}
\newcommand{\lin}[1]{{\cal L}(#1)}

\begin{definition}\label{def:lin} Let $C$ be a class with template
~\lstinline@$C_1$ with ... with $C_n$ { $\stats$ }@.
The {\em linearization} of $C$, $\lin C$ is defined as follows:
\bda{rcl}
\lin C &=& C\ , \ \lin{C_n} \uright \ldots \uright \lin{C_1} 
\eda
Here $\uright$ denotes concatenation where elements of the right operand
replace identical elements of the left operand:
\bda{lcll}
\{a, A\} \uright B &=& a, (A \uright B)  &{\bf if} a \not\in B \\
                 &=& A \uright B       &{\bf if} a \in B
\eda
\end{definition}

\example Consider the following class definitions.
\begin{lstlisting}
abstract class AbsIterator extends AnyRef with ScalaObject { ... }
trait RichIterator extends AbsIterator { ... }
class StringIterator extends AbsIterator { ... }
class Iter extends StringIterator with RichIterator { ... }
\end{lstlisting}
Then the linearization of class \lstinline@Iter@ is
\begin{lstlisting}
{ Iter, RichIterator, StringIterator, AbsIterator, AnyRef, Any }
\end{lstlisting}

Note that the linearization of a class refines the inheritance
relation: if $C$ is a subclass of $D$, then $C$ precedes $D$ in any
linearization where both $C$ and $D$ occur.
\ref{def:lin} also satisfies the property that a linearization
of a class always contains the linearization of its direct superclass
as a suffix.  For instance, the linearization of
\lstinline@StringIterator@ is
\begin{lstlisting}
{ StringIterator, AbsIterator, AnyRef, Any }
\end{lstlisting}
which is a suffix of the linearization of its subclass \lstinline@Iter@.
The same is not true for the linearization of mixins.
For instance, the linearization of \lstinline@RichIterator@ is
\begin{lstlisting}
{ RichIterator, AbsIterator, AnyRef, Any }
\end{lstlisting}
which is not a suffix of the linearization of \lstinline@Iter@.


\subsection{Class Members}
\label{sec:members}

A class $C$ defined by a template 
~\lstinline@$C_1$ with $\ldots$ with $C_n$ { $\stats$ }@~ 
can define members in its statement sequence
$\stats$ and can inherit members from all parent classes.  Scala
adopts Java and C\#'s conventions for static overloading of
methods. It is thus possible that a class defines and/or inherits
several methods with the same name.  To decide whether a defined
member of a class $C$ overrides a member of a parent class, or whether
the two co-exist as overloaded variants in $C$, Scala uses the
following definition of {\em matching} on members:

\begin{definition}
A member definition $M$ {\em matches} a member definition $M'$, if $M$
and $M'$ bind the same name, and one of following holds.
\begin{enumerate}
\item Neither $M$ nor $M'$ is a method definition.
\item $M$ and $M'$ define both monomorphic methods with equal argument
  types.
\item $M$ defines a parameterless method and $M'$ defines a method
  with an empty parameter list \code{()} or {\em vice versa}. 
\item $M$ and $M'$ define both polymorphic methods with 
equal number of argument types $\overline T$, $\overline T'$
and equal numbers of type parameters
$\overline t$, $\overline t'$, say, and $\overline T' = [\overline t'/\overline t]\overline T$.
%every argument type
%$T_i$ of $M$ is equal to the corresponding argument type $T'_i$ of
%$M'$ where every occurrence of a type parameter $t'$ of $M'$ has been replaced by the corresponding type parameter $t$ of $M$.
\end{enumerate}
\end{definition}
Member definitions fall into two categories: concrete and abstract.
Members of class $C$ are either {\em directly defined} (i.e. they appear in
$C$'s statement sequence $\stats$) or they are {\em inherited}.  There are two rules
that determine the set of members of a class, one for each category:

\begin{definition}\label{def:member}
A {\em concrete member} of a class $C$ is any concrete definition $M$ in
some class $C_i \in \lin C$, except if there is a preceding class $C_j
\in \lin C$ where $j < i$ which directly defines a concrete member $M'$ matching $M$.  

An {\em abstract member} of a class $C$ is any abstract definition $M$
in some class $C_i \in \lin C$, except if $C$ contains already a
concrete member $M'$ matching $M$, or if there is a preceding class
$C_j \in \lin C$ where $j < i$ which directly defines an abstract member $M'$ matching
$M$.
\end{definition}
This definition also determines the overriding relationships between
matching members of a class $C$ and its parents (\sref{sec:overriding}).  
First, a concrete definition always overrides an abstract definition.  Second, for
definitions $M$ and $M$' which are both concrete or both abstract, $M$
overrides $M'$ if $M$ appears in a class that precedes (in the
linearization of $C$) the class in which $M'$ is defined.

It is an error if a template directly defines two matching members. It
is also an error if a template contains two members (directly defined
or inherited) with the same name and the same erased type (\sref{sec:erasure}).

\comment{
The type of a member $m$ is determined as follows: If $m$ is defined
in $\stats$, then its type is the type as given in the member's
declaration or definition. Otherwise, if $m$ is inherited from the
base class ~\lstinline@$B$[$T_1$, $\ldots$. $T_n$]@, $B$'s class declaration has formal
parameters ~\lstinline@[$a_1 \commadots a_n$]@, and $M$'s type in $B$ is $U$, then
$M$'s type in $C$ is ~\lstinline@$U$[$a_1$ := $T_1 \commadots a_n$ := $T_n$]@.

\ifqualified{
Members of templates have internally qualified names $Q\qex x$ where
$x$ is a simple name and $Q$ is either the empty name $\epsilon$, or
is a qualified name referencing the module or class that first
introduces the member. A basic declaration or definition of $x$ in a
module or class $M$ introduces a member with the following qualified
name:
\begin{enumerate}
\item
If the binding is labeled with an ~\lstinline@override $Q$@\notyet{Override
  with qualifier} modifier,
where $Q$ is a fully qualified name of a base class of $M$, then the
qualified name is the qualified expansion (\sref{sec:names}) of $x$ in
$Q$.
\item
If the binding is labeled with an \code{override} modifier without a
base class name, then the qualified name is the qualified expansion
of $x$ in $M$'s least proper supertype (\sref{sec:templates}).
\item
An implicit \code{override} modifier is added and case (2) also
applies if $M$'s least proper supertype contains an abstract member
with simple name $x$.
\item
If no \code{override} modifier is given or implied, then if $M$ is
labeled \code{qualified}, the qualified name is $M\qex x$. If $M$ is
not labeled \code{qualified}, the qualified name is $\epsilon\qex x$.
\end{enumerate}
}
}

\example Consider the class definitions

\begin{lstlisting}
class A { def f: Int = 1 ; def g: Int = 2 ; def h: Int = 3 }
abstract class B { def f: Int = 4 ; def g: Int }
abstract class C extends A with B { def h: Int }
\end{lstlisting}

Then class \code{C} has a directly defined abstract member \code{h}. It
inherits member \code{f} from class \code{B} and member \code{g} from
class \code{A}.

\subsection{Overriding}
\label{sec:overriding}

\todo{Explain that classes cannot override each other}

A member $M$ of class $C$ that matches a non-private member $M'$ of a
base class of $C$ is said to {\em override} that member.  In this case
the binding of the overriding member $M$ must subsume
(\sref{sec:conformance}) the binding of the overridden member $M'$.
Furthermore, the following restrictions on modifiers apply to $M$ and
$M'$:
\begin{itemize}
\item
$M'$ must not be labeled \code{final}.
\item
$M$ must not be \code{private} (\sref{sec:modifiers}).
\item
If $M$ is labeled ~\lstinline@private[$C$]@~ for some enclosing class or package $C$,
then $M'$ must be labeled ~\lstinline@private[$C'$]@~ for some class or package $C'$ where
$C'$ equals $C$ or $C'$ is contained in $C$.
\item
If $M$ is labeled \code{protected}, then $M'$ must also be
labeled \code{protected}.
\item
If $M'$ is not an abstract member, then
$M$ must be labeled \code{override}.
\item
If $M'$ is incomplete (\sref{sec:modifiers}) in $C$ then $M$ must be
labeled \code{abstract override}.
\end{itemize}

\example\label{ex:compound-a}
Consider the definitions:
\begin{lstlisting}
trait Root { type T <: Root }
trait A extends Root { type T <: A }
trait B extends Root { type T <: B }
trait C extends A with B 
\end{lstlisting}
Then the class definition \code{C} is not well-formed because the
binding of \code{T} in \code{C} is
~\lstinline@type T <: B@,
which fails to subsume the binding ~\lstinline@type T <: A@~ of \code{T}
in type \code{A}. The problem can be solved by adding an overriding 
definition of type \code{T} in class \code{C}:
\begin{lstlisting}
class C extends A with B { type T <: C }
\end{lstlisting}

\section{Modifiers}
\label{sec:modifiers}

\syntax\begin{lstlisting}
  Modifier          ::=  LocalClassModifier
                      |  private [ "[" id "]" ] 
                      |  protected
                      |  override
                      |  implicit
  LocalClassModifier ::= abstract
                      |  final
                      |  sealed
\end{lstlisting}

Member definitions may be preceded by modifiers which affect the
accessibility and usage of the identifiers bound by them.  If several
modifiers are given, their order does not matter, but the same
modifier may not occur repeatedly.  Modifiers preceding a repeated
definition apply to all constituent definitions.  The rules governing
the validity and meaning of a modifier are as follows.
\begin{itemize}
\item
The \code{private} modifier can be used with any definition or
declaration in a template.  The modifier can be {\em qualified} with a
class or package identifier $C$ e.g.  ~\lstinline@private[$C$]@.
Members labeled with such a modifier can be accessed only from code
contained in the class or package named $C$.  It is a compile-time
error if $C$ does not denote a class or package enclosing the
definition.  

We say, a member {\em is private} if it is labeled with a
\code{private} modifier without qualification.  Such members can be
accessed only from within the directly enclosing template.  They are
not inherited by subclasses and they may not override definitions in
parent classes.

\code{private} may not be applied to abstract members, and it
may not be combined in one modifier list with
\code{protected}, \code{final} or \code{override}.
\item
The \code{protected} modifier applies to class member definitions.
Protected members can be accessed from within the template of the defining
class as well as in all templates that have the defining class as a base class.
%Furthermore, accesses from the template of the defining class are not
%permitted in packagings other than the one
%containing the definition.  
A protected identifier $x$ may be used as
a member name in a selection \lstinline@$r$.$x$@ only if $r$ is one of the reserved
words \code{this} and
\code{super}, or if $r$'s type conforms to a type-instance of the class
which contains the access.
\item
The \code{override} modifier applies to class member definitions or declarations.  It
is mandatory for member definitions or declarations that override some other concrete
member definition in a parent class. If an \code{override}
modifier is given, there must be at least one overridden member
definition or declaration (either concrete or abstract).  
\item
The \code{override} modifier has a different significance when
combined with the \code{abstract} modifier.  That modifier combination
is only allowed for value members of traits.  A member labeled
\code{abstract override} must override at least one other member and 
all members overridden by it must be incomplete. 

We call a member $M$ of a template {\em incomplete} if it is either
abstract (i.e.\ defined by a declaration), or it is labeled
\code{abstract} and \code{override} and 
every member overridden by $M$ is again incomplete. 

Note that the \code{abstract override} modifier combination does not
influence the concept whether a member is concrete or abstract. A
member is {\em abstract} if only a declaration is given for it; it is
{\em concrete} if a full definition is given.
\item
The \code{abstract} modifier is used in class definitions. It is
redundant for traits, and mandatory for all other classes which have
incomplete members.  Abstract classes cannot be instantiated
(\sref{sec:inst-creation}) with a constructor invocation unless
followed by mixins and/or a refinement which override all
incomplete members of the class.

The \code{abstract} modifier can also be used in conjunction with
\code{override} for class member definitions. In that case the
previous discussion applies.
\item
The \code{final} modifier applies to class member definitions and to
class definitions. A \code{final} class member definition may not be
overridden in subclasses. A \code{final} class may not be inherited by
a template. \code{final} is redundant for object definitions.  Members
of final classes or objects are implicitly also final, so the
\code{final} modifier is redundant for them, too.  \code{final} may
not be applied to incomplete members, and it may not be combined in one
modifier list with \code{private} or \code{sealed}.
\item
The \code{sealed} modifier applies to class definitions. A
\code{sealed} class may not be directly inherited, except if the inheriting 
template is defined the same source file as the inherited class.
However, subclasses of a sealed class can inherited anywhere.
\end{itemize}

\example The following code illustrates the use of qualified private:
\begin{lstlisting}
package outerpkg.innerpkg
class Outer {
  class Inner {
    private[Outer] def f()
    private[innerpkg] def g()
    private[outerpkg] def h()
  }
}
\end{lstlisting}
Here, accesses to the method \lstinline@f@ can appear anywhere within
\lstinline@OuterClass@, but not outside it. Accesses to method
\lstinline@g@ can appear anywhere within the package
\lstinline@outerpkg.innerpkg@, as would be the case for
package-private methods in Java. Finally, accesses to method
\lstinline@h@ can appear anywhere within package \lstinline@outerpkg@,
including packages contained in it. 

\example A useful idiom to prevent clients of a class from
constructing new instances of that class is to declare the class
\code{abstract} and \code{sealed}:

\begin{lstlisting}
object m {
  abstract sealed class C (x: Int) {
    def nextC = new C(x + 1) {}
  }
  val empty = new C(0) {}
}
\end{lstlisting}
For instance, in the code above clients can create instances of class
\lstinline@m.C@ only by calling the \code{nextC} method of an existing \lstinline@m.C@
object; it is not possible for clients to create objects of class
\lstinline@m.C@ directly. Indeed the following two lines are both in error:

\begin{lstlisting}
  new m.C(0)    // **** error: C is abstract, so it cannot be instantiated.
  new m.C(0) {} // **** error: illegal inheritance from sealed class.
\end{lstlisting}

\section{Class Definitions}
\label{sec:class-defs}

\syntax\begin{lstlisting} 
  TmplDef           ::= class ClassDef 
  ClassDef          ::= id [TypeParamClause] ClassParamClauses 
                        [`requires' SimpleType] ClassTemplate 
  ClassTemplate     ::= [extends TemplateParents] [[NewLine] TemplateBody]
  ClassParamClauses ::= {ClassParamClause} 
                        [[NewLine] `(' implicit ClassParams `)']
  ClassParamClause  ::= [NewLine] `(' [ClassParams ')'} 
  ClassParams       ::= ClassParam {`' ClassParam}
  ClassParam        ::= [{Modifier} (`val' | `var')] Param
  TemplateParents   ::= Constr {`with' SimpleType}
\end{lstlisting}

The most general form of class definition is 
\begin{lstlisting}
class $c$[$\tps\,$]($\ps_1$)$\ldots$($\ps_n$) requires $s$ extends $t$    $\gap(n \geq 0)$.
\end{lstlisting}
Here,
\begin{itemize}
\item[]
$c$ is the name of the class to be defined.
\item[] $\tps$ is a non-empty list of type parameters of the class
being defined.  The scope of a type parameter is the whole class
definition including the type parameter section itself.  It is
illegal to define two type parameters with the same name.  The type
parameter section \lstinline@[$\tps\,$]@ may be omitted. A class with a type
parameter section is called {\em polymorphic}, otherwise it is called
{\em monomorphic}.
\item[] 
$(\ps_1)\ldots(\ps_n)$ are formal value parameter clauses for the {\em primary
constructor} of the class. The scope of a formal value parameter includes
the template $t$. However, a formal value parameter may not form 
part of the types of any of the parent classes or members of the class
template $t$.
It is illegal to define two formal value parameters with the same name.
If no formal parameter sections are given, 
an empty parameter section \lstinline@()@ is assumed.

If a formal parameter declaration $x: T$ is preceded by a \code{val}
or \code{var} keyword, an accessor (getter) definition
(\sref{sec:vardef}) for this parameter is implicitly added to the
class. The getter introduces a value member $x$ of class $c$ that is
defined as an alias of the parameter. If the introducing keyword is
\code{var}, a setter accessor \lstinline@$x$_=@ (\sref{sec:vardef}) is also
implicitly added to the class. In invocation of that setter \lstinline@$x$_=($e$)@
changes the value of the parameter to the result of evaluating $e$.
The formal parameter declaration may contain modifiers, which then
carry over to the accessor definition(s). A formal parameter prefixed
by \code{val} or \code{var} may not at the same time be a call-by-name
parameter (\sref{sec:parameters}).

\item[] 
$s$ is the {\em self type} of the class. Inside the
class, the type of \code{this} is assumed to be $s$.  The self
type must conform to the self types of all classes which are inherited
by the template $t$. The self type declaration ~\lstinline@requires $s$@~ may be
omitted, in which case the self type of the class is assumed to be
equal to \lstinline@$c$[$\tps\,$]@.
\item[] 
$t$ is a
template (\sref{sec:templates}) of the form
\begin{lstlisting}
$sc$ with $mt_1$ with $\ldots$ with $mt_m$ { $\stats$ }   $\gap(m \geq 0)$
\end{lstlisting}
which defines the base classes, behavior and initial state of objects of
the class. The extends clause ~\lstinline@extends $sc$ with $mt_1$ with $\ldots$ with $mt_m$@~ 
can be omitted, in which case
~\lstinline@extends scala.AnyRef@~ is assumed.  The class body
~\lstinline@{$\stats\,$}@~ may also be omitted, in which case the empty body
\lstinline@{}@ is assumed.
\end{itemize}
This class definition defines a type \lstinline@$c$[$\tps\,$]@ and a constructor
which when applied to parameters conforming to types $\ps$
initializes instances of type \lstinline@$c$[$\tps\,$]@ by evaluating the template
$t$.

\example The following example illustrates \code{val} and \code{var}
parameters of a class \code{C}:
\begin{lstlisting}
class C(x: int, val y: String, var z: List[String])
val c = new C(1, "abc", List())
c.z = c.y :: c.z
\end{lstlisting}

\comment{
For any index $i$ let $\csig_i$ be a class signature consisting of a class
name and optional type parameter and value parameter sections. Let $ct$
be a class template.
Then a class definition 
~\lstinline@class $\csig_1 \commadots \csig_n$ $ct$@~ 
is a shorthand for the sequence of class definitions
~\lstinline@class $\csig_1$ $ct$; ...; class $\csig_n$ $ct$@.
A class definition 
~\lstinline@class $\csig_1 \commadots \csig_n: T$ $ct$@~ 
is a shorthand for the sequence of class definitions
~\lstinline@class $\csig_1: T$ $ct$; ...; class $\csig_n: T$ $ct$@.
}

\subsection{Constructor Definitions}\label{sec:constr-defs}

\syntax\begin{lstlisting}
  FunDef         ::= this ParamClause ParamClauses `=' ConstrExpr
  ConstrExpr     ::= SelfInvocation
                  |  `{' SelfInvocation {StatementSeparator BlockStat} `}'
  SelfInvocation ::= this ArgumentExprs {ArgumentExprs}
\end{lstlisting}

A class may have additional constructors besides the primary
constructor.  These are defined by constructor definitions of the form
~\lstinline@def this($\ps_1$)$\ldots$($\ps_n$) = $e$@.  Such a
definition introduces an additional constructor for the enclosing
class, with parameters as given in the formal parameter lists $\ps_1
\commadots \ps_n$, and whose evaluation is defined by the constructor
expression $e$.  The scope of each formal parameter is the constructor
expression $e$.  A constructor expression is either a self constructor
invocation \lstinline@this($\args_1$)$\ldots$($\args_n$)@ or a block
which begins with a self constructor invocation. The self constructor
invocation must construct a generic instance of the class. I.e. if the
class in question has name $C$ and type parameters
\lstinline@[$\tps\,$]@, then a self constructor invocation must
generate an instance of \lstinline@$C$[$\tps\,$]@; it is not permitted
to instantiate formal type parameters.

The signature and the self constructor invocation of a constructor
definition are type-checked and evaluated in the scope which is in
effect at the point of the enclosing class definition, augmented by
any type parameters of the enclosing class. The rest of the
constructor expression is type-checked and evaluated as a function
body in the current class.
  
If there are auxiliary constructors of a class $C$, they form together
with $C$'s primary constructor (\sref{sec:class-defs})
an overloaded constructor
definition. The usual rules for overloading resolution
(\sref{sec:overloading-resolution}) apply for constructor invocations of $C$,
including for the self constructor invocations in the constructor
expressions themselves. However, unlike other methods, constructors
are never inherited.  To prevent infinite cycles of constructor
invocations, there is the restriction that every self constructor
invocation must refer to a constructor definition which precedes it
(i.e. it must refer to either a preceding auxiliary constructor or the
primary constructor of the class).  

\example Consider the class definition

\begin{lstlisting}
class LinkedList[a]() {
  var head = _ 
  var tail = null 
  def isEmpty = tail != null   
  def this(head: a) = { this(); this.head = head }
  def this(head: a, tail: List[a]) = { this(head); this.tail = tail }
}
\end{lstlisting}
This defines a class \code{LinkedList} with three constructors.  The
second constructor constructs an singleton list, while the
third one constructs a list with a given head and tail.

\subsection{Case Classes}
\label{sec:case-classes}

\syntax\begin{lstlisting} 
  TmplDef  ::=  case class ClassDef
\end{lstlisting}

If a class definition is prefixed with \code{case}, the class is said
to be a {\em case class}.  

The formal parameters in the first parameter section of a case class
are called {\em elements}; they treated
specially. First, the value of such a parameter can be extracted as a
field of a constructor pattern. Second, a \code{val} prefix is
implicitly added to such a parameter, unless the parameter carries
already a \code{val} or \code{var} modifier. Hence, an accessor
definition for the parameter is generated (\sref{sec:class-defs}).

A case class definition of ~\lstinline@$c$[$\tps\,$]($\ps_1\,$)$\ldots$($\ps_n$)@~ with type
parameters $\tps$ and value parameters $\ps$ implicitly
generates a function definition for a {\em case class factory}
together with the class definition itself:
\begin{lstlisting}
def c[$\tps\,$]($\ps_1\,$)$\ldots$($\ps_n$): $s$ = new $c$[$\tps\,$]($\xs_1\,$)$\ldots$($\xs_n$)
\end{lstlisting}
(Here, $s$ is the self type of class $c$ and each $\xs_i$ denotes the
parameters of $\ps_i$.  If a type parameter section is missing in the
class, it is also missing in the factory definition).

Every case class implicitly overrides some method definitions of class
\lstinline@scala.AnyRef@ (\sref{sec:cls-object}) unless a definition of the same
method is already given in the case class itself or a concrete
definition of the same method is given in some base class of the case
class different from \code{AnyRef}. In particular:
\begin{itemize}
\item[] Method ~\lstinline@equals: (Any)boolean@~ is structural equality, where two
instances are equal if they belong to the same class and
have equal (with respect to \code{equals}) elements.
\item[] Method ~\lstinline@hashCode: ()int@~ computes a hash-code
depending on the data structure in a way which maps equal (with respect to
\code{equals}) values to equal hash-codes.
\item[] Method ~\lstinline@toString: ()String@~ returns a string representation which
contains the name of the class and its elements.
\end{itemize}

\example Here is the definition of abstract syntax for lambda
calculus:

\begin{lstlisting}
class Expr 
case class Var   (x: String)          extends Expr
case class Apply (f: Expr, e: Expr)   extends Expr
case class Lambda(x: String, e: Expr) extends Expr 
\end{lstlisting}
This defines a class \code{Expr} with case classes
\code{Var}, \code{Apply} and \code{Lambda}. A call-by-value evaluator for lambda
expressions could then be written as follows.

\begin{lstlisting}
type Env = String => Value 
case class Value(e: Expr, env: Env) 

def eval(e: Expr, env: Env): Value = e match {
  case Var (x) =>
    env(x)
  case Apply(f, g) =>
    val Value(Lambda (x, e1), env1) = eval(f, env) 
    val v = eval(g, env) 
    eval (e1, (y => if (y == x) v else env1(y)))
  case Lambda(_, _) =>
    Value(e, env)
}
\end{lstlisting}

It is possible to define further case classes that extend type
\code{Expr} in other parts of the program, for instance
\begin{lstlisting}
case class Number(x: Int) extends Expr 
\end{lstlisting}

This form of extensibility can be excluded by declaring the base class
\code{Expr} \code{sealed}; in this case, all classes that
directly extend \code{Expr} must be in the same source file as
\code{Expr}.

\subsection{Traits}
\label{sec:traits}

\syntax\begin{lstlisting}
  TmplDef          ::=  trait TraitDef
  TraitDef         ::=  id [TypeParamClause]
                        [`requires' SimpleType] [extends MixinParents] 
                        [[NewLine] TemplateBody]
  MixinParents     ::=  SimpleType {`with' SimpleType}
\end{lstlisting}

A trait is a class that is meant to be added to some other class
as a mixin. Unlike normal classes, traits cannot have
constructor parameters. Furthermore, no constructor arguments are
passed to its superclass. This is not necessary as traits are
initialized after the superclass is initialized.

Assume a trait $D$ defines some aspect of an instance $x$ of
type $C$ (i.e.\ $D$ is a base class of $C$). Then the {\em actual
supertype} of $D$ in $x$ is the compound type consisting of all the
base classes in $\lin C$ that succeed $D$.  The actual supertype gives
the context for resolving a \code{super} reference in a trait
(\sref{sec:this-super}). Note that the actual supertype depends 
on the type to which the trait is added in a mixin composition; it is not
statically known at the time the trait is defined.

If $D$ is not a trait, then its actual supertype is simply its
least proper supertype (which is statically known).

\example\label{ex:comparable} The following trait defines the property
of being comparable to objects of some type. It contains an abstract
method \lstinline@<@ and default implementations of the other
comparison operators \lstinline@<=@, \lstinline@>@, and
\lstinline@>=@. 

\begin{lstlisting}
trait Comparable[t <: Comparable[t]] requires t { 
  def < (that: t): boolean
  def <=(that: t): boolean = this < that || this == that
  def > (that: t): boolean = that < this 
  def >=(that: t): boolean = that <= this
}
\end{lstlisting}

\example Consider an abstract class \code{Table} that implements maps
from a type of keys \code{A} to a type of values \code{B}. The class
has a method \code{set} to enter a new key / value pair into the table,
and a method \code{get} that returns an optional value matching a
given key. Finally, there is a method \code{apply} which is like
\code{get}, except that it returns a given default value if the table
is undefined for the given key. This class is implemented as follows.
\begin{lstlisting}
abstract class Table[A, B](defaultValue: B) {
  def get(key: A): Option[B]
  def set(key: A, value: B)
  def apply(key: A) = get(key) match {
    case Some(value) => value
    case None => defaultValue
  }
}
\end{lstlisting}
Here is a concrete implementation of the \code{Table} class.
\begin{lstlisting}
class ListTable[A, B](defaultValue: B) extends Table[A, B](defaultValue) {
  private var elems: List[Pair[A, B]]
  def get(key: A) = elems.find(._1.==(key)).map(._2)
  def set(key: A, value: B) = { elems = Pair(key, value) :: elems }
}
\end{lstlisting}
Here is a trait that prevents concurrent access to the
\code{get} and \code{set} operations of its parent class:
\begin{lstlisting}
trait SynchronizedTable[A, B] extends Table[A, B] {
  abstract override def get(key: A): B = 
    synchronized { super.get(key) }
  abstract override def set((key: A, value: B) = 
    synchronized { super.set(key, value) }
}

\end{lstlisting}
Note that \code{SynchronizedTable} does not pass an argument to
its superclass, \code{Table}, even  though \code{Table} is defined with a
formal parameter. Note also that the \code{super} calls
in \code{SynchronizedTable}'s \code{get} and \code{set} methods
statically refer to abstract methods in class \code{Table}. This is
legal, as long as the calling method is labeled 
\code{abstract override} (\sref{sec:modifiers}).

Finally, the following mixin composition creates a synchronized list table
with strings as keys and integers as values and with a default value \code{0}:
\begin{lstlisting}
object MyTable extends ListTable[String, int](0) with SynchronizedTable
\end{lstlisting}
The object \code{MyTable} inherits its \code{get} and \code{set}
method from \code{SynchronizedTable}.  The \code{super} calls in these
methods are re-bound to refer to the corresponding implementations in
\code{ListTable}, which is the actual supertype of \code{SynchronizedTable} 
in \code{MyTable}. 

\section{Object Definitions}
\label{sec:object-defs}

\syntax\begin{lstlisting}
  ObjectDef       ::=  id ClassTemplate
\end{lstlisting}

An object definition defines a single object of a new class. Its 
most general form is
~\lstinline@object $m$ extends $t$@. Here,
$m$ is the name of the object to be defined, and 
$t$ is a template (\sref{sec:templates}) of the form
\begin{lstlisting}
$sc$ with $mt_1$ with $\ldots$ with $mt_n$ { $\stats$ }
\end{lstlisting}
which defines the base classes, behavior and initial state of $m$.
The extends clause ~\lstinline@extends $sc$ with $mt_1$ with $\ldots$ with $mt_n$@~ 
can be omitted, in which case
~\lstinline@extends scala.AnyRef@~ is assumed.  The class body
~\lstinline@{$\stats\,$}@~ may also be omitted, in which case the empty body
\lstinline@{}@ is assumed.

The object definition defines a single object (or: {\em module})
conforming to the template $t$.  It is roughly equivalent to the
following three definitions, which together define a class and create
a single object of that class on demand:
\begin{lstlisting}
final class $m\Dollar$cls extends $t$ 
private var $m\Dollar$instance = null
final def m = {
  if ($m\Dollar$instance == null) $m\Dollar$instance = new m$\Dollar$cls
  $m\Dollar$instance
}
\end{lstlisting}
Here, the \code{final} modifiers are omitted if the definition occurs
as part of a block. The names ~\lstinline@$m\Dollar$cls@~ and
~\lstinline@$m\Dollar$instance@~ are inaccessible for user programs.

Note that the value defined by an object definition is instantiated
lazily.  The ~\lstinline@new $m\Dollar$cls@~ constructor is evaluated
not at the point of the object definition, but is instead evaluated
the first time $m$ is dereferenced during execution of the program
(which might be never at all). An attempt to dereference $m$ again in
the course of evaluation of the constructor leads to a infinite loop
or run-time error.  
\todo{implement: Other threads trying to dereference $m$ while the
constructor is being evaluated block until evaluation is complete.}

However, the expansion given above is not accurate for top-level
objects. It cannot be because variable and method definition cannot
appear on the top-level. Instead, top-level objects are translated to
static fields. \todo{expand}

\example
Classes in Scala do not have static members; however, an equivalent
effect can be achieved by an accompanying object definition
E.g.
\begin{lstlisting}
abstract class Point {
  val x: Double 
  val y: Double 
  def isOrigin = (x == 0.0 && y == 0.0) 
}
object Point {
  val origin = new Point() { val x = 0.0; val y = 0.0 }
}
\end{lstlisting}
This defines a class \code{Point} and an object \code{Point} which
contains \code{origin} as a member.  Note that the double use of the
name \code{Point} is legal, since the class definition defines the
name \code{Point} in the type name space, whereas the object
definition defines a name in the term namespace. 

This technique is applied by the Scala compiler when interpreting a
Java class with static members. Such a class $C$ is conceptually seen
as a pair of a Scala class that contains all instance members of $C$
and a Scala object that contains all static members of $C$.

\comment{
Let $ct$ be a class template. 
Then an object definition 
~\lstinline@object $x_1 \commadots x_n$ $ct$@~ 
is a shorthand for the sequence of object definitions
~\lstinline@object $x_1$ $ct$; ...; object $x_n$ $ct$@.
An object definition 
~\lstinline@object $x_1 \commadots x_n: T$ $ct$@~ 
is a shorthand for the sequence of object definitions
~\lstinline@object $x_1: T$ $ct$; ...; object $x_n: T$ $ct$@.
}

\comment{
\example Here's an outline of a module definition for a file system.

\begin{lstlisting}
module FileSystem {
  private type FileDirectory 
  private val dir: FileDirectory

  interface File {
    def read(xs: Array[Byte])
    def close: Unit
  }

  private class FileHandle extends File { $\ldots$ }

  def open(name: String): File = $\ldots$
}
\end{lstlisting}
}

\chapter{Expressions}
\label{sec:exprs}

\syntax\begin{lstlisting}
  Expr            ::=  [Bindings `=>'] Expr
                    |  Expr1
  Expr1           ::=  if `(' Expr `)' [NewLine] Expr [[`;'] else Expr]
                    |  try `{' block `}' [catch `{' CaseClauses `}'] 
                       [finally Expr]
                    |  while '(' Expr ')' [NewLine] Expr
                    |  do Expr [StatementSeparator] while `(' Expr ')'
                    |  for (`(' Enumerators `)' | `{' Enumerators `}') 
                       [NewLine] [yield] Expr
                    |  return [Expr]
                    |  throw Expr
                    |  [SimpleExpr `.'] id `=' Expr
                    |  SimpleExpr ArgumentExprs `=' Expr
                    |  PostfixExpr [`:' Type1]
                    |  PostfixExpr match `{' CaseClauses `}'
                    |  MethodClosure
  PostfixExpr     ::=  InfixExpr [id [NewLine]]
  InfixExpr       ::=  PrefixExpr
                    |  InfixExpr id [NewLine] PrefixExpr
  PrefixExpr      ::=  [`-' | `+' | `~' | `!'] SimpleExpr 
  SimpleExpr      ::=  Literal
                    |  null
                    |  Path
                    |  `(' [Expr] `)'
                    |  BlockExpr
                    |  new Template 
                    |  SimpleExpr `.' id 
                    |  SimpleExpr TypeArgs
                    |  SimpleExpr ArgumentExprs
                    |  XmlExpr
  ArgumentExprs   ::=  `(' [Exprs] ')'
                    |  BlockExpr
  MethodClosure   ::=  `.' id {`.' id | TypeArgs | ArgumentExprs}
  BlockExpr       ::=  `{' CaseClauses `}'
                    |  `{' Block `}'
  Block           ::=  {BlockStat StatementSeparator} [ResultExpr]
  ResultExpr      ::=  Expr1
                    |  Bindings `=>' Block
  Exprs           ::=  Expr {`,' Expr}
\end{lstlisting}

Expressions are composed of operators and operands. Expression forms are
discussed subsequently in decreasing order of precedence. 

The typing of expressions is often relative to some {\em expected
type} (which might be undefined).  
When we write ``expression $e$ is expected to conform to
type $T$'', we mean: (1) the expected type of $e$ is
$T$, and (2) the type of expression $e$ must conform to
$T$.

\section{Literals}

\syntax\begin{lstlisting}
  SimpleExpr    ::=  Literal
\end{lstlisting}

Typing of literals is as described in \sref{sec:literals}; their
evaluation is immediate.

\section{The {\em Null} Value}

The \code{null} value is of type \lstinline@scala.Null@, and is thus
compatible with every reference type.  It denotes a reference value
which refers to a special ``\lstinline@null@'' object. This object
implements the methods in class \lstinline@scala.AnyRef@ as follows:
\begin{itemize}
\item
\lstinline@eq($x\,$)@, \lstinline@==($x\,$)@, \lstinline@equals($x\,$)@ return \code{true} iff their
argument $x$ is also the ``null'' object.
\item
\lstinline@isInstanceOf[$T\,$]@ always returns \code{false}.
\item
\lstinline@asInstanceOf[$T\,$]@ returns the ``null'' object itself if
$T$ conforms to \lstinline@scala.AnyRef@, and throws a
\lstinline@NullPointerException@ otherwise.
\item
\code{toString()} returns the string ``null''.
\end{itemize}
A reference to any other member of the ``null'' object causes a
\code{NullPointerException} to be thrown. 

\section{Designators}
\label{sec:designators}

\syntax\begin{lstlisting}
  Designator  ::=  Path
                |  SimpleExpr `.' id
\end{lstlisting}

A designator refers to a named term. It can be a {\em simple name} or
a {\em selection}. If $r$ is a stable identifier
(\sref{sec:stable-ids}) of type $T$, the selection $r.x$ refers
statically to a term member $m$ of $r$ that is identified in $T$ by
the name $x$. \comment{There might be several such members, in which
case overloading resolution (\sref{overloading-resolution}) is applied
to pick a unique one.}  

For other expressions $e$, $e.x$ is typed as
if it was ~\lstinline@{ val $y$ = $e$; $y$.$x$ }@, for some fresh name
$y$.  The typing rules for blocks implies that in that case $x$'s type
may not refer to any abstract type member of $e$.

The expected type of a designator's prefix is always undefined.  The
type of a designator is the type of the entity it refers to, with the
following exception: The type of a path (\sref{sec:paths}) $p$ which
occurs as the prefix of a selection, or which has a singleton type as
expected type, is the singleton type \lstinline@$p$.type@.

The selection $e.x$ is evaluated by first evaluating the qualifier
expression $e$, which yields an object $r$, say. The selection's
result is then the member $r$ that is either defined by $m$ or defined
by a definition overriding $m$.

\section{This and Super}
\label{sec:this-super}

\syntax\begin{lstlisting}
  SimpleExpr    ::=  [id `.'] this
                  |  [id `.'] super [`[' id `]'] `.' id
\end{lstlisting}

The expression \code{this} can appear in the statement part of a
template or compound type. It stands for the object being defined by
the innermost template or compound type enclosing the reference. If
this is a compound type, the type of \code{this} is that compound type.
If it is a template of an instance creation expression, the type of
\code{this} is the type of that template. If it is a template of a
class or object definition with simple name $C$, the type of this
is the same as the type of \lstinline@$C$.this@.

The expression \lstinline@$C$.this@ is legal in the statement part of an
enclosing class or object definition with simple name $C$. It
stands for the object being defined by the innermost such definition.
If the expression's expected type is a singleton type, or
\lstinline@$C$.this@ occurs as the prefix of a selection, its type is
\lstinline@$C$.this.type@, otherwise it is the self type of class $C$.

A reference ~\lstinline@super.$m$@~ refers statically to a member $m$
in the least proper supertype of the innermost template containing the
reference.  It evaluates to the member $m'$ in the actual supertype of
that template which is equal to $m$ or which overrides $m$.  The
statically referenced member $m$ must be concrete, or the template
containing the reference must have a member $m'$ which overrides $m$
and which is labeled \code{abstract override}.  

A reference ~\lstinline@$C$.super.$m$@~ refers statically to a member
$m$ in the least proper supertype of the innermost enclosing class or
object definition named $C$ which encloses the reference. It evaluates
to the member $m'$ in the actual supertype of that class or object
which is equal to $m$ or which overrides $m$.  The statically
referenced member $m$ must be concrete, or the innermost enclosing
class or object definition named $C$ must have a member $m'$ which
overrides $m$ and which is labeled \code{abstract override}.

The \code{super} prefix may be followed by a class qualifier
\lstinline@[$C\,$]@, as in \lstinline@$C$.super[$C\,$].$x$@. This is
called a {\em static super reference}.  In this case, the reference is
to the member of $x$ in the (first) parent class of $C$ whose simple
name is $M$. That member must be concrete.

\example\label{ex:super}
Consider the following class definitions

\begin{lstlisting}
class Root { val x = "Root" }
class A extends Root { override val x = "A" ; val superA = super.x }
trait B extends Root { override val x = "B" ; val superB = super.x }
class C extends Root with B { 
  override val x = "C" ; val superC = super.x }
}
class D extends A with B {
  override val x = "D" ; val superD = super.x }
}
\end{lstlisting}
The linearization of class \code{C} is ~\lstinline@{C, B, Root}@~ and
the linearization of class \code{D} is ~\lstinline@{D, B, A, Root}@.
Then we have:
\begin{lstlisting}
(new A).superA == "Root", 
(new C).superA == "Root", (new C).superB = "Root", (new C).superC = "B",
(new D).superA == "Root", (new D).superB = "A",    (new D).superD = "B",
\end{lstlisting}
Note that the \code{superB} function returns different results
depending on whether \code{B} is mixed in with class \code{Root} or \code{A}.

\comment{
\example Consider the following class definitions:
\begin{lstlisting}
class Shape {
  override def equals(other: Any) = $\ldots$ 
  $\ldots$
}
trait Bordered extends Shape {
  val thickness: int 
  override def equals(other: Any) = other match {
    case that: Bordered => 
      super equals other && this.thickness == that.thickness
    case _ => false
  }
  $\ldots$
}
trait Colored extends Shape {
  val color: Color 
  override def equals(other: Any) = other match {
    case that: Colored => 
      super equals other && this.color == that.color
    case _ => false
  }
  $\ldots$
}
\end{lstlisting}

Both definitions of \code{equals} are combined in the class
below.
\begin{lstlisting}
trait BorderedColoredShape extends Shape with Bordered with Colored {
  override def equals(other: Any) = 
    super[Bordered].equals(that) && super[Colored].equals(that)
}
\end{lstlisting}
}

\section{Function Applications}
\label{sec:apply}

\syntax\begin{lstlisting}
  SimpleExpr    ::=  SimpleExpr ArgumentExprs
\end{lstlisting}

An application \lstinline@$f$($e_1 \commadots e_n$)@ applies the function $f$ to the
argument expressions $e_1 \commadots e_n$. If $f$ has a method type
\lstinline@($T_1 \commadots T_n$)U@, the type of each argument
expression $e_i$ must conform to the corresponding parameter type
$T_i$. If $f$ has some value type, the application is taken to be
equivalent to \lstinline@$f$.apply($e_1 \commadots e_n$)@, i.e.\ the
application of an \code{apply} method defined by $f$.

%Class constructor functions
%(\sref{sec:class-defs}) can only be applied in constructor invocations
%(\sref{sec:constr-invoke}), never in expressions.

Evaluation of \lstinline@$f$($e_1 \commadots e_n$)@ usually entails evaluation of
$f$ and $e_1 \commadots e_n$ in that order. Each argument expression
is converted to the type of its corresponding formal parameter.  After
that, the application is rewritten to the function's right hand side,
with actual arguments substituted for formal parameters.  The result
of evaluating the rewritten right-hand side is finally converted to
the function's declared result type, if one is given.

The case of a formal parameter with a parameterless
method type ~\lstinline@=>$T$@~ is treated specially. In this case, the
corresponding actual argument expression is not evaluated before the
application. Instead, every use of the formal parameter on the
right-hand side of the rewrite rule entails a re-evaluation of the
actual argument expression. In other words, the evaluation order for
\code{=>}-parameters is {\em call-by-name} whereas the evaluation
order for normal parameters is {\em call-by-value}.

\section{Type Applications}
\label{sec:type-app}
\syntax\begin{lstlisting}
  SimpleExpr    ::=  SimpleExpr `[' Types `]'
\end{lstlisting}

A type application \lstinline@$e$[$T_1 \commadots T_n$]@ instantiates a
polymorphic value $e$ of type
~\lstinline@[$a_1$ >: $L_1$ <: $U_1 \commadots a_n$ >: $L_n$ <: $U_n$]$S$@~ with
argument types \lstinline@$T_1 \commadots T_n$@.  Every argument type
$T_i$ must obey the corresponding bounds $L_i$ and
$U_i$.  That is, for each $i = 1 \commadots n$, we must
have $\sigma L_i  \conforms T_i \conforms \sigma U_i$, where $\sigma$ is the
substitution $[a_1 := T_1 \commadots a_n := T_n]$.  The type
of the application is $\sigma S$.  

If the function part $e$ is of some value type, the type application
is taken to be equivalent to 
~\lstinline@$e$.apply[$T_1 \commadots$ T$_n$]@, i.e.\ the application of an \code{apply} method defined by
$e$.

Type applications can be omitted if local type inference
(\sref{sec:local-type-inf}) can infer best type parameters for a
polymorphic functions from the types of the actual function arguments
and the expected result type.

\section{Instance Creation Expressions}
\label{sec:inst-creation}

\syntax\begin{lstlisting}
  SimpleExpr     ::=  new Template
\end{lstlisting}

A simple instance creation expression is of the form ~\lstinline@new $c$@~ 
where $c$ is a constructor invocation
(\sref{sec:constr-invoke}).  Let $T$ be the type of $c$. Then $T$ must
denote a (a type instance of) a non-abstract subclass of
\lstinline@scala.AnyRef@ which conforms to its self type
(\sref{sec:class-defs}). The expression is evaluated by creating a fresh
object of type $T$ which is is initialized by evaluating $c$. The
type of the expression is $T$.

A general instance creation expression is of the form 
~\lstinline@new $t$@~ for some template $t$ (\sref{sec:templates}).
Such an expression is equivalent to the block
\begin{lstlisting}
{ class $a$ extends $t$; new $a$ }
\end{lstlisting}
where $a$ is a fresh name of an {\em anonymous class}.

\section{Blocks}
\label{sec:blocks}

\syntax\begin{lstlisting}
  BlockExpr   ::=  `{' Block `}'
  Block       ::=  [{BlockStat StatementSeparator} ResultExpr]
\end{lstlisting}

A block expression ~\lstinline@{$s_1$; $\ldots$; $s_n$; $e\,$}@~ is
constructed from a sequence of block statements $s_1 \commadots s_n$
and a final expression $e$.  The statement sequence may not contain
two definitions or declarations that bind the same name in the same
namespace.  The final expression can be omitted, in which
case the unit value \lstinline@()@ is assumed.

%Whether or not the scope includes the statement itself
%depends on the kind of definition.

The expected type of the final expression $e$ is the expected
type of the block. The expected type of all preceding statements is
undefined.

The type of a block ~\lstinline@$s_1$; $\ldots$; $s_n$; $e$@~ is
usually the type of $e$.  That type must be equivalent to a type which
does not refer to an entity defined locally in the block. If this
condition is violated, there are two other possibilities:
\begin{enumerate}
\item
If a fully defined expected type is given, the
type of the block is instead assumed to be the expected type.
\item 
Otherwise, if the type of $e$ is an anonymous class $a$ introduced by the
expansion of an instance creation expression
(\sref{sec:inst-creation}), the type of the block is taken to be the 
least proper supertype (\sref{sec:templates}) of $a$.
\end{enumerate}
It is a compile-time error if neither of the previous two clauses applies.

Evaluation of the block entails evaluation of its
statement sequence, followed by an evaluation of the final expression
$e$, which defines the result of the block.

\example
Written in isolation, 
the block 
\begin{lstlisting}
{ class C extends B {$\ldots$} ; new C }
\end{lstlisting}
is illegal, since its type
refers to class $C$, which is defined locally in the block.

However, when used in a definition such as 
\begin{lstlisting}
val x: B = { class C extends B {$\ldots$} ; new C }
\end{lstlisting}
the block is well-formed, since the problematic type $C$ can be
replaced by the expected type $B$.

\section{Prefix, Infix, and Postfix Operations}
\label{sec:infix-operations}

\syntax\begin{lstlisting}
  PostfixExpr     ::=  InfixExpr [id]
  InfixExpr       ::=  PrefixExpr
                    |  InfixExpr id PrefixExpr
  PrefixExpr      ::=  [`-' | `+' | `!' | `~'] SimpleExpr 
\end{lstlisting}

Expressions can be constructed from operands and operators.  A prefix
operation $op;e$ consists of a prefix operator $op$, which
must be one of the identifiers `\lstinline@+@', `\lstinline@-@', `\lstinline@!@', or
`\lstinline@~@', and a simple expression $e$.  The expression is
equivalent to the postfix method application $e.op$.
\todo{Generalize to arbitrary operators}

Prefix operators are different from normal function applications in
that their operand expression need not be atomic. For instance, the
input sequence \lstinline@-sin(x)@ is read as \lstinline@-(sin(x))@, whereas the
function application \lstinline@negate sin(x)@ would be parsed as the
application of the infix operator \code{sin} to the operands
\code{negate} and \lstinline@(x)@.

An infix or postfix operator can be an arbitrary identifier. Infix
operators have precedence and associativity defined as follows:

The {\em precedence} of an infix operator is determined by the operator's first
character. Characters are listed below in increasing order of
precedence, with characters on the same line having the same precedence.
\begin{lstlisting}
        $\mbox{\rm\sl(all letters)}$
        |
        ^
        &
        < >
        = !
        :
        + -
        * / %
        $\mbox{\rm\sl(all other special characters)}$
\end{lstlisting}
That is, operators starting with a letter have lowest precedence,
followed by operators starting with `\lstinline@|@', etc.

The {\em associativity} of an operator is determined by the operator's
last character.  Operators ending with a colon `\lstinline@:@' are
right-associative. All other operators are left-associative.

Precedence and associativity of operators determine the grouping of
parts of an expression as follows.
\begin{itemize}
\item If there are several infix operations in an
expression, then operators with higher precedence bind more closely
than operators with lower precedence.
\item If there are consecutive infix
operations $e_0; \op_1; e_1; \op_2 \ldots \op_n; e_n$ 
with operators $\op_1 \commadots \op_n$ of the same precedence, 
then all these operators must
have the same associativity. If all operators are left-associative,
the sequence is interpreted as
$(\ldots(e_0;\op_1;e_1);\op_2\ldots);\op_n;e_n$. 
Otherwise, if all operators are right-associative, the
sequence is interpreted as
$e_0;\op_1;(e_1;\op_2;(\ldots \op_n;e_n)\ldots)$.
\item
Postfix operators always have lower precedence than infix
operators. E.g.\ $e_1;\op_1;e_2;\op_2$ is always equivalent to
$(e_1;\op_1;e_2);\op_2$.
\end{itemize}
A postfix operation $e;\op$ is interpreted as $e.\op$. A
left-associative binary operation $e_1;\op;e_2$ is interpreted as
$e_1.\op(e_2)$. If $\op$ is right-associative, the same operation is
interpreted as ~\lstinline@(val $x$=$e_1$; $e_2$.$\op$($x\,$))@, 
where $x$ is a fresh name.

\section{Typed Expressions}

\syntax\begin{lstlisting}
  Expr1              ::=  PostfixExpr [`:' Type1]
\end{lstlisting}

The typed expression $e: T$ has type $T$. The type of
expression $e$ is expected to conform to $T$. The result of
the expression is the value of $e$ converted to type $T$.

\example Here are examples of well-typed and illegally typed expressions.

\begin{lstlisting}
  1: int               // legal, of type int
  1: long              // legal, of type long
  // 1: string         // ***** illegal
\end{lstlisting}

\section{Method closures}
\syntax\begin{lstlisting}
  MethodClosure   ::=  `.' id {`.' id | TypeArgs | ArgumentExprs}
\end{lstlisting}

A method closure $.id$ starts with a period and an identifier, which
may be followed by selections and type- and value-arguments. This
expression is equivalent to an anonymous function
\lstinline@$x$ => $x.id$@ where $x$ is a fresh parameter name. No type
for $x$ is given; hence this type needs to be inferable from the
context of the expression.

\example The following method returns the $n$'th column of a given
list of row-lists $xss$, using methods \lstinline@map@,
\lstinline@drop@ and \lstinline@head@ defined in class
\lstinline@scala.List@.
\begin{lstlisting}
def column[T](xss: List[List[T]], n: int): List[T] = 
  xss.map(.drop(i)).map(.head)
\end{lstlisting}
 
\section{Assignments}\label{sec:assigments}

\syntax\begin{lstlisting}
  Expr1        ::=  Designator `=' Expr
                 |  SimpleExpr ArgumentExprs `=' Expr
\end{lstlisting}

The interpretation of an assignment to a simple variable ~\lstinline@$x$ = $e$@~
depends on the definition of $x$. If $x$ denotes a mutable
variable, then the assignment changes the current value of $x$ to be
the result of evaluating the expression $e$. The type of $e$ is
expected to conform to the type of $x$. If $x$ is a parameterless
function defined in some template, and the same template contains a
setter function \lstinline@$x$_=@ as member, then the assignment
~\lstinline@$x$ = $e$@~ is interpreted as the invocation
~\lstinline@$x$_=($e\,$)@~ of that setter function.  Analogously, an
assignment ~\lstinline@$f.x$ = $e$@~ to a parameterless function $x$
is interpreted as the invocation ~\lstinline@$f.x$_=($e\,$)@.

An assignment ~\lstinline@$f$($\args\,$) = $e$@~ with a function application to the
left of the ``\lstinline@=@' operator is interpreted as 
~\lstinline@$f.$update($\args$, $e\,$)@, i.e.\
the invocation of an \code{update} function defined by $f$.

\example \label{ex:imp-mat-mul}
Here is the usual imperative code for matrix multiplication.

\begin{lstlisting}
def matmul(xss: Array[Array[double]], yss: Array[Array[double]]) = {
  val zss: Array[Array[double]] = new Array(xss.length, yss.length) 
  var i = 0 
  while (i < xss.length) {
    var j = 0 
    while (j < yss(0).length) {
      var acc = 0.0 
      var k = 0 
      while (k < yss.length) {
        acc = acc + xs(i)(k) * yss(k)(j) 
        k = k + 1
      }
      zss(i)(j) = acc 
      j = j + 1
    }
    i = i + 1
  }
  zss
}
\end{lstlisting}
Desugaring the array accesses and assignments yields the following
expanded version:
\begin{lstlisting}
def matmul(xss: Array[Array[double]], yss: Array[Array[double]]) = {
  val zss: Array[Array[double]] = new Array(xss.length, yss.length) 
  var i = 0 
  while (i < xss.length) {
    var j = 0 
    while (j < yss(0).length) {
      var acc = 0.0 
      var k = 0 
      while (k < yss.length) {
        acc = acc + xss.apply(i).apply(k) * yss.apply(k).apply(j) 
        k = k + 1
      }
      zss.apply(i).update(j, acc) 
      j = j + 1
    }
    i = i + 1
  }
  zss
}
\end{lstlisting}

\section{Conditional Expressions}

\syntax\begin{lstlisting}
  Expr1          ::=  if `(' Expr `)' [NewLine] Expr [[`;'] else Expr]
\end{lstlisting}

The conditional expression ~\lstinline@if ($e_1$) $e_2$ else $e_3$@~ chooses
one of the values of $e_2$ and $e_3$, depending on the
value of $e_1$. The condition $e_1$ is expected to
conform to type \code{boolean}.  The then-part $e_2$ and the
else-part $e_3$ are both expected to conform to the expected
type of the conditional expression. The type of the conditional
expression is the least upper bound of the types of $e_1$ and
$e_2$.  A semicolon preceding the \code{else} symbol of a
conditional expression is ignored.

The conditional expression is evaluated by evaluating first
$e_1$. If this evaluates to \code{true}, the result of
evaluating $e_2$ is returned, otherwise the result of
evaluating $e_3$ is returned.

A short form of the conditional expression eliminates the
else-part. The conditional expression ~\lstinline@if ($e_1$) $e_2$@~ is
evaluated as if it was ~\lstinline@if ($e_1$) $e_2$ else ()@.  The type of
this expression is \code{unit} and the then-part
$e_2$ is also expected to conform to type \code{unit}.

\section{While Loop Expressions}

\syntax\begin{lstlisting}
  Expr1          ::=  while `(' Expr ')' Expr
\end{lstlisting}

The while loop expression ~\lstinline@while ($e_1$) $e_2$@~ is typed and
evaluated as if it was an application of ~\lstinline@whileLoop ($e_1$) ($e_2$)@~ where
the hypothetical function \code{whileLoop} is defined as follows.

\begin{lstlisting}
  def whileLoop(cond: => Boolean)(body: => Unit): Unit  =
    if (cond) { body ; while(cond)(body) } else {}
\end{lstlisting}

\comment{
\example The loop 
\begin{lstlisting}
  while (x != 0) { y = y + 1/x ; x = x - 1 }
\end{lstlisting}
Is equivalent to the application
\begin{lstlisting}
  whileLoop (x != 0) { y = y + 1/x ; x = x - 1 }
\end{lstlisting}
Note that this application will never produce a division-by-zero 
error at run-time, since the
expression ~\lstinline@(y = 1/x)@~ will be evaluated in the body of
\code{while} only if the condition parameter is false.
}

\section{Do Loop Expressions}

\syntax\begin{lstlisting}
  Expr1          ::=  do Expr [StatementSeparator] while `(' Expr ')'
\end{lstlisting}

The do loop expression ~\lstinline@do $e_1$ while ($e_2$)@~ is typed and
evaluated as if it was the expression ~\lstinline@($e_1$ ; while ($e_2$) $e_1$)@.
A semicolon preceding the \code{while} symbol of a do loop expression is ignored.

\section{For-Comprehensions}\label{sec:for-comprehensions}

\syntax\begin{lstlisting}
  Expr1          ::=  for `(' Enumerators `)' [yield] Expr
  Enumerators    ::=  Generator {StatementSeparator Enumerator}
  Enumerator     ::=  Generator 
                  |   val Pattern1 `=' Expr 
                  |   Expr
  Generator      ::=  val Pattern1 `<-' Expr
\end{lstlisting}

A comprehension ~\lstinline@for ($\enums\,$) yield $e$@~ evaluates
expression $e$ for each binding generated by the enumerators
$\enums$. An enumerator sequence always starts with a generator; this
can be followed by further generators, value definitions, or filters.
A {\em generator} ~\lstinline@val $p$ <- $e$@~ produces bindings from
an expression $e$ which is matched in some way against pattern $p$. A
{\em value definition} binds a value name (or several names in a
pattern) to the result of evaluating an expression. A {\em filter} is
an expression which restricts enumerated bindings. The precise meaning
of generators and filters is defined by translation to invocations of
four methods: \code{map}, \code{filter}, \code{flatMap}, and
\code{foreach}. These methods can be implemented in different ways for
different carrier types.  \comment{As an example, an implementation of
these methods for lists is given in \sref{cls-list}.}

The translation scheme is as follows.  In a first step, every
generator ~\lstinline@val $p$ <- $e$@, where $p$ is not irrefutable (\sref{sec:patterns})
for the type of $e$, is replaced by
\begin{lstlisting}
val $p$ <- $e$.filter { case $p$ => true; case _ => false }
\end{lstlisting}

Then, the following rules are applied repeatedly until all
comprehensions have been eliminated.
\begin{itemize}
\item
A for-comprehension 
~\lstinline@for (val $p$ <- $e\,$) yield $e'$@~ 
is translated to
~\lstinline@$e$.map { case $p$ => $e'$ }@.

\item
A for-comprehension
~\lstinline@for (val $p$ <- $e\,$) $e'$@~ 
is translated to
~\lstinline@$e$.foreach { case $p$ => $e'$ }@.

\item
A for-comprehension
\begin{lstlisting}
for (val $p$ <- $e$; val $p'$ <- $e'; \ldots$) yield $e''$ ,
\end{lstlisting}
where \lstinline@$\ldots$@ is a (possibly empty)
sequence of generators or filters,
is translated to
\begin{lstlisting}
$e$.flatmap { case $p$ => for (val $p'$ <- $e'; \ldots$) yield $e''$ } .
\end{lstlisting}
\item
A for-comprehension
\begin{lstlisting}
for (val $p$ <- $e$; val $p'$ <- $e'; \ldots$) $e''$ .
\end{lstlisting}
where \lstinline@$\ldots$@ is a (possibly empty)
sequence of generators or filters,
is translated to
\begin{lstlisting}
$e$.foreach { case $p$ => for (val $p'$ <- $e'; \ldots$) $e''$ } .
\end{lstlisting}
\item
A generator ~\lstinline@val $p$ <- $e$@~ followed by a filter $f$ is translated to
a single generator ~\lstinline@val $p$ <- $e$.filter(($x_1 \commadots x_n$) => $f\,$)@~ where
$x_1 \commadots x_n$ are the free variables of $p$.
\item
A generator ~\lstinline@val $p$ <- $e$@~ followed by a value definition 
~\lstinline@val $p'$ = $e'$@ is translated to the following generator of pairs of values, where
$x$ and $x'$ are fresh names:
\begin{lstlisting}
val Pair($p$, $p'$) <- 
  for (val $x @ p$ <- $e$) yield { val $x' @ p'$ = $e'$; Pair($x$, $x'$) }
\end{lstlisting}
\end{itemize}

\example
the following code produces all pairs of numbers
between $1$ and $n-1$ whose sums are prime.
\begin{lstlisting}
for  { val i <- range(1, n) 
       val j <- range(1, i) 
       isPrime(i+j)
} yield Pair (i, j)
\end{lstlisting}
The for-comprehension is translated to:
\begin{lstlisting}
range(1, n)
  .flatMap {
     case i => range(1, i)
       .filter { j => isPrime(i+j) }
       .map { case j => Pair(i, j) } }
\end{lstlisting}

\comment{
\example
\begin{lstlisting}
class List[a] {
  def map[b](f: (a)b): List[b] = match {
    case <> => <>
    case x :: xs => f(x) :: xs.map(f)
  }
  def filter(p: (a)Boolean) = match {
    case <> => <>
    case x :: xs => if p(x) then x :: xs.filter(p) else xs.filter(p)
  }
  def flatMap[b](f: (a)List[b]): List[b] =
    if (isEmpty) Nil
    else f(head) ::: tail.flatMap(f) 
  def foreach(f: (a)Unit): Unit =
    if (isEmpty) ()
    else (f(head); tail.foreach(f)) 
}
\end{lstlisting}

\example
\begin{lstlisting}
abstract class Graph[Node] {
  type Edge = (Node, Node)
  val nodes: List[Node]
  val edges: List[Edge]
  def succs(n: Node) = for ((p, s) <- g.edges, p == n) s
  def preds(n: Node) = for ((p, s) <- g.edges, s == n) p
}
def topsort[Node](g: Graph[Node]): List[Node] = {
  val sources = for (n <- g.nodes, g.preds(n) == <>) n
  if (g.nodes.isEmpty) <>
  else if (sources.isEmpty) new Error(``topsort of cyclic graph'') throw
  else sources :+: topsort(new Graph[Node] {
    val nodes = g.nodes diff sources
    val edges = for ((p, s) <- g.edges, !(sources contains p)) (p, s)
  })
}
\end{lstlisting}
}

\example For comprehensions can be used to express vector 
and matrix algorithms concisely. 
For instance, here is a function to compute the transpose of a given matrix:

\begin{lstlisting}
def transpose[a](xss: Array[Array[a]]) {
  for (val i <- Array.range(0, xss(0).length)) yield
    Array(for (val xs <- xss) yield xs(i))
\end{lstlisting}

Here is a function to compute the scalar product of two vectors:
\begin{lstlisting}
def scalprod(xs: Array[double], ys: Array[double]) {
  var acc = 0.0 
  for (val Pair(x, y) <- xs zip ys) acc = acc + x * y  
  acc
}
\end{lstlisting}

Finally, here is a function to compute the product of two matrices. 
Compare with the imperative version of \ref{ex:imp-mat-mul}.
\begin{lstlisting}
def matmul(xss: Array[Array[double]], yss: Array[Array[double]]) = {
  val ysst = transpose(yss) 
  for (val xs <- xs) yield
    for (val yst <- ysst) yield 
      scalprod(xs, yst)
}
\end{lstlisting}
The code above makes use of the fact that \code{map}, \code{flatmap},
\code{filter}, and \code{foreach} are defined for members of class
\lstinline@scala.Array@.

\section{Return Expressions}

\syntax\begin{lstlisting}
  Expr1      ::=  return [Expr]
\end{lstlisting}

A return expression ~\lstinline@return $e$@~ must occur inside the
body of some enclosing named method or function $f$. This function
must have an explicitly declared result type, and the type of $e$ must
conform to it. The return expression evaluates the expression $e$ and
returns its value as the result of $f$. The evaluation of any statements or
expressions following the return expression is omitted. The type of 
a return expression is \code{scala.Bottom}.



\section{Throw Expressions}

\syntax\begin{lstlisting}
  Expr1      ::=  throw Expr
\end{lstlisting}

A throw expression ~\lstinline@throw $e$@~ evaluates the expression
$e$. The type of this expression must conform to
\code{Throwable}.  If $e$ evaluates to an exception
reference, evaluation is aborted with the thrown exception. If $e$
evaluates to \code{null}, evaluation is instead aborted with a
\code{NullPointerException}. If there is an active
\code{try} expression (\sref{sec:try}) which handles the thrown
exception, evaluation resumes with the handler; otherwise the thread
executing the \code{throw} is aborted.  The type of a throw expression
is \code{scala.Bottom}.

\section{Try Expressions}\label{sec:try}

\syntax\begin{lstlisting}
  Expr1       ::=  try `{' Block `}' [catch Expr] [finally Expr]
\end{lstlisting}

A try expression ~\lstinline@try { $b$ } catch $e$@~ evaluates the block
$b$.  If evaluation of $b$ does not cause an exception to be
thrown, the result of $b$ is returned. Otherwise the {\em
handler} $e$ is applied to the thrown exception.  Let $\proto$
be the expected type of the try expression.  The block $b$ is
expected to conform to $\proto$.  The handler $e$ is expected
conform to type ~\lstinline@scala.PartialFunction[scala.Throwable, $\proto\,$]@.
The type of the try expression is the least upper bound of the type of
$b$ and the result type of $e$.

A try expression ~\lstinline@try { $b$ } finally $e$@~ evaluates the block
$b$.  If evaluation of $b$ does not cause an exception to be
thrown, the expression $e$ is evaluated. If an exception is thrown
during evaluation of $e$, the evaluation of the try expression is
aborted with the thrown exception. If no exception is thrown during
evaluation of $e$, the result of $b$ is returned as the
result of the try expression. 

If an exception is thrown during
evaluation of $b$, the finally block
$e$ is also evaluated. If another exception $e$ is thrown
during evaluation of $e$, evaluation of the try expression is
aborted with the thrown exception. If no exception is thrown during
evaluation of $e$, the original exception thrown in $b$ is
re-thrown once evaluation of $e$ has completed.  The block
$b$ is expected to conform to the expected type of the try
expression. The finally expression $e$ is expected to conform to
type \code{unit}.

A try expression ~\lstinline@try { $b$ } catch $e_1$ finally $e_2$@~ is a shorthand
for  ~\lstinline@try { try { $b$ } catch $e_1$ } finally $e_2$@.




\section{Anonymous Functions}
\label{sec:closures}

\syntax\begin{lstlisting}
  Expr1           ::=  Bindings `=>' Expr
  ResultExpr      ::=  Bindings `=>' Block
  Bindings        ::=  `(' Binding {`,' Binding `)'
                    |  id [`:' Type1]
  Binding         ::=  id [`:' Type]
\end{lstlisting}

The anonymous function ~\lstinline@($x_1$: $T_1 \commadots x_n$: $T_n$) => e@~ 
maps parameters $x_i$ of types $T_i$ to a result given
by expression $e$. The scope of each formal parameter
$x_i$ is $e$. Formal parameters must have pairwise distinct names.

If the expected type of the anonymous function is of the form
~\lstinline@scala.Function$n$[$S_1 \commadots S_n$, $R\,$]@, the
expected type of $e$ is $R$ and the type $T_i$ of any of the
parameters $x_i$ can be omitted, in which
case~\lstinline@$T_i$ = $S_i$@ is assumed.
If the expected type of the anonymous function is
some other type, all formal parameter types must be explicitly given,
and the expected type of $e$ is undefined. The type of the anonymous
function
is~\lstinline@scala.Function$n$[$S_1 \commadots S_n$, $T\,$]@,
where $T$ is the type of $e$. $T$ must be equivalent to a
type which does not refer to any of the formal parameters $x_i$.

The anonymous function is evaluated as the instance creation expression
\begin{lstlisting}
new scala.Function$n$[$T_1 \commadots T_n$, $T$] {
  def apply($x_1$: $T_1 \commadots x_n$: $T_n$): $T$ = $e$
}
\end{lstlisting}
In the case of a single formal parameter, ~\lstinline@($x$: $T\,$) => $e$@~ and ~\lstinline@($x\,$) => $e$@~ 
can be abbreviated to ~\lstinline@$x$: $T$ => e@, and ~\lstinline@$x$ => $e$@, respectively.

\example Examples of anonymous functions:

\begin{lstlisting}
  x => x                             // The identity function

  f => g => x => f(g(x))             // Curried function composition

  (x: Int,y: Int) => x + y           // A summation function

  () => { count = count + 1; count } // The function which takes an
                                     // empty parameter list $()$, 
                                     // increments a non-local variable 
                                     // `count' and returns the new value.
\end{lstlisting}

\section{Statements}
\label{sec:statements}

\syntax\begin{lstlisting}
  BlockStat    ::=  Import
                 |  Def
                 |  {LocalClassModifier} TmplDef
                 |  Expr1
                 | 
  TemplateStat ::=  Import
                 |  {AttributeClause} {Modifier} Def
                 |  {AttributeClause} {Modifier} Dcl
                 |  Expr
                 | 
\end{lstlisting}

Statements occur as parts of blocks and templates.  A statement can be
an import, a definition or an expression, or it can be empty.
Statements used in the template of a class definition can also be
declarations.  An expression that is used as a statement can have an
arbitrary value type. An expression statement $e$ is evaluated by
evaluating $e$ and discarding the result of the evaluation. 
\todo{Generalize to implicit coercion?}

Block statements may be definitions which bind local names in the
block. The only modifiers allowed in block-local definitions are modifiers
\code{abstract}, \code{final}, or \code{sealed} preceding a class or
object definition.

Evaluation of a statement sequence entails evaluation of the
statements in the order they are written.

\section{Implicit Conversions}
\label{sec:impl-conv}

Implicit conversions can be applied to expressions whose type does not
match their expected type, as well as to unapplied methods. The
available implicit conversions are given in the next two sub-sections.

We say, a type $T$ is {\em compatible} to a type $U$ if $T$ conforms
to $U$ after applying eta-expansion (\sref{sec:eta-expand}) and view applications
(\sref{sec:views}).

\subsection{Value Conversions}

The following five implicit conversions can be applied to an
expression $e$ which has some value type $T$ and which is type-checked with
some expected type $\proto$.

\paragraph{\em Overloading Resolution} 
If an expression denotes several possible members of a class, 
overloading resolution (\sref{sec:overloading-resolution})
is applied to pick a unique member.

\paragraph{\em Type Instantiation}  
An expression $e$ of polymorphic type
\begin{lstlisting}
[$a_1$ >: $L_1$ <: $U_1 \commadots a_n$ >: $L_n$ <: $U_n$]$T$
\end{lstlisting}
which does not appear as the function part of
a type application is converted to a type instance of $T$
by determining with local type inference
(\sref{sec:local-type-inf}) instance types ~\lstinline@$T_1 \commadots T_n$@~ 
for the type variables ~\lstinline@$a_1 \commadots a_n$@~ and
implicitly embedding $e$ in the type application
~\lstinline@$e$[$T_1 \commadots T_n$]@~ (\sref{sec:type-app}).

\paragraph{\em Numeric Literal Narrowing}
If the expected type is \code{byte}, \code{short} or \code{char}, and
the expression $e$ is an integer literal fitting in the range of that
type, it is converted to the same literal in that type.

\paragraph{\em Value Discarding}
If $e$ has some value type and the expected type is \code{unit},
$e$ is converted to the expected type by embedding it in the 
term ~\lstinline@{ $e$; () }@.

\paragraph{\em View Application}
If none of the previous conversions applies, and the $e$'s type
does not conform to the expected type $\proto$, it is attempted to convert
$e$ to the expected type with a view (\sref{sec:views}).\bigskip

\subsection{Method Conversions}

The following four implicit conversions can be applied to methods
which are not applied to some argument list.

\paragraph{\em Evaluation}
A parameterless method $m$ of type \lstinline@=> $T$@ is always converted to
type $T$ by evaluating the expression to which $m$ is bound.

\paragraph{\em Implicit Application}
  If the method takes only implicit parameters, implicit
  arguments are passed following the rules of \sref{sec:impl-params}.

\paragraph{\em Eta Expansion}
  Otherwise, if the method is not a constructor, 
  and the expected type $\proto$ is a function type
  $(\Ts') \Arrow T'$ eta-expansion
  (\sref{sec:eta-expand}) is performed on the
  expression $e$.

\paragraph{\em Empty Application}
  Otherwise, if $e$ has method type $()T$ where $T$ is compatible with
  $\proto$, it is implicitly applied to the empty
  argument list, yielding $e()$.


\subsection{Overloading Resolution}
\label{sec:overloading-resolution}

If an identifier or selection $e$ references several members of a
class, the context of the reference is used to identify a unique
member.  The way this is done depends on whether or not $e$ is used as
a function.  Let $\AA$ be the set of members referenced by $e$.

Assume first that $e$ appears as a function in an application, as
in \lstinline@$e$($\args\,$)@.  If there is precisely one alternative in
$\AA$ which is a (possibly polymorphic) method type whose arity
matches the number of arguments given, that alternative is chosen.

Otherwise, let $\argtypes$ be the vector of types obtained by
typing each argument with an undefined expected type. One determines
first the set of applicable alternatives. A method type alternative is
{\em applicable} if each type in $\argtypes$ is compatible with
the corresponding formal parameter type in the alternative, and, if 
the expected type is defined, the method's result type is compatible to
it.  A polymorphic method type is applicable if local type inference
can determine type arguments so that the instantiated method type is
applicable.

Let $\BB$ be the set of applicable alternatives. It is an error if
$\BB$ is empty. Otherwise, one chooses the {\em most specific}
alternative among the alternatives in $\BB$, according to the
following definition of being ``more specific''.
\begin{itemize} 
\item
A method type \lstinline@($\Ts\,$)$U$@ is more specific than some other
type $S$ if $S$ is applicable to arguments \lstinline@($\ps\,$)@ of
types $\Ts$.
\item
A polymorphic method type
~\lstinline@[$a_1$ >: $L_1$ <: $U_1 \commadots a_n$ >: $L_n$ <: $U_n$]T@~ is
more specific than some other type $S$ if $T$ is more
specific than $S$ under the assumption that for
$i = 1 \commadots n$ each $a_i$ is an abstract type name
bounded from below by $L_i$ and from above by $U_i$.
\item
Any other type is always more specific than a parameterized method
type or a polymorphic type.
\end{itemize}
It is an error if there is no unique alternative in $\BB$ which is
more specific than all other alternatives in $\BB$.

Assume next that $e$ appears as a function in a type application, as
in \lstinline@$e$[$\targs\,$]@. Then we choose all alternatives in
$\AA$ which take the same number of type parameters as there are type
arguments in $\targs$. It is an error if no such alternative exists.
If there are several such alternatives overloading resolution is
applied again to the whole expression \lstinline@$e$[$\targs\,$]@.  

Assume finally that $e$ does not appear as a function in either
an application or a type application. If an expected type is given,
let $\BB$ be the set of those alternatives in $\AA$ which are
compatible (\sref{sec:impl-conv}) to it. Otherwise, let $\BB$ be the same as $\AA$.
We choose in this case the most specific alternative among all
alternatives in $\BB$. It is an error if there is no unique
alternative in $\BB$ which is more specific than all other
alternatives in $\BB$.

\example Consider the following definitions:

\begin{lstlisting}
  class A extends B {}
  def f(x: B, y: B) = $\ldots$
  def f(x: A, y: B) = $\ldots$
  val a: A 
  val b: B
\end{lstlisting}
Then the application \lstinline@f(b, b)@ refers to the first
definition of $f$ whereas the application \lstinline@f(a, a)@
refers to the second.  Assume now we add a third overloaded definition
\begin{lstlisting}
  def f(x: B, y: A) = $\ldots$
\end{lstlisting}
Then the application \lstinline@f(a, a)@ is rejected for being ambiguous, since
no most specific applicable signature exists.

\subsection{Local Type Inference}
\label{sec:local-type-inf}

Local type inference infers type arguments to be passed to expressions
of polymorphic type. Say $e$ is of type [$a_1$ >: $L_1$ <: $U_1
\commadots a_n$ >: $L_n$ <: $U_n$]$T$ and no explicit type parameters
are given. 

Local type inference converts this expression to a type
application ~\lstinline@$e$[$T_1 \commadots T_n$]@. The choice of the
type arguments $T_1 \commadots T_n$ depends on the context in which
the expression appears and on the expected type $\proto$. 
There are three cases.

\paragraph{\em Case 1: Selections}
If the expression appears as the prefix of a selection with a name
$x$, then type inference is {\em deferred} to the whole expression
$e.x$. That is, if $e.x$ has type $S$, it is now treated as having
type [$a_1$ >: $L_1$ <: $U_1 \commadots a_n$ >: $L_n$ <: $U_n$]$S$,
and local type inference is applied in turn to infer type arguments 
for $a_1 \commadots a_n$, using the context in which $e.x$ appears.

\paragraph{\em Case 2: Values}
If the expression $e$ appears as a value without being applied to
value arguments, the type arguments are inferred by solving a
constraint system which relates the expression's type $T$ with the
expected type $\proto$. Without loss of generality we can assume that
$T$ is a value type; if it is a method type we apply eta-expansion
(\sref{sec:eta-expand}) to convert it to a function type.  Solving
means finding a substitution $\sigma$ of types $T_i$ for the type
parameters $a_i$ such that
\begin{itemize}
\item 
All type parameter bounds are respected, i.e.\ 
$\sigma L_i <: \sigma a_i$ and $\sigma a_i <: \sigma U_i$ for $i = 1 \commadots n$.
\item 
The expression's type conforms to the expected type, i.e.\ 
$\sigma T <: \sigma \proto$.
\end{itemize}
It is a compile time error if no such substitution exists.  
If several substitutions exist, local-type inference will choose for
each type variable $a_i$ a minimal or maximal type $T_i$ of the
solution space.  A {\em maximal} type $T_i$ will be chosen if the type
parameter $a_i$ appears contravariantly (\sref{sec:variances}) in the
type $T$ of the expression.  A {\em minimal} type $T_i$ will be chosen
in all other situations, i.e. if the variable appears covariantly,
non-variantly or not at all in the type $T$. We call such a substitution
an {\em optimal solution} of the given constraint system for the type $T$.

\paragraph{\em Case 3: Methods} The last case applies if the expression
$e$ appears in an application $e(d_1 \commadots d_m)$. In that case
$T$ is a method type $(R_1 \commadots R_m)T'$. Without loss of
generality we can assume that the result type $T'$ is a value type; if
it is a method type we apply eta-expansion (\sref{sec:eta-expand}) to
convert it to a function type.  One computes first the types $S_j$ of
the argument expressions $d_j$, using two alternative schemes.  Each
argument expression $d_j$ is typed first with the expected type $R_j$,
in which the type parameters $a_1 \commadots a_n$ are taken as type
constants.  If this fails, the argument $d_j$ is typed instead with an
expected type $R_j'$ which results from $R_j$ by replacing every type
parameter in $a_1 \commadots a_n$ with {\sl undefined}.

In a second step, type arguments are inferred by solving a constraint
system which relates the method's type with the expected type
$\proto$ and the argument types $S_1 \commadots S_m$. Solving the
constraint system means
finding a substitution $\sigma$ of types $T_i$ for the type parameters
$a_i$ such that
\begin{itemize}
\item 
All type parameter bounds are respected, i.e.\ 
$\sigma L_i <: \sigma a_i$ and $\sigma a_i <: \sigma U_i$ for $i = 1 \commadots n$.
\item 
The method's result type $T'$ conforms to the expected type, i.e.\ 
$\sigma T' <: \sigma \proto$.
\item
Each argument type conforms to the corresponding formal parameter
type, i.e.\ 
$\sigma S_j <: \sigma R_j$ for $j = 1 \commadots m$.
\end{itemize}
It is a compile time error if no such substitution exists.  If several
solutions exist, an optimal one for the type $T'$ is chosen.

All or parts of an expected type $\proto$ may be undefined. The rules for
conformance (\sref{sec:conformance}) are extended to this case by adding
the rule that for any type $T$ the following two statements are always
true:
\[
   \mbox{\sl undefined} <: T \tab\mbox{and}\tab T <: \mbox{\sl undefined} .
\]

It is possible that no minimal or maximal solution for a type variable
exists, in which case a compile-time error results. Because $<:$ is a
pre-order, it is also possible that a solution set has several optimal
solutions for a type. In that case, a Scala compiler is free to pick
any one of them.

\example Consider the two methods:
\begin{lstlisting}
def cons[a](x: a, xs: List[a]): List[a] = x :: xs
def nil[b]: List[b] = Nil
\end{lstlisting}
and the definition
\begin{lstlisting}
val xs = cons(1, nil) .
\end{lstlisting}
The application of \code{cons} is typed with an undefined expected
type. This application is completed by local type inference to 
~\lstinline@cons[int](1, nil)@. 
Here, one uses the following
reasoning to infer the type argument \lstinline@int@ for the type
parameter \code{a}:

First, the argument expressions are typed. The first argument \code{1}
has type \code{int} whereas the second argument \lstinline@nil@ is
itself polymorphic. One tries to type-check \lstinline@nil@ with an
expected type \code{List[a]}. This leads to the constraint system
\begin{lstlisting}
List[b?] <: List[a]
\end{lstlisting}
where we have labeled \lstinline@b?@ with a question mark to indicate
that it is a variable in the constraint system.
Because class \lstinline@List@ is covariant, the optimal
solution of this constraint is
\begin{lstlisting}
b = scala.Bottom .
\end{lstlisting}

In a second step, one solves the following constraint system for
the type parameter \code{a} of \code{cons}:
\begin{lstlisting}
int <: a?
List[scala.Bottom] <: List[a?]
List[a?] <: $\mbox{\sl undefined}$
\end{lstlisting}
The optimal solution of this constraint system is
\begin{lstlisting}
a = int ,
\end{lstlisting}
so \code{int} is the type inferred for \code{a}.

\example Consider now the definition  
\begin{lstlisting}
val ys = cons("abc", xs)
\end{lstlisting}
where \code{xs} is defined of type \code{List[int]} as before.
In this case local type inference proceeds as follows.

First, the argument expressions are typed. The first argument
\code{"abc"} has type \code{String}. The second argument \code{xs} is
first tried to be typed with expected type \code{List[a]}. This fails,
as \code{List[int]} is not a subtype of \code{List[a]}. Therefore, 
the second strategy is tried; \code{xs} is now typed with expected type
\lstinline@List[$\mbox{\sl undefined}$]@. This succeeds and yields the argument type
\code{List[int]}.

In a second step, one solves the following constraint system for
the type parameter \code{a} of \code{cons}:
\begin{lstlisting}
String <: a?
List[int] <: List[a?]
List[a?] <: $\mbox{\sl undefined}$
\end{lstlisting}
The optimal solution of this constraint system is
\begin{lstlisting}
a = scala.Any ,
\end{lstlisting}
so \code{scala.Any} is the type inferred for \code{a}.

\subsection{Eta Expansion}\label{sec:eta-expand}

  {\em Eta-expansion} converts an expression of method type to an
  equivalent expression of function type. It proceeds in two steps.

  First, one identifes the maximal sub-expressions of $e$; let's
  say these are $e_1 \commadots e_m$. For each of these, one creates a
  fresh name $x_i$. Let $e'$ be the expression resulting from
  replacing every maximal subexpression $e_i$ in $e$ by the
  corresponding fresh name $x_i$. Second, one creates a fresh name $y_i$
  for every argument type $T_i$ of the method ($i = 1 \commadots
  n$). The result of eta-conversion is then:
\begin{lstlisting}
  { val $x_1$ = $e_1$; 
    $\ldots$ 
    val $x_m$ = $e_m$; 
    ($y_1: T_1 \commadots y_n: T_n$) => $e'$($y_1 \commadots y_n$) 
  }
\end{lstlisting}

Eta expansion is not applicable to methods with call-by-name
parameters ~\lstinline@$x$: => $T$@~ or repeated parameters
~\lstinline@x: T*@ (\sref{sec:parameters}), because its result type
would not be expressible as a function type. Hence, methods with such
parameters always need to be applied to arguments immediately.


\chapter{Implicit Parameters and Views}\label{sec:implicits}

\section{The Implicit Modifier}\label{sec:impl-defs}

\syntax\begin{lstlisting}
  Modifier     ::= implicit
  ParamClauses ::= {[NewLine] `(' [Param {`,' Param}] ')'} 
                   [[NewLine] `(' implicit Param {`,' Param} `)']
\end{lstlisting}

Template members and parameters labeled with an \code{implicit}
modifier can be passed to implicit parameters (\sref{sec:impl-params})
and can be used as implicit conversions called views (\sref{sec:views}).

\example\label{ex:impl-monoid}
The following code defines an abstract class of monoids and
two concrete implementations, \code{StringMonoid} and
\code{IntMonoid}. The two implementations are marked implicit.

\begin{lstlisting}
abstract class Monoid[a] extends SemiGroup[a] {
  def unit: a
}
implicit object StringMonoid extends Monoid[String] {
  def add(x: String, y: String): String = x.concat(y)
  def unit: String = ""
}

implicit object IntMonoid extends Monoid[int] {
  def add(x: Int, y: Int): Int = x + y
  def unit: Int = 0
}
\end{lstlisting}

\section{Implicit Parameters}\label{sec:impl-params}

An implicit parameter list
~\lstinline@(implicit $p_1$,$\ldots$,$p_n$)@~ marks the parameters $p_1 \commadots p_n$ as
implicit. A method or constructor can have only one implicit parameter
list, and it must be the last parameter list given.

A method with implicit parameters can be applied to arguments just
like a normal method. In this case the \code{implicit} label has no
effect. However, if such a method misses arguments for its implicit
parameters, such arguments will be automatically provided.

The actual arguments that are eligible to be passed to an implicit
parameter fall into two categories: First, eligible are all
identifiers $x$ that can be accessed at the point of the method call
without a prefix and that denote an implicit definition
(\sref{sec:impl-defs}) or an implicit parameter. An eligible
identifier may thus be a local name, or a member of an enclosing
template, or it may be have been made accessible without a prefix
through an import clause (\sref{sec:import}). Second, eligible are
also all members of companion modules of the implicit parameter's type
that are labeled \code{implicit}.

Here, the {\em companion module} of a class is an object which has the
same name as the class and is defined in the same scope and
compilation unit.  The set of companion modules of a
non-function type $T$ consists of all companion modules of $T$'s base
classes
\sref{sec:base-classes-member-defs}. The set of companion modules of 
a function type  ~\lstinline~($T_1$ \commadots $T_n$) => $S$~ is the set of 
companion modules of  ~\lstinline@$T_1$ with $\ldots$ $T_n$ with $S$@.  

If there are several eligible arguments which match the implicit
parameter's type, a most specific one will be chosen using the rules
of static overloading resolution (\sref{sec:overloading-resolution}).

\example Assuming the classes from \ref{ex:impl-monoid}, here is a 
method which computes the sum of a list of elements using the
monoid's \code{add} and \code{unit} operations.
\begin{lstlisting}
def sum[a](xs: List)(implicit m: Monoid[a]): a = 
  if (xs.isEmpty) m.unit
  else m.add(xs.head, sum(xs.tail))
\end{lstlisting}
The monoid in question is marked as an implicit parameter, and can therefore
be inferred based on the type of the list.
Consider for instance the call 
\begin{lstlisting}
  sum(List(1, 2, 3))
\end{lstlisting}
in a context where \lstinline@stringMonoid@ and \lstinline@intMonoid@
are visible.  We know that the formal type parameter \lstinline@a@ of
\lstinline@sum@ needs to be instantiated to \lstinline@Int@. The only
eligible object which matches the implicit formal parameter type
\lstinline@Monoid[Int]@ is \lstinline@intMonoid@ so this object will
be passed as implicit parameter.\bigskip

This discussion also shows that implicit parameters are inferred after
any type arguments are inferred (\sref{sec:local-type-inf}). 

Implicit methods can themselves have implicit parameters. An example
is the following method from module \code{scala.List}, which injects
lists into the \lstinline@scala.Ordered@ class, provided the element
type of the list is also convertible to this type.
\begin{lstlisting}
implicit def list2ordered[a](x: List[a])
  (implicit elem2ordered: a => Ordered[a]): Ordered[List[a]] = 
  ...
\end{lstlisting}
Assume in addition a method
\begin{lstlisting}
implicit def int2ordered(x: int): Ordered[int]
\end{lstlisting}
that injects integers into the \lstinline@Ordered@ class.  We can now
define a \code{sort} method over ordered lists:
\begin{lstlisting}
sort(xs: List[a])(implicit a2ordered: a => Ordered[a]) = ...
\end{lstlisting}
We can apply \code{sort} to a list of lists of integers ~\lstinline@yss: List[List[int]]@~ 
as follows:
\begin{lstlisting}
sort(yss)
\end{lstlisting}
The call above will be completed by passing two nested implicit arguments:
\begin{lstlisting}
sort(yss)(xs: List[int] => list2ordered[int](xs)(int2ordered)) .
\end{lstlisting}
The possibility of passing implicit arguments to implicit arguments
raises the possibility of an infinite recursion.  For instance, one
might try to define the following method, which injects {\em every} type into the \lstinline@Ordered@ class:
\begin{lstlisting}
def magic[a](x: a)(implicit a2ordered: a => Ordered[a]): Ordered[a] = 
  a2ordered(x)
\end{lstlisting}
Now, if we applied \lstinline@sort@ to an argument \code{arg} of a type that did not have
another injection into the ordered class, one would obtain an infinite expansion:
\begin{lstlisting}
sort(arg)(x => magic(x)(x => magic(x)(x => ... )))
\end{lstlisting}
To prevent such infinite expansions, we require that every implicit 
method definition is contractive.

A method definition is {\em contractive} if the type of every implicit
parameter type is properly contained in the type that is obtained by
removing all implicit parameters from the method type and converting
the rest to a function type.

A type $T$ is {\em contained} in a type $U$ if one of the following holds:
\begin{itemize}
\item $T$ is the same as some part of $U$,  
\item $U$ is a function type and $T$ is not.
\item $U$ and $T$ are both function types, and the arity of $U$ is greater than 
      the arity of $T$.
\item $U$ and $T$ both parameterized types (including function types)
      with the same type constructor,
      and each type argument of $T$ is contained in the corresponding type argument of $U$.
\end{itemize}
A type $T$ is {\em properly contained} in a type $U$ if $T$ is contained
in $U$ and different from $U$.

\example The type of \code{list2ordered} is
\begin{lstlisting}
  (List[a])(implicit a => Ordered[a]): Ordered[List[a]] .
\end{lstlisting}
This type is contractive, because the type of the implicit parameter,
~\lstinline@a => Ordered[a]@, is properly contained in the function type
of the method without implicit parameters, ~\lstinline@List[a] => Ordered[List[a]]@.

The type of \code{magic} is
\begin{lstlisting}
  (a)(implicit a => Ordered[a]): Ordered[a] .
\end{lstlisting}
This type is not contractive, because the type of the implicit parameter,
~\lstinline@a => Ordered[a]@, is the same as the function type
of the method without implicit parameters. 


\section{Views}\label{sec:views}

Implicit parameters and methods can also define implicit conversions
called views. A {\em view} from type $S$ to type $T$ is
defined by an implicit value which has function type
\lstinline@$S$=>$T$@, or by a method convertible to a value of that type.

Views are applied in two situations.
\begin{enumerate}
\item
If an expression $e$ is of type $T$, and $T$ does not conform to the expression's
expected type $\proto$.
In this case, a view $v$ is searched which is applicable to $e$
and whose result type conforms to $\proto$.  The view must be
denotable by a single identifier at the point of the application, or
else it must be a member of some companion module of the type $T \Rightarrow \proto$. 
If such a view is found, the expression $e$ is
converted to \lstinline@$v$($e$)@.
\item
In a selection $e.m$ with $e$ of type $T$, if the selector $m$ does not
denote a member of $T$.
In thus case, a view $v$ is searched which is applicable to $e$
and whose result contains a member named $m$.  The view must be
denotable by a single identifier at the point of the application, or
else it must be a member of some companion module of the type $T$
If such a view is found, the selection $e.m$ is
converted to \lstinline@$v$($e$).$m$@. 
\end{enumerate}
As for implicit parameters, overloading resolution is applied
if there are several possible candidates.

\example\label{ex:impl-ordered} Class \lstinline@scala.Ordered[a]@ contains a method
\begin{lstlisting}
  def <= [b >: a](that: b)(implicit b2ordered: b => Ordered[b]): boolean .
\end{lstlisting}
Assume two lists \code{xs} and \code{ys} of type \code{List[int]}
and assume that the \code{list2ordered} and \code{int2ordered}
methods defined in \sref{sec:impl-params} are in scope.
Then the operation
\begin{lstlisting}
  xs <= ys
\end{lstlisting}
is legal, and is expanded to:
\begin{lstlisting}
  list2ordered(xs)(int2ordered).<=
    (ys)
    (xs => list2ordered(xs)(int2ordered))
\end{lstlisting}
The first application of \lstinline@list2ordered@ converts the list
\code{xs} to an instance of class \code{Ordered}, whereas the second 
occurrence is part of an implicit parameter passed to the \code{<=} method.

\section{View Bounds}\label{sec:view-bounds}

\syntax\begin{lstlisting}
  TypeParam       ::=  id [>: Type] [<: Type] [<% Type]
\end{lstlisting}

A type parameter $a$ may have a view bound
\lstinline@$a$ <% $T$@. In this case the type parameter may be
instantiated to any type $S$ which is convertible by application of a
view to the bound $T$.

A method or class containing such a type parameter is treated as being
equivalent to a
method with a view parameter. E.g.
\begin{lstlisting}
def $f$[$a$ <% $T$]($\ps$): $R$ = ...
\end{lstlisting}
is expanded to 
\begin{lstlisting}
def $f$[$a$]($\ps$)(implicit $v$: $a$ => $T$): $R$ = ...
\end{lstlisting}
where $v$ is a fresh name for the implicit parameter.

\example The \code{<=} method mentioned in \ref{ex:impl-ordered} can be declared
more concisely as follows:
\begin{lstlisting}
  def <= [b >: a <% Ordered[b]](that: b): boolean
\end{lstlisting}

\chapter{Pattern Matching}

\section{Patterns}

\label{sec:patterns}

\syntax\begin{verbatim}
  Pattern         ::=  Pattern1 { `|' Pattern1 }
  Pattern1        ::=  varid `:' Type1
                    |  `_' `:' Type1
                    |  Pattern2
  Pattern2        ::=  varid [`@' Pattern3]
                    |  Pattern3
  Pattern3        ::=  SimplePattern 
                    |  SimplePattern {id SimplePattern}
  SimplePattern   ::=  `_'
                    |  varid
                    |  Literal
                    |  null
                    |  StableId [ `(' [Patterns] `)' ]
                    |  `(' [Pattern] `)'
                    |  XmlPattern
  Patterns        ::=  Pattern [`,' Patterns]
                    |  `_' `*'
\end{verbatim}

%For clarity, this section deals with a subset of the Scala pattern language.
%The extended Scala pattern language, which is described below, adds more
%flexible variable binding and regular hedge expressions.

A pattern is built from constants, constructors, variables and type
tests. Pattern matching tests whether a given value (or sequence of values)
has the shape defined by a pattern, and, if it does, binds the
variables in the pattern to the corresponding components of the value
(or sequence of values).  The same variable name may not be bound more
than once in a pattern.

Pattern matching is always done in a context which supplies an
expected type of the pattern. We distinguish the following kinds of
patterns.

A {\em variable pattern} $x$ is a simple identifier which starts with
a lower case letter.  It matches any value, and binds the variable
name to that value.  The type of $x$ is the expected type of the
pattern as given from outside.  A special case is the wild-card
pattern $\_$ which is treated as if it was a fresh variable.

A {\em typed pattern} $x: T$ consists of a pattern variable $x$ and a
type $T$. The type $T$ may be a class type or a compound type; it may
not contain a refinement (\sref{sec:refinements}).  This pattern
matches any value which is an instance of the erasure
(\sref{sec:erasure}) of $T$ and binds the variable name to that value.
$T$ must conform to the pattern's expected type. The type of $x$ is
$T$.

A {\em pattern literal} $l$ matches any value that is equal (in terms
of $==$) to it. Its type must conform to the expected type of the
pattern. 

A {\em named pattern constant} $r$ is a stable identifier
(\sref{sec:stable-ids}). To resolve the syntactic overlap with a
variable pattern, a named pattern constant may not be a simple name
starting with a lower-case letter. The type of $r$ must conform
to the expected type of the pattern. The pattern matches any value $v$
such that ~\lstinline@$r$ == $v$@~ (\sref{sec:cls-object}).

A {\em constructor pattern} $c(p_1 \commadots p_n)$ where $n \geq 0$
consists of an identifier $c$, followed by element patterns $p_1
\commadots p_n$. The constructor $c$ is a simple or qualified name
which denotes a case class (\sref{sec:case-classes}). If the case
class is monomorphic, then it must conform to the expected type of the
pattern, and the formal parameter types of $x$'s primary constructor
(\sref{sec:class-defs}) are taken as the expected types of the element
patterns $p_1\commadots p_n$.  If the case class is polymorphic, then
its type parameters are instantiated so that the instantiation of $c$
conforms to the expected type of the pattern. The instantiated formal
parameter types of $c$'s primary constructor are then taken as the
expected types of the component patterns $p_1\commadots p_n$.  The
pattern matches all objects created from constructor invocations
$c(v_1)\ldots(v_n)$ where each element pattern $p_i$ matches the
corresponding value $v_i$.

A {\em sequence pattern} $s(p_1 \commadots p_n)$ where $n \geq 0$
consists of an identifier $s$, followed by element patterns $p_1
\commadots p_n$. The last element pattern may also be a {\em sequence wildcard}
\code{_*}. The constructor $s$ is a simple or qualified name
which denotes some subclass of class \code{scala.Seq}. So as to
disambiguate sequence patterns from constructor patterns, $s$ is not
permitted to denote a case class. The expected type of the sequence
pattern must itself conform to some type instance
~\lstinline@scala.Seq[$T$]@~ of the sequence class.  Each element
pattern $p_i$ is type-checked with $T$ as expected type, unless it is
a sequence wildcard. If a final sequence wildcard is present, the
pattern matches all values $v$ that are sequences of class $s$ which
start with elements matching patterns $p_1 \commadots p_{n-1}$.  If no
final sequence wildcard is given, the pattern matches all values $v$
that are sequences of class $s$ and of length $n$ which consist of
elements matching patterns $p_1 \commadots p_n$.

An {\em infix operation pattern} ~\lstinline@p id p'@~ is a shorthand for the
constructor pattern ~\lstinline@id_class(p, p')@~.  The precedence and
associativity of operators in patterns is the same as in expressions
(\sref{sec:infix-operations}).

A {\em pattern alternative} ~\lstinline@$p_1$ | $\ldots$ | $p_n$@~
consists of a number of alternative patterns $p_i$. All alternative
patterns are type checked with the epxected type of the pattern. They
may no bind variables other than wildcards. The alternative pattern 
matches a value $v$ if at least one its alternatives matches $v$.

{\em XML patterns} are treated in \sref{sec:xml-pats}.

\example Some examples of patterns are:
\begin{enumerate}
\item
The pattern ~\lstinline@ex: IOException@ matches all instances of class
\lstinline@IOException@, binding variable \verb@ex@ to the instance.
\item
The pattern ~\lstinline@(x, _)@~ matches pairs of values, binding \lstinline@x@ to
the first component of the pair. The second component is matched
with a wildcard pattern.
\item
The pattern ~\lstinline@x :: y :: xs@~ matches lists of length $\geq 2$,
binding \lstinline@x@ to the list's first element, \lstinline@y@ to the list's
second element, and \lstinline@xs@ to the remainder.
\item
The pattern ~\lstinline@1 | 2 | 3@~ matches the integers between 1 and 3.
\end{enumerate}

A pattern $p$ is {\em irrefutable} for a type $T$, if one of the following applies:
\begin{enumerate}
\item $p$ is a variable pattern,
\item $p$ is a typed pattern $x: T'$, and $T <: T'$,
\item $p$ is a constructor pattern $c(p_1 \commadots p_n)$, the type $T$
      is an instance of class $c$, the primary constructor
      (\sref{sec:class-defs}) of type $T$ has
      argument types $T_1 \commadots T_n$, and each $p_i$ is irrefutable for $T_i$.
\end{enumerate}

%%% new patterns

\subsection{Regular Pattern Matching}\label{sec:reg-pats}

Regular expression patterns are currently unimplemented in Scala  version 2.0.

\comment{
\syntax\begin{lstlisting}
  Pattern         ::=  Pattern1 { `|' Pattern1 }
  Pattern1        ::=  varid `:' Type
                    |  `_' `:' Type
                    |  Pattern2
  Pattern2        ::=  [varid `@'] Pattern3
  Pattern3        ::=  SimplePattern [ '*' | '?' | '+' ]
                    |  SimplePattern { id' SimplePattern }
  SimplePattern   ::=  `_'
                    |  varid
                    |  Literal
                    |  null
                    |  StableId [ `(' [Patterns] `)' ]
                    |  `(' [Patterns] `)'
  Patterns        ::=  Pattern {`,' Pattern}
  id'             ::=  id $\textit{ but not }$ '*' | '?' | '+' | `@' | `|'
\end{lstlisting}

We distinguish between tree patterns and hedge patterns (hedges 
are ordered sequences of trees). A {\em tree pattern} describes 
a set of matching trees (like above). A {\em hedge pattern} describes 
a set of matching hedges. Both kinds of patterns may contain {\em 
variable bindings} which serve to extract constituents of a tree or hedge.

The type of a patterns and the expected types of variables 
within patterns are determined by the context and the structure of the
patterns. The last case ensures that a variable bound 
to a hedge pattern will have a sequence type.

The following patterns are added:

A {\em hedge pattern} $p_1 \commadots p_n$ where $n \geq 0$ is a
sequence of patterns separated by commas and matching the hedge described
by the components. Hedge patterns may appear as arguments to constructor 
applications, or nested within another hedge pattern if grouped with
parentheses. Note that empty hedge patterns are allowed. The type of tree 
patterns that appear in a hedge pattern is the expected type as 
determined from the enclosing constructor.
A {\em fixed-length argument pattern} is a special hedge pattern where 
where all $p_i$ are tree patterns.

A {\em choice pattern} $p_1 | \ldots | p_n$ is a choice among several
alternatives, which may not contain variable-binding patterns. It
matches every tree and every hedge matched by at least one of its 
alternatives.  Note that the empty sequence may appear as an alternative.  
An {\em option pattern} $p?$ is an abbreviation for $(p| )$. A choice is 
a tree pattern if all its branches are tree patterns. In this case, all 
branches must conform to the expected type and the type 
of the choice is the least upper bound of the branches. Otherwise, 
its type is determined by the enclosing hedge pattern it is part of.

An {\em iterated pattern} $p*$ matches zero, one or more occurrences 
of items matched by $p$, where $p$ may be either a tree pattern or a hedge pattern. $p$ may not 
contain a variable-binding. A {\em non-empty iterated pattern} $p+$ is an 
abbreviation for $(p,p*)$. 

The treatment of the following patterns changes with to the 
previous section:

A {\em constructor pattern} $c(p)$ consists of a simple type $c$
followed by a pattern $p$.  If $c$ designates a monomorphic case
class, then it must conform to the expected type of the pattern, the
pattern must be a fixed length argument pattern $p_1 \commadots p_n$
whose length corresponds to the number of arguments of $c$'s primary
constructor. The expected types of the component patterns are then
taken from the formal parameter types of (said) constructor.  If $c$
designates a polymorphic case class, then there must be a unique type
application instance of it such that the instantiation of $c$ conforms
to the expected type of the pattern. The instantiated formal parameter
types of $c$'s primary constructor are then taken as the expected
types of the component patterns $p_1\commadots p_n$.  In both cases,
the pattern matches all objects created from constructor invocations
$c(v_1 \commadots v_n)$ where each component pattern $p_i$ matches the
corresponding value $v_i$. If $c$ does not designate a case class, it
must be a subclass of \lstinline@Seq[$T\,$]@. In that case $p$ may be an
arbitrary sequence pattern. Value patterns in $p$ are expected to conform to
type $T$, and the pattern matches all objects whose \lstinline@elements()@
method returns a sequence that matches $p$.

The pattern $(p)$ is regarded as equivalent to the pattern $p$, if $p$
is a nonempty sequence pattern. The empty tuple $()$ is a shorthand
for the constructor pattern \code{Unit}.

A {\em variable-binding} $x @ p$ is a simple identifier $x$
which starts with a lower case letter, together with a pattern $p$. It
matches every item (tree or hedge) matched by $p$, and in addition binds 
it to the variable name. If $p$ is a tree pattern of type $T$, the type 
of $x$ is also $T$.
If $p$ is a hedge pattern enclosed by constructor $c <: $\lstinline@Seq[$T\,$]@,
then the type of $x$ is \lstinline@List[$T\,$]@
where $T$ is the expected type as dictated by the constructor. 

%A pattern consisting of only a variable $x$ is treated as the bound
%value pattern $x @ \_$. A typed pattern $x:T$ is treated as $x @ (_:T)$.
%
Regular expressions that contain variable bindings may be ambiguous,
i.e. there might be several ways to match a sequence against the
pattern. In these cases, the \emph{right-longest policy} applies:
patterns that appear more to the right than others in a sequence take
precedence in case of overlaps.

\example Some examples of patterns are:
\begin{enumerate}
\item
The pattern ~\lstinline@ex: IOException@~ matches all instances of class
\code{IOException}, binding variable \code{ex} to the instance.
\item
The pattern ~\lstinline@Pair(x, _)@~ matches pairs of values, binding \code{x} to
the first component of the pair. The second component is matched
with a wildcard pattern.
\item
The pattern \ \code{List( x, y, xs @ _ * )} matches lists of length $\geq 2$,
binding \code{x} to the list's first element, \code{y} to the list's
second element, and \code{xs} to the remainder, which may be empty.
\item
The pattern \ \code{List( 1, x@(( 'a' | 'b' )+),y,_ )} matches a list that
contains 1 as its first element, continues with a non-empty sequence of 
\code{'a'}s and \code{'b'}s, followed by two more elements. The sequence of 'a's and 'b's
is bound to \code{x}, and the next to last element is bound to \code{y}.
\item
The pattern \code{List( x@( 'a'* ), 'a'+ )} matches a non-empty list of
\code{'a'}s. Because of the shortest match policy, \code{x} will always be bound to
the empty sequence.
\item
The pattern \code{List( x@( 'a'+ ), 'a'* )} also matches a non-empty list of
\code{'a'}s. Here, \code{x} will always be bound to
the sequence containing one \code{'a'}.
\end{enumerate}

}

\section{Pattern Matching Expressions}
\label{sec:pattern-match}

\syntax\begin{lstlisting}
  Expr            ::=  PostfixExpr match `{' CaseClauses `}'
  CaseClauses     ::=  CaseClause {CaseClause} 
  CaseClause      ::=  case Pattern [`if' PostfixExpr] `=>' Block 
\end{lstlisting}

A pattern matching expression 
\begin{lstlisting}
e match { case $p_1$ => $b_1$ $\ldots$ case $p_n$ => $b_n$@ }
\end{lstlisting}
consists of a selector expression $e$ and a number $n > 0$ of
cases. Each case consists of a (possibly guarded) pattern $p_i$ and a
block $b_i$. Each $p_i$ might be complemented by a guard
~\lstinline@if $e$@~ where $e$ is a boolean expression. 
The scope of the pattern
variables in $p_i$ comprises the pattern's guard and the corresponding block $b_i$.

Let $T$ be the type of the selector expression $e$ and let $a_1
\commadots a_m$ be the type parameters of all methods enclosing 
the pattern matching expression.  For every $a_i$, let $L_i$ be its
lower bound and $U_i$ be its higher bound.  Every pattern $p \in
\{p_1, \commadots p_n\}$ can be typed in two ways. First, it is attempted
to type $p$ with $T$ as its expected type. If this fails, $p$ is
instead typed with a modified expected type $T'$ which results from
$T$ by replacing every occurrence of a type parameter $a_i$ by
\mbox{\sl undefined}.  If this second step fails also, a compile-time
error results. If the second step succeeds, let $T_p$ be the type of
pattern $p$ seen as an expression. One then determines minimal bounds
$L'_1 \commadots L'_m$ and maximal bounds $U'_1 \commadots U'_m$ such
that for all $i$, $L_i <: L'_i$ and $U'_i <: U_i$ and the following
constraint system is satisfied:
\[
    L_1 <: a_1 <: U_1\;\wedge\;\ldots\;\wedge\;L_m <: a_m <: U_m 
    \ \Rightarrow\ T_p <: T
\]
If no such bounds can be found, a compile time error results.  If such
bounds are found, the pattern matching clause starting with $p$ is
then typed under the assumption that each $a_i$ has lower bound $L'_i$
instead of $L_i$ and has upper bound $U'_i$ instead of $U_i$.

The expected type of every block $b_i$ is the expected type of the
whole pattern matching expression.  The type of the pattern matching
expression is then the least upper bound of the types of all blocks
$b_i$.

When applying a pattern matching expression to a selector value,
patterns are tried in sequence until one is found which matches the
selector value (\sref{sec:patterns}). Say this case is $\CASE;p_i
\Arrow b_i$.  The result of the whole expression is then the result of
evaluating $b_i$, where all pattern variables of $p_i$ are bound to
the corresponding parts of the selector value.  If no matching pattern
is found, a \code{scala.MatchError} exception is thrown.

The pattern in a case may also be followed by a guard suffix \ \code{if e}\ 
with a boolean expression $e$.  The guard expression is evaluated if
the preceding pattern in the case matches. If the guard expression
evaluates to \code{true}, the pattern match succeeds as normal. If the
guard expression evaluates to \code{false}, the pattern in the case
is considered not to match and the search for a matching pattern
continues.

In the interest of efficiency the evaluation of a pattern matching
expression may try patterns in some other order than textual
sequence. This might affect evaluation through
side effects in guards. However, it is guaranteed that a guard
expression is evaluated only if the pattern it guards matches.

\example\label{ex:eval}
 Consider the following definitions of arithmetic terms:

\begin{lstlisting}
abstract class Term[T]
case class Lit(x: int) extends Term[int]
case class Succ(t: Term[int]) extends Term[int]
case class IsZero(t: Term[int]) extends Term[boolean]
case class If[T](c: Term[boolean], 
                 t1: Term[T], 
                 t2: Term[T]) extends Term[T]
\end{lstlistng}
There are terms to represent numeric literals, incrementation, a zero
test, and a conditional. Every term carries as a type parameter the
type of the expression it representes (either \code{int} or \code{boolean}).

A type-safe evaluator for such terms can be written as follows.
\begin{lstlisting}
def eval[T](t: Term[T]): T = t match {
  case Lit(n)        => n
  case Succ(u)       => eval(u) + 1
  case IsZero(u)     => eval(u) == 0
  case If(c, u1, u2) => eval(if (eval(c)) u1 else u2)
}
\end{lstlisting}
Note that the evaluator makes crucial use of the fact that type
parameters of enclosing methods can acquire new bounds through pattern
matching.

For instance, the type of the pattern in the second case,
\lstinline@Succ(u)@, is \code{int}. It conforms to the selector type
\code{T} only if we assume an upper and lower bound of \code{int} for \code{T}.
Under the assumption ~\lstinline@int <: T <: int@~ we can also
verify that the type right hand side of the second case, \code{int}
conforms to its expected type, \code{T}.

\section{Pattern Matching Anonymous Functions}

\syntax\begin{lstlisting}
  BlockExpr ::= `{' CaseClauses `}'
\end{lstlisting}

An anonymous function can be defined by a sequence of cases 
\begin{lstlisting}
{ case $p_1$ => $b_1$ $\ldots$ case $p_n$ => $b_n$@ }
\end{lstlisting}
which appear as an expression without a prior \code{match}.  The
expected type of such an expression must in part be defined. It must
be either ~\lstinline@scala.Function1[$T_p$, $T_r$]@~
or ~\lstinline@scala.PartialFunction[$T_p$, $T_r$]@, where the
argument type $T_p$ must be fully determined, but the result type
$T_r$ may be undetermined.

If the expected type is ~\lstinline@scala.Function1[$T_p$, $T_r$]@~,
the expression is taken to be equivalent to the anonymous function:
\begin{lstlisting}
(x: $T_p$) => x match { case $p_1$ => $b_1$ $\ldots$ case $p_n$ => $b_n$@ }
\end{lstlisting}
As was shown in \sref{sec:closures} this anonymous function is in turn
equivalent to the following instance creation expression:
\begin{lstlisting}
new scala.Function1[$T_p$, $T$] {
  def apply($x$: $T_p$): $T$ = $x$ match {
    case $p_1$ => $b_1$ $\ldots$ case $p_n$ => $b_n$
  }
}
\end{lstlisting}
Here, $x$ is a fresh name and $T$ is the least upper bound of the
types of all $b_i$.

If the expected type is ~\lstinline@scala.PartialFunction[$T_p$, $T_r$]@~,
the expression is taken to be equivalent to the following instance creation expression:
\begin{lstlisting}
new scala.PartialFunction[$T_p$, $T_r$] {
  def apply($x$: $T_p$): $T$ = x match {
    case $p_1$ => $b_1$ $\ldots$ case $p_n$ => $b_n$
  }
  def isDefinedAt($x$: $T_p$): $T$ = {
    case $p_1$ => true $\ldots$ case $p_n$ => true 
    case _ => false
  }
}
\end{lstlisting}
Here, $x$ is a fresh name and $T$ is the least upper bound of the
types of all $b_i$. The final default case in the \code{isDefinedAt}
method is omitted if one of the patterns $p_1 \commadots p_n$ is
already a variable or wildcard pattern.

\chapter{Top-Level Definitions}
\label{sec:topdefs}

\section{Compilation Units}

\syntax\begin{lstlisting}
  CompilationUnit  ::=  [package QualId StatementSeparator] TopStatSeq
  TopStatSeq       ::=  TopStat {StatementSeparator TopStat}
  TopStat          ::=  {AttributeClause} {Modifier} TmplDef
                     |  Import
                     |  Packaging
                     |
  QualId           ::=  id {`.' id}
\end{lstlisting}

A compilation unit consists of a sequence of packagings, import
clauses, and class and object definitions, which may be preceded by a
package clause.

A compilation unit ~\lstinline@package $p$; $\stats$@~ starting with a package
clause is equivalent to a compilation unit consisting of a single
packaging ~\lstinline@package $p$ { $\stats$ }@.

Implicitly imported into every compilation unit are, in that order :
the package \code{java.lang}, the package \code{scala}, and the object
\code{scala.Predef} (\sref{cls:predef}). Members of a later import in
that order hide members of an earlier import.

\section{Packagings}\label{sec:packagings}

\syntax\begin{lstlisting}
  Packaging       ::=  package QualId `{' TopStatSeq `}'
\end{lstlisting}

A package is a special object which defines a set of member classes,
objects and packages.  Unlike other objects, packages are not introduced
by a definition.  Instead, the set of members of a package is determined by
packagings.

A packaging ~\lstinline@package $p$ { $\ds$ }@~ injects all
definitions in $\ds$ as members into the package whose qualified name
is $p$. Members of a package are called {\em top-level} definitions.
If a definition in $\ds$ is labeled \code{private}, it is
visible only for other members in the package.

Selections $p$.$m$ from $p$ as well as imports from $p$
work as for objects. However, unlike other objects, packages may not
be used as values. It is illegal to have a package with the same fully
qualified name as a module or a class.

Top-level definitions outside a packaging are assumed to be injected
into a special empty package. That package cannot be named and
therefore cannot be imported. However, members of the empty package
are visible to each other without qualification.

\section{Programs}

A {\em program} is a top-level object that has a member method
\code{main} of type ~\lstinline@(Array[String])unit@. Programs can be
executed from a command shell. The program's command arguments are are
passed to the \code{main} method as a parameter of type
\code{Array[String]}.

The \code{main} method of a program can be directly defined in the
object, or it can be inherited. The scala library defines a class
\code{scala.Application} that defines an empty inherited \code{main} method.
An objects $m$ inheriting from this class is thus a program, 
which executes the initializaton code of the object $m$.

\example The following example will create a hello world program by defining
a method \code{main} in module \code{test.HelloWorld}.
\begin{lstlisting}
package test 

object HelloWord {
  def main(args: Array[String]) = System.out.println("hello world")
}
\end{lstlisting}

This program can be started by either of the commands
\begin{lstlisting}
scala test.HelloWorld
\end{lstlisting}
In a Java environment, the command
\begin{lstlisting}
java test.HelloWorld
\end{lstlisting}
would work as well. 

\code{HelloWorld} can also be defined without without a \code{main} method 
by inheriting from \code{Application} instead:
\begin{lstlisting}
package test 
object HelloWord extends Application {
  System.out.println("hello world")
}
\end{lstlisting}

\chapter{XML expressions and patterns}

{\bf By Burak Emir}\bigskip\bigskip


This chapter describes the syntactic structure of XML expressions and patterns.
It follows as close as possible the XML 1.0 specification \cite{w3c:xml},
changes being mandated by the possibility of embedding Scala code fragments.

\section{XML expressions}
XML expressions are expressions generated by the following production, where the 
opening bracket `<' of the first element must be in a position to start the lexical
XML mode (\sref{sec::xmlMode}).

\syntax\begin{lstlisting}
XmlExpr ::= Element {Element}
\end{lstlisting}
Well-formedness constraints of the XML specification apply, which
means for instance that start tags and end tags must match, and
attributes may only be defined once, with the exception of constraints
related to entity resolution.

The following productions describe Scala's extensible markup language,
designed as close as possible to the W3C extensible markup language
standard. Only the productions for attribute values and character data
are changed. Scala does not support neither declarations, CDATA
sections nor processing instructions. Entity references are not
resolved at runtime.

\syntax\begin{lstlisting}
Element       ::=    EmptyElemTag
                |    STag Content ETag                                       

EmptyElemTag  ::=    `<' Name {S Attribute} [S] `/>'                         

STag          ::=    `<' Name {S Attribute} [S] `>'                          
ETag          ::=    `</' Name [S] '>'                                        
Content       ::=    [CharData] {Content1 [CharData]}
Content1      ::=    Element
                |    Reference
                |    CDSect
                |    PI
                |    Comment
                |    ScalaExpr
\end{lstlisting}

If an XML expression is a single element, its value is a runtime
representation of an XML node (an instance of a subclass of 
\lstinline@scala.xml.Node@). If the XML expression consists of more
than one element, then its value is a runtime representation of a
sequence of XML nodes (an instance of a subclass of 
\lstinline@scala.Seq[scala.xml.Node]@).

If an XML expression is an entity reference, CDATA section, processing 
instructions or a comments, it is represented by an instance of the 
corresponding Scala runtime class.

By default, beginning and trailing whitespace in element content is removed, 
and consecutive occurrences of whitespace are replaced by a single space
character \U{0020}. This behavior can be changed to preserve all whitespace
with a compiler option.
\syntax\begin{lstlisting}
Attribute     ::=    Name Eq AttValue                                    

AttValue      ::=    `"' {CharQ | CharRef} `"'
                |    `'' {CharA | CharRef} `''
                |    ScalaExp

ScalaExpr     ::=    `{' expr `}'

CharData      ::=   { CharNoRef } $\mbox{\rm\em without}$ {CharNoRef}`{'CharB {CharNoRef} 
                                  $\mbox{\rm\em and without}$ {CharNoRef}`]]>'{CharNoRef}
\end{lstlisting}
XML expressions may contain Scala expressions as attribute values or
within nodes. In the latter case, these are embedded using a single opening 
brace `{' and ended by a closing brace `}'. To express a single opening braces 
within XML text as generated by CharData, it must be doubled. Thus, `{{` 
represents the XML text `{` and does not introduce an embedded Scala 
expression.

\syntax\begin{lstlisting}
BaseChar, Char, Comment, CombiningChar, Ideographic, NameChar, S, Reference
              ::=  $\mbox{\rm\em ``as in W3C XML''}$

Char1         ::=  Char $\mbox{\rm\em without}$ `<' | `&'
CharQ         ::=  Char1 $\mbox{\rm\em without}$ `"'
CharA         ::=  Char1 $\mbox{\rm\em without}$ `''
CharB         ::=  Char1 $\mbox{\rm\em without}$ '{'

Name          ::=  XNameStart {NameChar}

XNameStart    ::= `_' | BaseChar | Ideographic 
                 $\mbox{\rm\em (as in W3C XML, but without }$ `:'

\end{lstlisting}
\section{XML patterns}\label{sec:xml-pats}
XML patterns are patterns generated by the following production, where
the opening bracket `<' of the element patterns must be in a position
to start the lexical XML mode (\sref{sec::xmlMode}).

\syntax\begin{lstlisting}
XmlPattern  ::= ElementPattern {ElementPattern}
\end{lstlisting}
Well-formedness constraints of the XML specification apply.

If an XML pattern is a single element pattern, it expects the type of runtime
representation of an XML tree, and matches exactly one instance of this type
that has the same structure as described by the pattern. If an XML pattern 
consists of more than one element, then it expects the type of sequences
of runtime representations of XML trees, and matches every sequence whose 
elements match the sequence described by the pattern.

XML patterns may contain Scala patterns(\sref{sec:pattern-match}).

Whitespace is treated the same way as in XML expressions. Patterns 
that are entity references, CDATA sections, processing 
instructions and comments match runtime representations which are the
the same.

By default, beginning and trailing whitespace in element content is removed, 
and consecutive occurrences of whitespace are replaced by a single space
character \U{0020}. This behavior can be changed to preserve all whitespace
with a compiler option.

\syntax\begin{lstlisting}
ElemPattern   ::=    EmptyElemTagP
                |    STagP ContentP ETagP                                    

EmptyElemTagP ::=    '<' Name [S] '/>'
STagP         ::=    '<' Name [S] '>'                          
ETagP         ::=    '</' Name [S] '>'                                        
ContentP      ::=    [CharData] {(ElemPattern|ScalaPatterns) [CharData]}
ContentP1     ::=    ElemPattern
                |    Reference
                |    CDSect
                |    PI
                |    Comment
                |    ScalaPatterns
ScalaPatterns ::=    '{' patterns '}'
\end{lstlisting}


\chapter{Attributes}

\syntax\begin{lstlisting}
  AttributeClause ::=  `[' Attribute {`,' Attribute} `]' [NewLine]
  Attribute       ::=  Constr
\end{lstlisting}

Attributes associate meta-information with definitions.  A simple
attribute clause has the form $[C]$ or $[C(a_1 \commadots a_n)]$.
Here, $c$ is a constructor of a class $C$, which must conform to the
class \lstinline@scala.Attribute@. All given constructor arguments
$a_1 \commadots a_n$ must be constant expressions. An attribute clause
applies to the first definition or declaration following it. More than
one attribute clause may precede a definition and declaration. The
order in which these clauses are given does not matter.  It is also
possible to combine several attributes separated by commas in one
clause. Such a combined clause $[A_1 \commadots A_n]$ is equivalent to
a set of clauses $[A_1] \ldots [A_n]$.

The meaning of attribute clauses is implementation-dependent. On the
Java platform, the following attributes have a standard meaning.\bigskip

\lstinline@transient@
\begin{quote}
Marks a field to be non-persistent; this is
equivalent to the \lstinline@transient@
modifier in Java.
\end{quote}

\lstinline@volatile@
\begin{quote}Marks a field which can change its value
outside the control of the program; this
is equivalent to the \lstinline@volatile@
modifier in Java.
\end{quote}

\lstinline@Serializable@
\begin{quote}Marks a class to be serializable; this is
equivalent to inheriting from the 
\lstinline@java.io.Serializable@ interface
in Java.
\end{quote}

\lstinline@SerialVersionUID(<longlit>)@
\begin{quote}Attaches a serial version identifier (a
\lstinline@long@ constant) to a class.
This is equivalent to a the following field
definition in Java:
\begin{lstlisting}[language=Java]
  private final static SerialVersionUID = <longlit> 
\end{lstlisting}
\end{quote}

\lstinline@beanProperty@
\begin{quote}
When prefixed to a definition of some variable \code{X}, this
attribute causes getter and setter methods \code{getX}, \code{setX} in
the Java bean style to be added in the class containing the
variable. The first letter of the variable appears capitalized after
the \code{get} or \code{set}. When the attribute is added to the
definition of an immutable value definition \code{X}, only a setter is
generated.
\end{quote}


\chapter{The Scala Standard Library}

The Scala standard library consists of the package \code{scala} with a
number of classes and modules. Some of these classes are described in
the following.

\section{Root Classes}
\label{sec:cls-root}
\label{sec:cls-any}
\label{sec:cls-object}

The root of the Scala class hierarchy is formed by class \code{Any}.
Every class in a Scala execution environment inherits directly or
indirectly from this class.  Class \code{Any} has two direct
subclasses: \code{AnyRef} and\code{AnyVal}.

The subclass \code{AnyRef} represents all values which are represented
as objects in the underlying host system. Every user-defined Scala
class inherits directly or indirectly from this class. Furthermore,
every user-defined Scala class also inherits the trait
\code{scala.ScalaObject}.  Classes written in other languages still
inherit from \code{scala.AnyRef}, but not from
\code{scala.ScalaObject}.

The class \code{AnyVal} has a fixed number subclasses, which describe
values which are not implemented as objects in the underlying host
system.

Classes \code{AnyRef} and \code{AnyVal} are required to provide only
the members declared in class \code{Any}, but implementations may add
host-specific methods to these classes (for instance, an
implementation may identify class \code{AnyRef} with its own root
class for objects).

The signatures of these root classes are described by the following
definitions.

\begin{lstlisting}
package scala 
/** The universal root class */
abstract class Any {

  /** Defined equality; abstract here */
  def equals(that: Any): boolean 

  /** Semantic equality between values of same type */
  final def == (that: Any): boolean  =  this equals that

  /** Semantic inequality between values of same type */
  final def != (that: Any): boolean  =  !(this == that)

  /** Hash code; abstract here */
  def hashCode(): Int = $\ldots$

  /** Textual representation; abstract here */
  def toString(): String = $\ldots$

  /** Type test; needs to be inlined to work as given */
  def isInstanceOf[a]: Boolean = this match {
    case x: a => true
    case _ => false
  }

  /** Type cast; needs to be inlined to work as given */ */
  def asInstanceOf[a]: a = this match {
    case x: a => x
    case _ => if (this eq null) this
              else throw new ClassCastException()
  }
}

/** The root class of all value types */
final class AnyVal extends Any 

/** The root class of all reference types */
class AnyRef extends Any {
  def equals(that: Any): Boolean     = this eq that 
  final def eq(that: Any): Boolean   = $\ldots$  // reference equality
  
  def hashCode(): Int = $\ldots$     // hashCode computed from allocation address
  def toString(): String  = $\ldots$ // toString computed from hashCode and class name

/** A mixin class for every user-defined Scala class */
trait ScalaObject extends AnyRef 
\end{lstlisting}

The test ~\lstinline@$x$.asInstanceOf[$T$]@ is treated specially if $T$ is a
numeric value type (\sref{sec:cls-value}. In this case the cast will
be translated to an application of a conversion method ~\lstinline@x.to$T$@ 
(\sref{cls:numeric-value}). For non-numeric values $x$ the operation will raise a
\code{ClassCastException}.

\section{Value Classes}
\label{sec:cls-value}

Value classes are classes whose instances are not represented as
objects by the underlying host system.  All value classes inherit from
class \code{AnyVal}. Scala implementations need to provide the
value classes \code{Unit}, \code{Boolean}, \code{Double}, \code{Float},
\code{Long}, \code{Int}, \code{Char}, \code{Short}, and \code{Byte}
(but are free to provide others as well).
The signatures of these classes are defined in the following.

\subsection{Numeric Value Types} \label{cls:numeric-value}

Classes \code{Double}, \code{Float},
\code{Long}, \code{Int}, \code{Char}, \code{Short}, and \code{Byte}
are together called {\em numeric value types}. Classes \code{Byte},
\code{Short}, or \code{Char} are called {\em subrange types}.
Subrange types, as well as \code{Int} and \code{Long} are called {\em
integer types}, whereas \code{Float} and \code{Double} are called {\em
floating point types}.

Numeric value types are ranked in the following partial order:

\begin{lstlisting}
Byte - Short 
             \
               Int - Long - Float - Double
             / 
        Char 
\end{lstlisting}
\code{Byte} and \code{Short} are the lowest-ranked types in this order, 
whereas \code{Double} is the highest-ranked.  Ranking does {\em not}
imply a conformance (\sref{sec:conformance}) relationship; for
instance \code{Int} is not a subtype of \code{Long}.  However, object
\code{Predef} (\sref{cls:predef}) defines views (\sref{sec:views}) 
from every numeric value type to all higher-ranked numeric value types. Therefore,
lower-ranked types are implicitly converted to higher-ranked types
when required by the context (\sref{sec:impl-conv}).

Given two numeric value types $S$ and $T$, the {\em operation type} of
$S$ and $T$ is defined as follows: If both $S$ and $T$ are subrange
types then the operation type of $S$ and $T$ is \code{Int}.  Otherwise
the operation type of $S$ and $T$ is the larger of the two types wrt
ranking. Given two numeric values $v$ and $w$ the operation type of
$v$ and $w$ is the operation type of their run-time types.

Any numeric value type $T$ supports the following methods.
\begin{itemize}
\item 
Comparison methods for equals (\code{==}), not-equals (\code{!=}),
less-than (\code{<}), greater-than (\code{>}), less-than-or-equals
(\code{<=}), greater-than-or-equals (\code{>=}), which each exist in 7
overloaded alternatives. Each alternative takes a parameter of some
numeric value type. Its result type is type \code{Boolean}. The
operation is evaluated by converting the receiver and its argument to
their operation type and performing the given comparison operation of
that type.
\item
Arithmetic methods addition (\code{+}), subtraction (\code{-}),
multiplication (\code{*}), division (\code{/}), and remainder
(\lstinline@%@), which each exist in 7 overloaded alternatives. Each
alternative takes a parameter of some numeric value type $U$.  Its
result type is the operation type of $T$ and $U$. The operation is
evaluated by converting the receiver and its argument to their
operation type and performing the given arithmetic operation of that
type.
\item
Parameterless arithmethic methods identity (\code{+}) and negation
(\code{-}), with result type $T$.  The first of these returns the
receiver unchanged, whereas the second returns its negation.
\item
Conversion methods \code{toByte}, \code{toShort}, \code{toChar},
\code{toInt}, \code{toLong}, \code{toFloat}, \code{toDouble} which
convert the receiver object to the target type, using the rules of
Java's numeric type cast operation. The conversion might truncate the
numeric value (as when going from \code{Long} to \code{Int} or from
\code{Int} to \code{Byte}) or it might lose precision (as when going
from \code{Double} to \code{Float} or when converting between
\code{Long} and \code{Float}). 
\end{itemize}

Integer numeric value types support in addition the following operations:
\begin{itemize}
\item 
Bit manipulation methods bitewise-and (\code{&}), bitwise-or
{\code{|}}, and bitwise-exclsuive-or (\code{^}), which each exist in 5
overloaded alternatives. Each alternative takes a parameter of some
integer numeric value type. Its result type is the operation type of
$T$ and $U$. The operation is evaluated by converting the receiver and
its argument to their operation type and performing the given bitwise
operation of that type.
\item
A parameterless bit-negation method (\lstinline@~@). Its result type is
the reciver type $T$ or \code{Int}, whichevery is larger.
The operation is evaluated by converting the receiver to the result
type and negating every bit in its value.
\item
Bit-shift methods left-shift (\code{<<}), arithmetic right-shift
(\code{>>}), and unsigned right-shift (\code{>>>}). Each of these
methods of has two overloaded alternatives, which take a parameter $n$
of type \code{Int}, respectively \code{Long}. The result type of the
operation is the reciver type $T$, or \code{Int}, whichever is larger.
The operation is evaluated by converting the receiver to the result
type and performing the specified shift by $n$ bits.
\end{itemize}

Numeric value types also implement operations \code{equals},
\code{hashCode}, and \code{toString} from class \code{Any}.

The \code{equals} method tests whether the argument is a numeric value
type. If this is true, it will perform the \code{==} operation which
is appropriate for that type. That is, the \code{equals} method of a
numeric value type can be thought of being defined as follows:
\begin{lstlisting}
def equals(other: Any): Boolean = other match {
  case that: Byte   => this == that
  case that: Short  => this == that
  case that: Char   => this == that
  case that: Int    => this == that
  case that: Long   => this == that
  case that: Float  => this == that
  case that: Double => this == that
  case _ => false
}
\end{lstlisting}
The \code{hashCode} method returns an integer hashcode that maps equal
numeric values to equal results. It is guaranteed to be the identity for 
for type \code{Int} and for all subrange types.

The \code{toString} method displays its receiver as an integer or
floating point number.

\example As an example, here is the signature of the numeric value type \code{Int}:

\begin{lstlisting}
package scala 
abstract sealed class Int extends AnyVal {
  def == (that: Double): Boolean  // double equality
  def == (that: Float): Boolean   // float equality
  def == (that: Long): Boolean    // long equality
  def == (that: Int): Boolean     // int equality
  def == (that: Short): Boolean   // int equality
  def == (that: Byte): Boolean    // int equality
  def == (that: Char): Boolean    // int equality
  /* analogous for !=, <, >, <=, >= */

  def + (that: Double): Double    // double addition
  def + (that: Float): Double     // float addition
  def + (that: Long): Long        // long addition
  def + (that: Int): Int          // int addition
  def + (that: Short): Int        // int addition
  def + (that: Byte): Int         // int addition
  def + (that: Char): Int         // int addition
  /* analogous for -, *, /, % */
  
  def & (that: Long): Long        // long bitwise and
  def & (that: Int): Int          // int bitwise and
  def & (that: Short): In         // int bitwise and
  def & (that: Byte): Int         // int bitwise and
  def & (that: Char): Int         // int bitwise and
  /* analogous for |, ^ */

  def << (cnt: Int): Int          // int left shift
  def << (cnt: Long): Int         // long left shift
  /* analogous for >>, >>> */

  def + : Int                     // int identity
  def - : Int                     // int negation
  def ~ : Int                     // int bitwise negation

  def toByte: Byte                // convert to Byte
  def toShort: Short              // convert to Short
  def toChar: Char                // convert to Char
  def toInt: Int                  // convert to Int
  def toLong: Long                // convert to Long
  def toFloat: Float              // convert to Float
  def toDouble: Double            // convert to Double
}
\end{lstlisting}

\subsection{Class \large{\code{Boolean}}}
\label{sec:cls-boolean}

Class \code{Boolean} has only two values: \code{true} and
\code{false}. It implements operations as given in the following
signature:

\begin{lstlisting}
package scala 
abstract sealed class Boolean extends AnyVal {
  def && (def x: Boolean): Boolean  // boolean and
  def || (def x: Boolean): Boolean  // boolean or
  def &  (x: Boolean): Boolean      // boolean strict and
  def |  (x: Boolean): Boolean      // boolean strict or

  def == (x: Boolean): Boolean      // boolean equality
  def != (x: Boolean): Boolean      // boolean inequality

  def !: Boolean                    // boolean negation
}
\end{lstlisting}
The class also implements operations \code{equals}, \code{hashCode},
and \code{toString} from class \code{Any}.

The \code{equals} method returns \code{true} if the argument is the
same boolean value as the receiver, \code{false} otherwise.  The
\code{hashCode} method returns \code{1} when invoked on \code{true}, 
and \code{0} when invokend on \code{false}. The \code{toString} method
returns the receiver converted to a string, i.e.\ either \code{"true"}
or \code{"false"}.

\subsection{Class \large{\code{Unit}}}

Class \code{Boolean} has only one value: \code{()}. It implements only
the three methods \code{equals}, \code{hashCode}, and \code{toString}
from class \code{Any}.

The \code{equals} method returns \code{true} if the argument is the
unit value \code{()}, \code{false} otherwise.  The
\code{hashCode} method returns a fixed, implementation-specific hash-code, 
The \code{toString} method returns \code{"()"}.

\section{Standard Reference Classes}
\label{cls:reference}

This section presents some standard Scala reference classes which are
treated in a special way in Scala compiler -- either Scala provides
syntactic sugar for them, or the Scala compiler generates special code
for their operations. Other classes in the standard Scala library are
documented in the Scala library documentation by HTML pages.

\subsection{Class \large{\code{String}}}

Scala's \lstinline@String@ class is usually derived from the standard String
class of the underlying host system (and may be identified with
it). For Scala clients the class is taken to support in each case a
method
\begin{lstlisting}
def + (that: Any): String 
\end{lstlisting}
which concatenates its left operand with the textual representation of its
right operand.

\subsection{The \large{\code{Tuple}} classes}

Scala defines tuple classes \lstinline@Tuple$n$@ for $n = 2 \commadots 9$.
These are defined as follows.

\begin{lstlisting}
package scala 
case class Tuple$n$[+a_1, ..., +a_n](_1: a_1, ..., _$n$: a_$n$) {
  def toString = "(" ++ _1 ++ "," ++ $\ldots$ ++ "," ++_$n$ ++ ")"
}
\end{lstlisting}

The implicitly imported \code{Predef} object (\sref{cls:predef}) defines
the names \code{Pair} as an alias of \code{Tuple2} and \code{Triple}
as an alias for \code{Tuple3}.

\subsection{The \large{\code{Function}} Classes}
\label{sec:cls-function}

Scala defines function classes \lstinline@Function$n$@ for $n = 1 \commadots 9$.
These are defined as follows.

\begin{lstlisting}
package scala 
trait Function$n$[-a_1, ..., -a_$n$, +b] {
  def apply(x_1: a_1, ..., x_$n$: a_$n$): b 
  def toString = "<function>" 
}
\end{lstlisting}

\comment{
There is also a module \code{Function}, defined as follows.
\begin{lstlisting}
package scala 
module Function {
  def compose[a](fs: List[(a)a]): (a)a  = {
    x => fs match {
      case Nil => x
      case f :: fs1 => compose(fs1)(f(x))
    }
  }
}
\end{lstlisting}
}
A subclass of \lstinline@Function1@ represents partial functions,
which are undefined on some points in their domain. In addition to the
\code{apply} method of functions, partial functions also have a
\code{isDefined} method, which tells whether the function is defined
at the given argument:
\begin{lstlisting}
class PartialFunction[-a,+b] extends Function1[a, b] {
  def isDefinedAt(x: a): Boolean
}
\end{lstlisting}

The implicitly imported \code{Predef} object (\sref{cls:predef}) defines the name 
\code{Function} as an alias of \code{Function1}.

\subsection{Class \large{\code{Array}}}\label{cls:array}

The class of generic arrays is given as follows.

\begin{lstlisting}
final class Array[A](len: Int) extends Seq[A] {
  def length: Int = len
  def apply(i: Int): A = $\ldots$
  def update(i: Int, x: A): Unit = $\ldots$
  def elements: Iterator[A] = $\ldots$
  def subArray(from: Int, end: Int): Array[a] = $\ldots$
  def filter(p: a => Boolean): Array[a] = $\ldots$
  def map[b](f: a => b): Array[b] = $\ldots$
  def flatMap[b](f: a => Array[b]): Array[b] = $\ldots$
}
\end{lstlisting}
If $T$ is not a type parameter or abstract type, the type Array[$T$]
is represented as the native array type \lstinline{[]$T$} in the
underlying host system. In that case \code{length} returns
the length of the array, \code{apply} means subscribting, and
\code{update} means element update. Because of the syntactic sugar for
\code{apply} and
%\code{update} operations (\sref{sec:impl-conv}, \sref{sec:assignments}),
\code{update} operations (\sref{sec:impl-conv},
we have the following correspondences between Scala and Java/C\# code for
operations on an array \code{xs}:

\begin{lstlisting}
$\mbox{\em Scala}$            $\mbox{\em Java/C\#}$
  xs.length        xs.length
  xs(i)            xs[i]
  xs(i) = e        xs[i] = e
\end{lstlisting}

Arrays also implement the sequence trait \code{scala.Seq}
by defining an \code{elements} method which returns
all elements of the array in an \code{Iterator}.

Because of the tension between parametrized types in Scala and the ad-hoc
implementation of arrays in the host-languages, some subtle points
need to be taken into account when dealing with arrays. These are
explained in the following.

First, unlike arrays in Java or C\#, arrays in Scala are {\em not}
co-variant; That is, $S <: T$ does not imply 
~\lstinline@Array[$S$] $<:$ Array[$T$]@ in Scala.  
However, it is possible to cast an array
of $S$ to an array of $T$ if such a cast is permitted in the host
enironment.

For instance \code{Array[String]} does not conform to
\code{Array[Object]}, even though \code{String} conforms to \code{Object}.
However, it is possible to cast an expression of type
~\lstinline@Array[String]@~ to ~\lstinline@Array[Object]@, and this
cast will succeed withiout raising a \code{ClassCastException}. Example:
\begin{lstlisting}
val xs = new Array[String](2)
// val ys: Array[Object] = xs   // **** error: incompatible types
val ys: Array[Object] = xs.asInstanceOf[Array[Object]] // OK
\end{lstlisting}

Second, for {\em polymorphic arrays}, that have a type parameter or
abstract type $T$ as their element type, a representation different
from
\lstinline@[]T@ might be used. However, it is guaranteed that 
\code{isInstanceOf} and \code{asInstanceOf} still work as if the array 
used the standard representation of monomorphic arrays:
\begin{lstlisting}
val ss = new Array[String](2)

def f[T](xs: Array[T]): Array[String] = 
  if (xs.isInstanceOf[Array[String]]) xs.asInstanceOf[Array[String])
  else throw new Error("not an instance")

f(ss)                                     // returns ss
\end{lstlisting}
The representatuon chosen for polymorphic arrays also guarantees that
polymorphic array creations work as expected. An example is the
following implementation of method \lstinline@mkArray@, which creates
an array of an arbitrary type $T$, given a sequence of $T$'s which
defines its elements.
\begin{lstlisting}
def mkArray[T](elems: Seq[T]): Array[T] = {
  val result = new Array[T](elems.length)
  var i = 0
  for (val elem <- elems) {
    result(i) = elem
    i = i + 1
  }
}
\end{lstlisting}
Note that under Java's erasure model of arrays the method above would
not work as expected -- in fact it would always return an array of
\lstinline@Object@.

Third, in a Java environment there is a method \code{System.arraycopy}
which takes two objects as parameters together with start indices and
a length argument, and copies elements from one object to the other,
provided the objects are arrays of compatible element
types. \code{System.arrayCopy} will not work for Scala's polymorphic
arrays because of their different representation. One should instead
use method \code{Array.copy}, defined as follows:
\begin{lstlisting}
package scala
object Array { 
  def copy(src: AnyRef, srcPos: Int, 
           dest: AnyRef, destPos: Int, 
           length: Int): Unit = $\ldots$
\end{lstlisting}

\example The following method duplicates a given argument array and returns a pair consisting of the original and the duplicate:
\begin{lstlisting}
def duplicate[T](xs: Array[T]) = {
  val ys = new Array[T](xs.length)
  Array.copy(xs, 0, ys, 0, xs.length)
  Pair(xs, ys)
}
\end{lstlisting}

\section{Class Node}\label{cls:Node}
\begin{lstlisting}
package scala.xml 

trait Node {

  /** the label of this node */
  def label: String               

  /** attribute axis */
  def attribute: Map[String, String] 

  /** child axis (all children of this node) */
  def child: Seq[Node]          

  /** descendant axis (all descendants of this node) */
  def descendant: Seq[Node] = child.toList.flatMap { 
    x => x::x.descendant.asInstanceOf[List[Node]] 
  } 

  /** descendant axis (all descendants of this node) */
  def descendant_or_self: Seq[Node] = this::child.toList.flatMap { 
    x => x::x.descendant.asInstanceOf[List[Node]] 
  } 

  override def equals(x: Any): boolean = x match {
    case that:Node => 
      that.label == this.label && 
        that.attribute.sameElements(this.attribute) && 
          that.child.sameElements(this.child)
    case _ => false
  } 

 /** XPath style projection function. Returns all children of this node
  *  that are labeled with 'that. The document order is preserved.
  */
    def \(that: Symbol): NodeSeq = {
      new NodeSeq({
        that.name match {
          case "_" => child.toList  
          case _ =>
            var res:List[Node] = Nil 
            for (val x <- child.elements  x.label == that.name) {
              res = x::res 
            }
            res.reverse
        }
      }) 
    }

 /** XPath style projection function. Returns all nodes labeled with the 
  *  name 'that from the descendant_or_self axis. Document order is preserved.
  */
  def \\(that: Symbol): NodeSeq = {
    new NodeSeq(
      that.name match {
        case "_" => this.descendant_or_self 
        case _ => this.descendant_or_self.asInstanceOf[List[Node]].
        filter(x => x.label == that.name) 
      })
  }

  /** hashcode for this XML node */
  override def hashCode() = 
    Utility.hashCode(label, attribute.toList.hashCode(), child) 

  /** string representation of this node */
  override def toString() = Utility.toXML(this) 

}
\end{lstlisting}

\newpage
\section{The \large{\code{Predef}} Object}\label{cls:predef}

The \code{Predef} object defines standard functions and type aliases
for Scala programs. It is always implicitly imported, so that all its
defined members are available without qualification. Its definition
for the JVM environment conforms to the following signature:

\begin{lstlisting}
package scala
object Predef {

  // Standard type aliases ---------------------------------------------

  type byte = scala.Byte
  type short = scala.Short
  type char = scala.Char
  type int = scala.Int
  type long = scala.Long
  type float = scala.Float
  type double = scala.Double
  type boolean = scala.Boolean
  type unit = scala.Unit

  type String = java.lang.String
  type NullPointerException = java.lang.NullPointerException
  type Throwable = java.lang.Throwable

  type Pair[+p, +q] = Tuple2[p, q]
  type Triple[+a, +b, +c] = Tuple3[a, b, c]

  type Function[-a,+b] = Function1[a,b]

  // Factory methods -------------------------------------------------------

  def Pair[a, b](x: a, y: b) = Tuple2(x, y)
  def Triple[a, b, c](x: a, y: b, z: c) = Tuple3(x, y, z)

  def Tuple[a1, a2](x1: a1, x2: a2) = Tuple2(x1, x2)
  def Tuple[a1, a2, a3](x1: a1, x2: a2, x3: a3) = Tuple3(x1, x2, x3)

  // analogous for tuples of length 4-9:
  $\ldots$

\end{lstlisting}
\newpage
\begin{lstlisting}
  def Array[A <: AnyRef](xs: A*): Array[A] = {
    val array = new Array[A](xs.length);
    var i = 0
    for (val x <- xs.elements) { array(i) = x; i = i + 1; }
    array
  }

  // analogous to above:
  def Array(xs: boolean*): Array[boolean] = $\ldots$
  def Array(xs: byte*)   : Array[byte]    = $\ldots$
  def Array(xs: short*)  : Array[short]   = $\ldots$
  def Array(xs: char*)   : Array[char]    = $\ldots$
  def Array(xs: int*)    : Array[int]     = $\ldots$
  def Array(xs: long*)   : Array[long]    = $\ldots$
  def Array(xs: float*)  : Array[float]   = $\ldots$
  def Array(xs: double*) : Array[double]  = $\ldots$
  def Array(xs: unit*)   : Array[unit]    = $\ldots$

  // The ``catch-all'' view ----------------------------------------

  implicit def identity[a](x: a): a = x

  // Views into class Ordered

  implicit def int2ordered(x: int): Ordered[int] = new Ordered[int] with Proxy {
    def self: Any = x
    def compareTo [b >: int <% Ordered[b]](y: b): int = y match {
      case y1: int =>
        if (x < y1) -1
        else if (x > y1) 1
        else 0
      case _ => -(y compareTo x)
    }
  }

    // The implementations of following methods are analogous to the last one:

  implicit def char2ordered(x: char): Ordered[char] = $\ldots$ 
  implicit def long2ordered(x: long): Ordered[long] = $\ldots$ 
  implicit def float2ordered(x: float): Ordered[float] = $\ldots$
  implicit def double2ordered(x: double): Ordered[double] = $\ldots$
  implicit def boolean2ordered(x: boolean): Ordered[boolean] = $\ldots$

\end{lstlisting}
\newpage
\begin{lstlisting}
  implicit def seq2ordered[A <% Ordered[A]](xs: Array[A]): Ordered[Seq[A]] = 
    new Ordered[Seq[A]] with Proxy {
      def compareTo[B >: Seq[A] <% Ordered[B]](that: B): Int = that match {
        case that: Seq[A] =>
          var res = 0
          val these = this.elements
          val those = that.elements
          while (res == 0 && these.hasNext)
            res = if (!those.hasNext) 1 else these.next compareTo those.next
        case _ => - (that compareTo xs)
    }

  implicit def string2ordered(x: String): Ordered[String] = 
    new Ordered[String] with Proxy {
      def self: Any = x
      def compareTo [b >: String <% Ordered[b]](y: b): int = y match {
        case y1: String => x compareTo y1
        case _ => -(y compareTo x)
      }
    }

  implicit def tuple2ordered[a1 <% Ordered[a1], a2 <% Ordered[a2]]
                            (x: Tuple2[a1, a2]): Ordered[Tuple2[a1, a2]] = 
    new Ordered[Tuple2[a1, a2]] with Proxy {
      def self: Any = x
      def compareTo[T >: Tuple2[a1, a2] <% Ordered[T]](y: T): Int = y match {
        case y: Tuple2[a1, a2] => 
          val res = x._1 compareTo y._1
          if (res == 0) x._2 compareTo y._2
          else res
        case _ => -(y compareTo x)
      }
    }

  // Analogous for Tuple3 to Tuple9

  // Views into class Seq

  implicit def string2seq(str: String): Seq[Char] = new Seq[Char] {
    def length = str.length()
    def elements = Iterator.fromString(str)
    def apply(n: Int) = str.charAt(n)
    override def hashCode(): Int = str.hashCode()
    override def equals(y: Any): Boolean = (str == y)
    override protected def stringPrefix: String = "String"
  }
\end{lstlisting}
\newpage
\begin{lstlisting}
  // Numeric conversion views

  implicit def byte2short(x: byte): short = x.toShort
  implicit def byte2int(x: byte): int = x.toInt
  implicit def byte2long(x: byte): long = x.toLong
  implicit def byte2float(x: byte): float = x.toFloat
  implicit def byte2double(x: byte): double = x.toDouble

  implicit def short2int(x: short): int = x.toInt
  implicit def short2long(x: short): long = x.toLong
  implicit def short2float(x: short): float = x.toFloat
  implicit def short2double(x: short): double = x.toDouble
  
  implicit def char2int(x: char): int = x.toInt
  implicit def char2long(x: char): long = x.toLong
  implicit def char2float(x: char): float = x.toFloat
  implicit def char2double(x: char): double = x.toDouble
  
  implicit def int2long(x: int): long = x.toLong
  implicit def int2float(x: int): float = x.toFloat
  implicit def int2double(x: int): double = x.toDouble

  implicit def long2float(x: long): float = x.toFloat
  implicit def long2double(x: long): double = x.toDouble

  implicit def float2double(x: float): double = x.toDouble

// Errors and asserts -----------------------------------------

  def error(message: String): Bottom = throw new Error(message)

  def exit(): Bottom = exit(0)
  def exit(status: Int): Bottom = {
    java.lang.System.exit(status)
    throw new Throwable()
  }

  def assert(assertion: Boolean): Unit =
    if (!assertion)
      throw new Error("assertion failed")

  def assert(assertion: Boolean, message: Any): Unit =
    if (!assertion)
      throw new Error("assertion failed: " + message)
\end{lstlisting}
\newpage
\begin{lstlisting}
  def assume(assumption: Boolean): Unit =
    if (!assumption)
      throw new Error("assumption failed")

  def assume(assumption: Boolean, message: Any): Unit =
    if (!assumption)
      throw new Error("assumption failed: " + message)
}
\end{lstlisting}

\comment{
\subsection{Base Classes}
\label{sec:base-classes}

For every template, class type and constructor invocation we define
two sets of class types: the {\em base classes} and {\em mixin base
classes}. Their definitions are as follows.

The {\em mixin base classes} of a template 
~\lstinline@$sc$ with $mt_1$ with $\ldots$ with $mt_n$ {$\stats\,$}@~ 
are 
the reduced union (\sref{sec:base-classes-member-defs}) of the base classes of all
mixins $mt_i$. The mixin base classes of a class type $C$ are the
mixin base classes of the template augmented by $C$ itself. The
mixin base classes of a constructor invocation of type $T$ are the
mixin base classes of class $T$.

The {\em base classes} of a template consist are the reduced union of
the base classes of its superclass and the template's mixin base
classes.  The base classes of class \lstinline@scala.Any@ consist of
just the class itself. The base classes of some other class type $C$
are the base classes of the template represented by $C$ augmented by
$C$ itself.  The base classes of a constructor invocation of type $T$
are the base classes of $T$.

The notions of mixin base classes and base classes are extended from
classes to arbitrary types following the definitions of
\sref{sec:base-classes-member-defs}.

\comment{
If two types in the base class sequence of a template refer to the
same class definition, then that definition must define a trait
(\sref{sec:traits}), and the type that comes later in the sequence must
conform to the type that comes first. 
(\sref{sec:base-classes-member-defs}).
}

\example 
Consider the following class definitions:
\begin{lstlisting}
class A 
class B extends A 
trait C extends A 
class D extends A 
class E extends B with C with D 
class F extends B with D with E 
\end{lstlisting} 
The mixin base classes and base classes of classes \code{A-F} are given in
the following table:
\begin{quote}\begin{tabular}{|l|l|l|} \hline
 \ & Mixin base classes & Base classes \\  \hline
A & A & A, ScalaObject, AnyRef, Any \\
B & B & B, A, ScalaObject, AnyRef, Any \\
C & C & C, A, ScalaObject, AnyRef, Any \\
D & D & D, A, ScalaObject, AnyRef, Any \\
E & C, D, E & E, B, C, D, A, ScalaObject, AnyRef, Any \\
F & C, D, E, F & F, B, D, E, C, A, ScalaObject, AnyRef, Any \\ \hline
\end{tabular}\end{quote}
Note that \code{D} is inherited twice by \code{F}, once directly, the
other time indirectly through \code{E}. This is permitted, since
\code{D} is a trait.
}
